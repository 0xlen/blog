var store = [{
        "title": "2016 不平凡的一年",
        "excerpt":"         2016年9月 升上大三   大學生涯邁入1/2，其實在這個階段，   我的確迷失方向，但是我相信自己的無懼。      承認自己的失敗，修正，然後繼續前進。    是我今年最大的體悟。   過去與現在   今年，   進入學校計中工作，幸運的是，進入了網路組。   我喜歡這份工作，除了對於網路層面的技術有更深的了解，   重要的是，學習如何處理問題的能力。   可貴的是，有一群認真的老師及學長不吝為我分享他們自己的經驗，   讓我從中獲得不一樣的啟發。   大一，其實一切都好，但是漸漸的，似乎跟自己預期走的方向越來越遠。   大二，接了系學會幹部。   接了幹部這年，課業、能力得過且過，   當然，也不能說大二的一切都是白費。   對於活動上的付出，   就像跟Steve Jobs一樣，開發Mac時想到了旁人看起來無用的書法課。   雖然說現在做的一切，也許無用；或許十年後，能有所幫助。   但是，站在大三的時間軸上，我還是迷惘了。   一次的計網工作下班後，跟老師暢談的夜晚，   仔細想想，我的確錯過了那個學習、瘋狂陶醉技術的自己。   重新檢視自己的道路，   也許走得路並不是這麼的直，中間偏離了自己預期的方向，   不可否認的是，我的確也從接任幹部的這一年學習到很多，   不管是想法的改變、對事情的見解，   以及與人際的相處、溝通能力，企劃及變通的能力。   覺得可惜的是，課都沒有認真上，   考試也沒有認真考，忙著弄系學會的事情。   當然， 也是有一些深刻的事情，   特別是接下資工營的總召， 實在是很特別的經驗，也間接實踐了自己的一些想法，   希望能藉由自己的經驗傳承，創造系上的一些不同，與改變。   不怕失敗   整年最深刻的成長，大概就是願意承認自己的錯誤。   人們總是害怕自己承認失敗的後果，   覺得自己會被責備、或是面對與論的壓力。   在課業上，我的確失敗；在過去活動驗收時，我遲到，我的確做得不好。   但是我願意承認自己的錯誤，   所以在2016快要進入尾聲的這刻，   決定重新找回遺失的自己，   更無懼的為自己的想法負責，努力執行。   重新繼續瘋狂的生活， 回歸最原本的道路，   才是我心中最渴望的本質，而且努力挑戰自己。   2016尾聲 後記   不要小看我買domain這個動作，   現在又開了GitHub page用jekyll自言自語，當然最期許的是自己能開始做出很多改變。   最近也投了AWS的internship，   希望有機會能進到面試階段、期待自己能進去看看，   也想試試看不同的公司、不同的文化，   更讓自己有更多不同的想法與成長。   對研究所也開始有一些見解與看法，   慶幸的是，至少沒這麼迷惘了，   心態也沒這麼失衡了，希望能找回更多動力與前進的契機。      2016.11.01 無懼，然後繼續前進   ","categories": [],
        "tags": ["mood"],
        "url": "https://easoncao.com/2016-year/",
        "teaser": "https://easoncao.com/assets/images/posts/2016/11/2016-year/direction.jpg"
      },{
        "title": "中華電信hinet 申請及設定IPv6 (DSL-7740C)",
        "excerpt":"                  Ping facebook using IPv6            前情提要   因為近期hinet的路由走國外海纜一直發生掉包的情形,   不管是facebook, slideshare很多有走相關國外CDN都傳出災情，   所以就不小心申請了IPv6,   希望這陣子藉著走IPv6的路由節點壓壓驚,   當然最主要的原因還是想申請IPv6玩玩看,   申請的程序也不需要跑中華電信營業門市,   藉這個機會就給他申請了.   申請IPv6   這部份原本想截圖, 不過發現申請過後沒辦法照正常的程序跑一遍,   所以申請步驟還是麻煩詳細參照一下這邊的步驟,   後面就主要著墨在Router端的設定,   當初11/3半夜線上申請,   以為收到mail通知申請程序就以為馬上就開通IPv6 dual stack的功能了,   還在傻傻的想說設定怎麼跑出來,   隔天11/4早上課上到一半hinet透過電話主動通知我,   告知機房已經完成IPv6 dual stack的設定了,   效率其實蠻快的.   進入D-Link DSL-7740C設定頁面   當初申請光世代100M/40M裝機人員所使用的機種正是D-Link DSL-7740C   我目前申請的位置沒辦法直接跑100M/40M,   必須透過50M兩條並行傳輸, 對我來說是蠻新鮮的,   特別是拿到Router後, 一連進去設定頁面發現其實功能蠻強大的,   只是一直沒有好好玩它XD   (要連進去小烏龜通常使用192.168.1.1這組IP在LAN的環境下應該就能正常進入)   (若不行則要先檢查一下default gateway是什麼去找出小烏龜的IP)   相關的帳號密碼會依據申請hinet的營業位置有不同的設定,      帳號: cht  密碼(北區): chtnvdsl  密碼(中區): chtcvdsl  密碼(南區): chtsvdsl    2021 更新 (DSL-7740C 適用帳號密碼)   最近注意到上述的密碼基於韌體更新有一些變動，如果無法登入的朋友可以嘗試以下訊息：      帳號: cht   密碼: 740C+LAN MAC 末四碼   MAC 位置可以翻下機器背面會有相關的資訊，例如：                     DSL-7740C MAC 位置            像上述範例密碼可以為：740CBA87   確認設定的帳號   申請hinet網路服務後, 營業處應該都會發一組HN號碼及HN密碼,   用於PPPoE驗證連線使用,   一般光世代浮動用戶帳號格式為: HN號碼@hinet.net (固定ip用戶則為@ip.hinet.net)   礙於個資法規定, 通常hinet裝機人員到府裝機設定時都會用一組@wifi.hinet.net的帳號密碼,   wifi.hinet.net跟hinet.net兩組的密碼是不同的,   wifi.hinet.net是方便裝機人員能直接進行網路設定, 密碼通常只有該營業處能得知,   而且稍微爬過資料得知這組帳號可能會發生沒有辦法拿到IPv6位址的情況 (當然說不定也可以),   帳號設定就請使用@hinet.net為主,   WAN介面及帳號設定   進到WAN Setup頁面可以看到4個interface (WAN1_4是我自己設定的),                     WAN設定            其中WAN1_2是原本hinet裝機人員設定的,   裡面設定的帳戶就是@wifi.hinet.net.            因為在設定的時候不希望影響原有的網路設定,   在WAN Setup頁面按下Add按鈕,   另外新增了一個interface WAN1_4, 帳號使用@hinet.net,            以下是相關設定 (如果是直接更改原本就有的 wifi.hinet.net 帳號則只須更改 2. 即可)      WAN Setting 選擇 PPPoE   username填入 HN號碼@hinet.net   password/confirm password填入對應的密碼   Default Route打勾 (確定能正常connect之後建議再將這個選項打勾)        Connect mode select       (可以先選Manual, 確認測試沒問題再設定成Connect-on demand)          若要手動測試interface可不可以正確透過PPPoE獲得IP,     至 STATUS &gt; INTERNET STATUS 內的 Connection 選擇對應的界面後,     按下Connect / Disconnect按鈕進行測試    設定IPv6           確認帳戶設定沒問題後, 將新增的interface設定為Defalt Route (參照前面的帳號設定步驟 4.)       (若是直接改裝機人員預設的帳號密碼則不用做這個動作, 因為預設就有勾選這個設定)            原本上網的介面就會被設定為新介面上網, 確認是否有正確從hinet機房獲得到IPv4的位址            進入IPv6設定頁面, 照以下方式設定              IPV6 CONNECTION TYPE                    My IPv6 Interface is : 設定hinet帳戶的介面 (預設就是Default Route)           My IPv6 Connection is : PPPoE (以PPP連線進行驗證並以dual stack方式上網)           IPv6 Enable : 勾選                       IPV6 DNS SETTINGS                    選擇 Use the following IPv6 DNS servers           Primary IPv6 DNS Address : 2001:4860:4860::8888    (Google public IPv6 DNS)           Secondary IPv6 DNS Address : 2001:4860:4860::8844  (Google public IPv6 DNS)                       LAN IPV6 ADDRESS SETTINGS                    Enable DHCP-PD : 勾選                       ADDRESS AUTOCONFIGURATION SETTINGS                    Autoconfiguration Type : SLAAC+Stateless DHCP (也可以使用不同的方式, 建議使用SLAAC+Stateless DHCP, 支援的設備較多)                           設定參考                  &lt;/figure&gt;           按下 Add/Apply            Reboot 重新啟動 DSL-7740C            進入STATUS &gt; IPv6就會顯示相關IPv6資訊了                   IPv6 Status            &lt;/figure&gt;           至test-ipv6.com進行測試                   &lt;/figure&gt;   部份問題      透過Wi-Fi上網的設備有時候可能會發生DHCP無法正確給DNS的狀況,  可能是DSL-7740C firmware bug, 建議手動綁一下DNS就可以解決了.   ","categories": [],
        "tags": ["hinet","ipv6","dlink"],
        "url": "https://easoncao.com/setup-hinet-ipv6-with-DSL-7740C/",
        "teaser": "https://easoncao.com/assets/images/posts/2016/11/hinet-ipv6/ping-facebook-v6.png"
      },{
        "title": "讀大學：回歸本質，找尋自己",
        "excerpt":"                  What is YOU?            (Photo credit: kodomut)   思考？你會思考嗎？   從國小到國中、國中到高中， 師長們其實默默的都為我們瘋狂的洗腦大學多美好的印象， 說著說著，其實默默的心裡自己也信了，   為了進入好學校、好大學，所以努力讀書、追求好成績， 特別是台灣教育最大的特色就是升學考試，把我們自己訓練的跟考試機器一樣。   從小其實我不愛讀書，也很討厭制式考科的教育制度，   但是因為父母、老師的期待，你還是會把該唸的本分給唸完，   寫著一堆不知道哪裡來的教科書、考卷、課堂隨時的小考，   搭配一堆無腦的畫叉否定跟訂正，不知道在訂正什麼，只為了下次不要再錯這題，   甚至為了配合出題者的答案，要去”背”這個形式的答案。   班上總是有那種就是沒辦法讀書的同學，比較愛玩，無法專心讀一大堆教科書，所以成績差不停的被老師勸說。   但是相對的，你只要乖乖讀書，成績都不會太差，大家還會很愛你，甚至把你當神膜拜。   從考試過程中我們不停的猜測、與同學競爭，成績好的同學就會被老師拿來當範本， 不愛唸書的同學就會被貼上沉淪的標籤。   國中，老師跟你說考上好高中就有好前景…   高中，考上好大學就可以玩四年，找工作不用煩惱…   就這樣一路來到大學，才發現事與願違，   當你進到大學， 若有機會教授在課堂上突然要求你自己思考，   漸漸的，你才會意識到其實你已經忘記 怎麼思考 這件事情，   什麼是思考，你會思考嗎？   這問題雖然好像有點像在開玩笑，可是如果你去問問現在普遍大學生，有幾位認真想過這個問題？   從我自己的感受是，他們甚至無法真正了解自己在做什麼。   因為高中前這樣教育制度下的訓練，其實真的大家都被訓練成不必思考，只因為誰誰誰叫我這樣做，所以做到符合標準的要求就好，而不是怎麼做能更好。   甚至不知道唸大學的目的為何，可能只是因為家長老師說要讀大學，所以來拿個學歷，   唸大學的過程中腦袋還會退化，不懂的如何思考問題、思考的方式也沒有邏輯，只是在盲目的鑽牛角尖，   最後課程還是只能淪為：考古題、筆試、標準答案，   反而是教授要求你做Project，特別是Team project，才有可能會意識到自己的不足。   回歸本質   我認為上大學應該是一個非常好的機會找回：真正會思考的自己   進大學還是會發現大家都是為了修課而修，大部分人努力挑了爽過的課程，而不是藉這個機會去學習、訓練自己如何思考問題，   一直沒辦法跳脫自己的舒適圈，我想這就是為什麼在討論一些Team Project時，產生大家都說自己沒想法的最大原因。   大三，這學期我修了一門很特別的課程：法國文化與紙藝應用，   老實說這門課十足震撼，在別人口中這是一門 “硬課” ，班上同學對老師及課程的評價也十分兩極化，   印象深刻的是，剛開學兩星期修課人數，從約40人撤選到學期現在過半，剩下不足20幾人，   這門課程真正重新帶領我學習如何”思考”， 並且從不同的切入點去看待事情及問題， 像是一張紙的顏色、纖維的脈絡、輕盈度、不同材質產生出什麼樣的變化，   甚至是滴一滴水在紙張的擴散程度，都是課堂中你可以關注的問題，   困難的地方在於，全憑你如何用最簡單、最細微的角度觀察出他們的”本質”，   講起來雖然抽象，但其實這就是當我們在解決問題時最缺乏的能力，   常常看問題時我們都會從很宏觀、多角度的方式去看待問題，   但當你從最基礎的地方開始出發，才能逐漸的將細節慢慢擴大。   主體意識（主觀認定）   雖然課程中，只講求從材質最真正的”本質”出發，課程的材料也偏向設計面的培養，   不管是老師從外面邀請的老師(業師)協助課程評論，或是要求我們用課外的時間親訪林業試驗場，   其實額外花很多課堂外的時間，但能堅持修這門課的學生，我想大概也不在乎那兩學分了。   矛盾的是，有時候可能教授們強調的「學分及成績，並不是代表你能力價值的東西」這句話聽起來很有道理，但還是很多人以主體意識的方式，去認定這些東西是比較具有參考價值、並且能夠評估能力的指標之一。   而紙藝這門課程最特別的地方就在於：強調主觀意識的重要性(指的是對於事物認定的想法)   在課堂中評估藝術品及學生任何「行為價值」的這些過程，常常發生老師跟邀請的業師會因為主觀認定的不同，造成評價矛盾的情況，   也讓我們在上臺報告時不知所措，可是老師及業師還是很有風度的願意承認自己的疏失，讓我們了解主觀認定上的不同都是需要被尊重的。   身為理工學生的我，往往會優先用客觀的角度分析事情，自從我修了這門課程，開始會對事情陷入哲學性的思考，   甚至不時會質疑事情的正確性，並且會用主觀意識的方式去切入問題，試著從問題中找出自己的答案，   這個答案，不是標準答案，但也不是錯誤的答案，但是我相信，對我自己一定是一個好答案。   勇於發問、不怕犯錯   也因為這門課程做出了一些小小突破，而近期的最大突破，就是開始學著認識真正的自己，   過去很感謝有機會能跟一些新創公司的負責人談話，談話過程中漸漸讓我意識到其實每個人都有自己的特質，以及自己是這麼的不足，   也很感謝他們讓我了解”發問”這件事情，是需要積極訓練的，   當你遇到問題時，提出問題的動機本來就沒有好跟壞之分，所以不要害怕發問，   這句話不知道有多少大學生能真正實踐（包括我自己）， 透過發問能力的訓練，你才能體悟到其實犯錯真的沒什麼，無知也是正常的事情，   但是如果已經知道自己不懂了，還不透過向他人發問去克服你自己的問題，那實在是太對不起自己了。   從談話中最獲益的一句話就是：   不管你現在能力如何，最重要的是，你如何去突破自己，你是否願意突破自己？   我自己因為擔任系學會幹部、在計網中心工讀的過程，漸漸的從面對人事物的過程中，才開始慢慢建立起自己的自信， 並且學會如何檢討自己，   這些經驗都是磨練自己的契機，過程從開始、當下、結束也有非常多的挑戰跟困難，但是當有機會的時候，一定要期許自己不要因為害怕就不敢做了。   當你將視野放大，你才會意識到自己的渺小與平凡。   只能不停的期許自己學習、學習再學習， 畢竟唯有意識到自己犯錯與缺失，才會有不一樣的成長與改變。   Next … ?   總結：思考 + 發問 = 解決問題   當你開始面臨思考如何克服現下的挑戰時，少不了的就是你發問及突破的勇氣，   不過，問題來了，   先問問自己，思考一下：你願不願意挑戰現在的 你自己？      突破現在的自己，往下個階段的前進吧。   ","categories": [],
        "tags": ["mood"],
        "url": "https://easoncao.com/what-is-you/",
        "teaser": "https://easoncao.com/assets/images/posts/2016/11/what-is-you/you.jpg"
      },{
        "title": "Stay hungry, stay foolish",
        "excerpt":"                  Stay hungry, stay foolish            (Photo credit: rob patrick)   一個人在外唸書第三年了，   2016年即將結束，   每當遇到低潮，總會想起家鄉，甚至不禁質疑自己為什麼要這麼辛苦，   長大了，自己讀書，自己規劃人生，自己學著跌倒站起來，   因為長大任憑叛逆的想法茁壯，心中卻又有一絲想依靠家裡的渴望。   即使這麼辛苦，   回頭翻翻一路成長的一些照片跟紀錄，   總是會意識到自己得不斷長大，   因為長大，所以接觸更深、更廣的世界，   知識更艱澀、學習更無涯，   學習中又會因為自己的無知感到悲憤、始終摸不著頭緒，   意識到自己能力還必須得不斷提昇，基礎知識還要不斷的熟悉、了解，   過程辛苦、迷茫，一無所獲，總期盼自己能有頓悟的那刻，   真希望我也能享受一下因為知識滿足的成就感啊，   但我想既然我這麼貪婪於知識，是不會滿足的，   每每總覺得自己十分不足，最後還是回頭告訴自己，   繼續長大吧。   ","categories": [],
        "tags": ["mood"],
        "url": "https://easoncao.com/stay-hungry-stay-foolish/",
        "teaser": "https://easoncao.com/assets/images/posts/2016/12/stay-hungry-stay-foolish/quote.jpg"
      },{
        "title": "2016 End",
        "excerpt":"                  See you, 2016!            台灣時間，2016年將進入尾聲，   在這個時間點，有很多感觸， 希望能藉由紀錄的方式摘要我這一年的感受，   今年邁入20，也是具備民法全責資格的年齡， 從弟弟、同學，到先生，不僅是稱謂上的不同，更代表著必須長大的殘酷事實，   可以大搖大擺的自己去銀行辦了張信用卡，簽署再也不用父母同意了， 享受刷卡便利的同時也必須開始學著如何支出， 意味著這個年齡開始，是好是壞做任何事情前都必須要思考清楚，   受惡房東氣，換了一個室友， 終於換了自己還滿意的新家，跟著室友一起搬家逃跑，（叫lalamove搬家還蠻便宜的） 自己買了新的鍋具，開始點煮菜技能（雖然還是很不會煮）， 把家裡的線路升到IPv6壓壓驚，   當幹部、奉獻青春、接下活動總召， 還記得當時活動前累到每天都睡沙發， 早上被嚇醒、晚上累到半夜再回家，或是洗個澡就又回學校，就怕漏掉每個細節（雖然現在也好像常睡客廳….咦！？）   今年也扛起迎新的任務，自己學著怎麼帶領團隊，在茫然中摸索， 歷經很多挫折跟難過，以及厭煩，厭煩總是做不好的無力感、沒有任何動力想前進跟繼續當幹部的念頭。   做一些我自己都難以理解的行為，因為我本來就不是會去主動帶人的角色， 也沒什麼社交能力，卻還是冒著生命危險硬把團隊炒熱絡，   對於團隊風氣不抱任何期待、任憑團隊意志被擊潰， 過程中還是得不斷的告訴自己撐下去、要把大家帶好帶滿， 所以再累再不願意，也是時時提醒自己，因為這個身份，我需要做的更多，   活動結束後其實很多感觸，但也非常疲乏，   一是今年天氣比較不給面子，辛苦辦的活動就這樣砍了。 二是很遺憾今年帶給我的感觸不比我前幾年來的深刻，可能因為我換了個位子也換了個腦袋吧。 三是活動辦完才發現，自己已經不小了，腦袋一直浮出「好像該做點什麼其他事情了」的想法。   其實很驚訝活動結束後竟然會有人願意給我這個邊緣人寫背卡（痛哭流涕了），   雖然活動結束後各自鳥獸散， 我就是比較懶，現在才感謝好像也有點晚，但感謝終究不嫌晚， 很慶幸2016有這群人陪著我一起成長，更高興的是，看見你們的成長，   自完成階段性的任務， 今年最大的收穫就是學習接納失敗，學著如何吸取教訓，適應變化， 還有練就如何面對千奇百怪的人、莫名其妙的通識課堂作業、期末如何用指數成長的方式爆肝， 期末每天跟deadline賽跑，發現自己真的很嫩，沒有那麼多能力（三下一學期做3、4個project，今年真的很特別）。   今年學習曲線也開始慢慢亂走，從學著怎麼寫測試， 開始放下自己code寫很好的成見，逼自己面對自己寫的爛碼， 又弄一堆雜七雜八的東西，做一些自己也不知道是不是正確的決定，   因為當沒有人幫你決定的時候，大部分沒有任何方向的人，我想都會跟我一樣茫然的，   也因為自從修了某紙藝課，有越來越感覺「不知道自己為什麼在這」、發現自己其實沒有對未來有太多規劃， 以及慢慢的開始發現自己跟別人的不同，   開始面對自己在很多方面確實比別人差，是一件很難接受的事情，老實說我也很難接受，   最重要的是，要找出自己最特別、最厲害的地方，了解自己的想法，自己真正渴望的東西， 因為盲目的追求新東西實在是太累人了，做得也並不一定比其他人得心應手，   我想這就是我2016最大的感觸了， 這一年要感謝的人太多，就感謝2016吧， 2017繼續加油，身為邊緣人的我要繼續在家陪我的project跨年了。  ","categories": [],
        "tags": ["mood"],
        "url": "https://easoncao.com/2016-end/",
        "teaser": "https://easoncao.com/assets/images/posts/2016/12/2016-end/see-you-2016.png"
      },{
        "title": "在 PHP FastCGI 環境下自訂使用者的 php.ini 設定",
        "excerpt":"         前言   因為自己興趣使然有在玩 VPS，雖然不排斥指令界面，   但有時候會沒睡飽不小心下錯指令，也有時候避免不了各設定檔互向關聯，當腦袋還沒清醒時去動 Production 的機器簡直超級悲劇，   因為玩玩的機器，沒打算買 cPanel 授權，所以我過去一直使用 Kloxo 當作我的 Panel，除了能更直覺的了解現在的設定外也能避免一些設定上的慘案。   自從歷經幾次的 Kloxo 漏洞被打實錄後，有了一些慘痛的教訓，   而且官方團隊也在 6.1.19 版本後正式宣告不維護，所以就跳槽到現在的 webmin + virtualmin 環境一陣子了。   Virtualmin 出乎我意外的好用，而且設定相比 Kloxo 也直覺多了，   從 Kloxo 到現在在用 Virtualmin 的過程中，不免會對設定很好奇，所以花了一點時間研究設定檔，紀錄一下。   環境   Server version: Apache/2.4.6 (CentOS) PHP: PHP 5.4.16 (Default) / PHP 5.5.21 / PHP 5.6.5 Panel: Webmin (1.831) + Virtualmin (5.05)   (關於多個 php 版本的設定有機會再來補個文章，可詳見Red Hat Software Collections)   設定   Apache (http)   &lt;Directory /home/user/public_html&gt;     Options -Indexes +IncludesNOEXEC +SymLinksIfOwnerMatch +ExecCGI     allow from all     AllowOverride All Options=ExecCGI,Includes,IncludesNOEXEC,Indexes,MultiViews,SymLinksIfOwnerMatch     Require all granted     AddType application/x-httpd-php .php     AddHandler fcgid-script .php     AddHandler fcgid-script .php5     AddHandler fcgid-script .php5.5     AddHandler fcgid-script .php5.6     FCGIWrapper /home/user/fcgi-bin/php5.5.fcgi .php     FCGIWrapper /home/user/fcgi-bin/php5.fcgi .php5     FCGIWrapper /home/user/fcgi-bin/php5.5.fcgi .php5.5     FCGIWrapper /home/user/fcgi-bin/php5.6.fcgi .php5.6 &lt;/Directory&gt;   新增 wrapper script /home/user/fcgi-bin/php5.fcgi   #!/bin/bash PHPRC=$PWD/../etc/php5 export PHPRC umask 022 export PHP_FCGI_CHILDREN PHP_FCGI_MAX_REQUESTS=99999 export PHP_FCGI_MAX_REQUESTS SCRIPT_FILENAME=$PATH_TRANSLATED export SCRIPT_FILENAME exec /bin/php-cgi   複製 php.ini 至 /home/user/etc/php5   cd /home/user/etc/php5 cp -a /etc/php.ini . chown user:user php.ini   確認FastCGI wrapper script權限是否設定正確   chown user:user php5.fcgi &amp;&amp; chmod 0755 php5.fcgi   重新啟動Apache   service apache restart   參考資料：     Using Custom php.ini with PHP5 under FastCGI  ","categories": [],
        "tags": ["php","apache"],
        "url": "https://easoncao.com/php-fastcgi-config-with-custom-php-ini/",
        "teaser": "https://easoncao.com/assets/images/posts/2017/01/php-fastcgi-config-with-custom-php-ini/setting.png"
      },{
        "title": "Apache / PHP 上傳大檔的注意事項",
        "excerpt":"         現在頻寬越來越大，ISP 提供上傳跟下載的費用也越來越便宜，   以目前大眾常使用的 100Mbps/40Mbps 家用頻寬一次傳個 300MB 的大檔也稀鬆平常。   但是像 Apache 2.4.18 及 php 預設設定仍然還卡在 20M 甚至 8M 內，   有時候應用程式需要傳大檔時這些設定不免成為瓶頸，   並不是程式有 bug ，很可能是設定上需要做一些調整，   所以自己整理一些設定的經驗作為參考，如果未來在做 trubleshooting 時可以朝以下方向著手。   追蹤問題   通常可以透過 Debug 錯誤訊息，/var/log/apache, /var/log/apache2/, /var/log/httpd 等等找到相關的錯誤及紀錄。   當問題比較難追蹤，可以試著多模擬幾次同樣的出錯流程。藉由重複產生問題，能在紀錄中找到比較明顯的表徵，並且進一步除錯。   PHP   php.ini : 預設 php 設定檔內可以檢查以下設定   upload_max_filesize 10M post_max_size 15M max_input_time 300 max_execution_time 300      upload_max_filesize : 限制最大上傳檔案大小   post_max_size : 這邊指的是 POST method 封包允許的大小，很多設定都設跟 upload_max_filesize 一樣，                   但照官方的建議應該是要設得比 upload_max_filesize 來得大，                   而一般來說 memory_limit 應該也必須比 post_max_size 大，才能分配足夠的記憶體空間給 POST 方法使用的變數。   max_input_time : 最大的上傳允許時間。   max_execution_time : PHP script 正常呼叫時允許的最大執行時間。通常上傳大檔時，因為傳輸頻寬影響，會導致接收檔案的 PHP script 執行時間過長。                        若太短會讓伺服器中斷仍在執行傳輸的作業，使傳輸連接中斷。   如果是 shared host，主機商沒有提供更動設定檔的權限，也可以試著透過 .htaccess 檔案方式直接設定。   (注意必須要 Apache 內環境設定啟用 AllowOverride All 的設定才會生效，若不確定建議直接聯絡主機商確認。)   .htaccess 設定如下   php_value upload_max_filesize 10M php_value post_max_size 10M php_value max_input_time 300 php_value max_execution_time 300   Apache   除了 PHP 本身的設定外，也要注意是不是 apache 本身的設定造成傳輸瓶頸。   遇到 apache mod_fcgid: HTTP request length xxxxx (so far) exceeds MaxRequestLen (xxxxx)   因為傳輸大檔超過 apache 允許的最大請求長度，所以 apache 會吐這個問題。      /etc/apache2/mods-available/fcgid.conf (ubuntu / debian)   在設定檔中加入或調整 MaxRequestLen 參數即可   MaxRequestLen 15728640   如果環境不同，注意設定檔案通常在以下地方：     /etc/apache2/conf-enabled (ubuntu / debian)            注意是不是有主要的 apache2.conf 會 include /etc/apache2/conf-available 底下的設定， 如果沒意外應該會 link 到 /etc/apache2/conf-available 底下。           /etc/httpd/conf/httpd.conf (RedHat / CentOS)            一樣要注意是不是有 /etc/httpd/conf.d/* 之類的設定檔， 通常需要檢查一下主要的設定檔看是不是有 Include 關鍵字再進一步去檢查。 (推薦使用grep -ri 'Include'指令)           其他關於大檔案上傳的可以參考 ownCloud 官方文件 Uploading big files &gt; 512MB 一節，   裡面包含了部份 nginx 的設定，十分值得參考。   ","categories": [],
        "tags": ["php","apache"],
        "url": "https://easoncao.com/apache-and-php-upload-large-file/",
        "teaser": "https://easoncao.com/assets/images/posts/2017/01/apache-and-php-upload-large-file/box.png"
      },{
        "title": "讓 git 不必 commit 而暫存特定檔案的修改",
        "excerpt":"         git 最常用的指令應該就屬 commit 了，   然而修改特定檔案後 (untrack)，想要回到修改前的狀態 (HEAD)，卻又想暫存現在的修改，   我們並不想要真正 commit ，因為如果只是一點試驗性的修改，就又多一筆 commit 會感覺有點多餘。   這時候常見的作法是 stash ，便能暫存目前的修改。   git stash   要回復只要使用 pop 即可   git stash pop   但是這不是本篇文章的重點，如果一次更改多處程式，只想暫存特定檔案的修改，   最簡單的方式可以利用 diff 達成。   git diff app.c &gt; stashed.diff git checkout app.c   這樣會多出一個 stashed.diff 檔案，利用 checkout 就能將修改倒帶回去，只要使用 apply 就能回復修改。   git apply stashed.diff   另一種作法則是將要保存修改的檔案全部 git add 一遍，透過 --keep-index 也能達到同樣暫存特定檔案修改的效果。   touch FileNotStashed.txt stashed.txt git add FileNotStashed.txt git stash --keep-index   參考資料：     Stash only one file out of multiple files that have changed with Git?  ","categories": [],
        "tags": ["git"],
        "url": "https://easoncao.com/git-stash-only-one-file/",
        "teaser": "https://easoncao.com/assets/images/posts/2017/01/git-stash-only-one-file/git.png"
      },{
        "title": "jQuery Selector 使用逗點之間的差異",
        "excerpt":"                  jQuery! write less, do more.            雖然好像有點舊飯重炒了，現在前端也打的這麼火熱，   這些紀錄出來的時機好像有點短，不過接觸 jQuery 也蠻常一段時間了，   好像沒什麼注意到有人區別逗號 “,” 這個很特別的存在，也常常是讓初學者混淆摸不著頭緒的一個符號，   jQuery selector 一般常見的寫法都是   $('button')   如果是選擇 class name 會利用 “.” 點符號表示， id 則是使用 “#” 井字符號表示，跟 css 的 selector 用法一樣。   $('.myClass') $('#id')   而逗點如果放在 ‘’ (單引號) 或 “” (雙引號) 間 (兩者在 jQuery 中其實沒有太大區別)， 代表的是 multiple selector，會同時選擇兩個以上的元素 (element)。   $('button, div')   上述程式同時選擇了 DOM 裡的 button 及 div。   但要注意的是，如果 “,” 逗號放置在 ‘’ (單引號) 或 “” (雙引號) 外，就變成有點像 function(param1, param2) 的概念，成兩個實體參數，   寫法為：   jQuery( selector [, context ] )   context 可以是 DOM element、Document 或是 jQuery Object，   這樣 jQuery 會縮小選擇範圍，以第二個參數作為選擇對象縮小搜尋，像以下範例。   $('div').on('click', function(e) {     $('p', this).addClass('active'); });   也就是說，下段程式碼，均有同等的效果。      Example 1     var $container = $('div'); $('button', $container)           Example 2     $('div button')           Example 3     $('div').find('button')           Example 4     var $container = $('div'); $container.find('button')           參考資料：     jQuery()   Multiple Selector (“selector1, selector2, selectorN”)  ","categories": [],
        "tags": ["jQuery","javascript"],
        "url": "https://easoncao.com/jquery-selector-using-comma/",
        "teaser": "https://easoncao.com/assets/images/posts/2017/01/jquery-selector-using-comma/jquery.png"
      },{
        "title": "讓PHPUnit測試單一個程式",
        "excerpt":"                  PHPUnit            在跑單元測試總有遇到亮紅燈的時候，健全一點的測試幾十個 assertion 都很正常，   但是如果 phpunit 只有幾個測試沒過全部重測也很浪費時間，所以稍微找了一下怎麼只測特定的 method 。   只測一個單元測試檔案   phpunit tests/testone.php   只跑 test/testone.php 裡的 testMethod()   phpunit --filter testMethod tests/testone.php   --filter 也支援 Namespace / Class name   phpunit --filter 'TestNamespace\\\\TestCaseClass::testMethod' phpunit --filter 'TestNamespace\\\\TestCaseClass' phpunit --filter TestNamespace phpunit --filter TestCaseClass   正規表達也沒問題   phpunit --filter '/::testMethod .*\"my named data\"/'   也有快速便捷的測法   phpunit --filter 'testMethod#2' phpunit --filter 'testMethod#2-4'   其他用法詳見：      PHPUnit 官方文件 Filter pattern  ","categories": [],
        "tags": ["phpunit","unit-test","php"],
        "url": "https://easoncao.com/let-phpunit-test-only-one-function/",
        "teaser": "https://easoncao.com/assets/images/posts/2017/01/let-phpunit-test-only-one-function/phpunit.png"
      },{
        "title": "Laravel 5 自訂分頁 (Pagination) 樣式",
        "excerpt":"Laravel 5.3   Laravel 5.3 開始官方將這部份重寫成 method，可以利用 links('view.name') 完成自訂分頁。   {{ $paginator-&gt;links('view.name') }}   透過 vendor:publish 指令很快的就能在 resources/views/vendor 產生對應的 Blade 。   php artisan vendor:publish --tag=laravel-pagination   詳見 Laravel 5.3 Customizing The Pagination View   Laravel &lt;= 5.2   Laravel 5.2 以下的版本可以利用實做 PresenterContract 類別達成，   重寫 render, getAvailablePageWrapper, getDisabledTextWrapper, getActivePageWrapper methods 的樣式。   新增 App\\Pagination\\CustomPresenter.php ， 範例程式如下。   &lt;?php  namespace App\\Pagination;  use Illuminate\\Contracts\\Pagination\\Paginator as PaginatorContract; use Illuminate\\Contracts\\Pagination\\Presenter as PresenterContract; use Illuminate\\Pagination\\BootstrapThreeNextPreviousButtonRendererTrait; use Illuminate\\Pagination\\UrlWindow; use Illuminate\\Pagination\\UrlWindowPresenterTrait;  class CustomPresenter implements PresenterContract {     use BootstrapThreeNextPreviousButtonRendererTrait, UrlWindowPresenterTrait;      /**      * The paginator implementation.      *      * @var \\Illuminate\\Contracts\\Pagination\\Paginator      */     protected $paginator;      /**      * The URL window data structure.      *      * @var array      */     protected $window;      /**      * Create a new Bootstrap presenter instance.      *      * @param  \\Illuminate\\Contracts\\Pagination\\Paginator  $paginator      * @param  \\Illuminate\\Pagination\\UrlWindow|null  $window      * @return void      */     public function __construct(PaginatorContract $paginator, UrlWindow $window = null)     {         $this-&gt;paginator = $paginator;         $this-&gt;window = is_null($window) ? UrlWindow::make($paginator) : $window-&gt;get();     }      /**      * Determine if the underlying paginator being presented has pages to show.      *      * @return bool      */     public function hasPages()     {         return $this-&gt;paginator-&gt;hasPages();     }      /**      * Convert the URL window into Bootstrap HTML.      *      * @return string      */     public function render()     {         if ($this-&gt;hasPages()) {             return sprintf(                 '&lt;ul class=\"article-pages db\"&gt;' .                 '&lt;div class=\"head\"&gt;%s&lt;/div&gt;' .                 '&lt;div class=\"tail\"&gt;%s&lt;/div&gt;' .                 '&lt;div class=\"pages\"&gt;%s&lt;/div&gt;' .                 '&lt;/ul&gt;',                 $this-&gt;getPreviousButton(),                 $this-&gt;getNextButton(),                 $this-&gt;getLinks()             );         }          return '';     }      /**      * Get HTML wrapper for an available page link.      *      * @param  string  $url      * @param  int  $page      * @param  string|null  $rel      * @return string      */     protected function getAvailablePageWrapper($url, $page, $rel = null)     {         $rel = is_null($rel) ? '' : ' rel=\"'.$rel.'\"';          return '&lt;li class=\"pg\"&gt;&lt;a href=\"'.htmlentities($url).'\"'.$rel.'&gt;'.$page.'&lt;/a&gt;&lt;/li&gt;';     }      /**      * Get HTML wrapper for disabled text.      *      * @param  string  $text      * @return string      */     protected function getDisabledTextWrapper($text)     {         return '&lt;li class=\"pg disabled\"&gt;&lt;span&gt;'.$text.'&lt;/span&gt;&lt;/li&gt;';     }      /**      * Get HTML wrapper for active text.      *      * @param  string  $text      * @return string      */     protected function getActivePageWrapper($text)     {         return '&lt;li class=\"pg now\"&gt;&lt;span&gt;'.$text.'&lt;/span&gt;&lt;/li&gt;';     }      /**      * Get a pagination \"dot\" element.      *      * @return string      */     protected function getDots()     {         return $this-&gt;getDisabledTextWrapper('...');     }      /**      * Get the current page from the paginator.      *      * @return int      */     protected function currentPage()     {         return $this-&gt;paginator-&gt;currentPage();     }      /**      * Get the last page from the paginator.      *      * @return int      */     protected function lastPage()     {         return $this-&gt;paginator-&gt;lastPage();     } }   在 Blade 內利用 with() 配合 paginate 物件即可達成，如以下程式碼。   &lt;ul&gt; @foreach ($items as $item)   &lt;li class=\"item\"&gt;$item&lt;/li&gt; @endforeach &lt;/ul&gt;  {!! with(new \\App\\Pagination\\CustomPresenter($items))-&gt;render() !!}   ","categories": [],
        "tags": ["php","laravel"],
        "url": "https://easoncao.com/custom-pagination-in-laravel-5/",
        "teaser": "https://easoncao.com/assets/images/posts/2017/02/laravel-5.4-work-with-vue-notice/laravel.png"
      },{
        "title": "在 Laravel 中簡易的擴充 Blade Helper function",
        "excerpt":"在 App/Providers/AppServiceProvider.php 檔案內 register() 新增 loader 程式碼。   &lt;?php  namespace App\\Providers;  use Illuminate\\Support\\ServiceProvider;  class AppServiceProvider extends ServiceProvider {     /**      * Bootstrap any application services.      *      * @return void      */     public function boot()     {         //     }      /**      * Register any application services.      *      * @return void      */     public function register()     {         // Reigister each helper files         foreach (glob(app_path().'/Helpers/*.php') as $filename){             require_once($filename);         }      } }   搜尋 config/app.php 中的 providers 陣列，確認有正確載入 AppServiceProvider。   'providers' =&gt; [      /*      * Application Service Providers...      */     App\\Providers\\AppServiceProvider::class,  ]   在 app/Helpers/ 內新增自訂的 helper function 即可。(注意不要與官方提供的 helper function 衝突)   Helper function 可以很方便的用來像自訂時間顯示格式   app\\Helpers\\TimeElapsedString.php   &lt;?php  /**  * Get time eplapsed string (4 months, 2 weeks, 3 days, 1 hour, 49 minutes, 15 seconds ago)  *  * Example:  *     echo time_elapsed_string('2013-05-01 00:22:35');  *     echo time_elapsed_string('@1367367755'); # timestamp input  *     echo time_elapsed_string('2013-05-01 00:22:35', true);  // get full string  *  * @param  Datetime  $datetime  * @param  boolean   $full  * @return string  */ function time_elapsed_string($datetime, $full = false) {     $now = new DateTime;     $ago = new DateTime($datetime);     $diff = $now-&gt;diff($ago);      $diff-&gt;w = floor($diff-&gt;d / 7);     $diff-&gt;d -= $diff-&gt;w * 7;      $string = array(         'y' =&gt; 'year',         'm' =&gt; 'month',         'w' =&gt; 'week',         'd' =&gt; 'day',         'h' =&gt; 'hour',         'i' =&gt; 'minute',         's' =&gt; 'second',     );     foreach ($string as $k =&gt; &amp;$v) {         if ($diff-&gt;$k) {             $v = $diff-&gt;$k . ' ' . $v . ($diff-&gt;$k &gt; 1 ? 's' : '');         } else {             unset($string[$k]);         }     }      if (!$full) $string = array_slice($string, 0, 1);     return $string ? implode(', ', $string) . ' ago' : 'just now'; }   在 Blade 內只要使用   {{ time_elapsed_string($time) }}   即可很容易的顯示出自訂的時間格式。   當然，利用寫為 Service 能夠將容易重用的 method 自訂為 Helper function。   以下是用於自訂 Response json 格式的 Helper function 範例   app\\Helpers\\Response.php   &lt;?php  /**  * Response messages json format  *  * @param  integer  $code  * @param  string   $messages  * @param  array    $extend  * @return \\Illuminate\\Http\\Response  */ function responseJSON($code, $messages, $extend = []) {     $data = [         'code'  =&gt;  $code,         'messages'  =&gt;  $messages,     ];      return response()-&gt;json(array_merge($data, $extend)); }   另一種作法則是透過 composer.json 設定 autoload 載入自訂的 Helper，   缺點則是較為缺乏彈性，若有多個 Helper 需要新增較不易管理及修改。   在 composer.json 中找到 autoload 選項後新增   \"autoload\": {     \"files\": [         \"app/BladeHelper.php\"     ] },   並且新增 app/BladeHelper.php 檔案，在裡面新增自訂的 Helper function 即可。   ","categories": [],
        "tags": ["php","laravel"],
        "url": "https://easoncao.com/extend-blade-helper-function-in-laravel/",
        "teaser": "https://easoncao.com/assets/images/posts/2017/02/laravel-5.4-work-with-vue-notice/laravel.png"
      },{
        "title": "Laravel 5.4 版使用官方內建 Vue.js 入門開發的一些注意事項",
        "excerpt":"         Laravel 5.4 最明顯由原本的預設自動化整合由 gulp 更換為 webpack，   同時 Laravel Elixir 也換成 Laravel Mix，   並且也整合 Vue.js 至官方預設的 Component，   如果不用官方 VM 開發的話過程中真的蠻容易踩不少雷。   安裝   安裝過程不詳細贅述，詳見官方文件。   laravel new app npm install   執行 npm run dev 遇到錯誤   ERROR  Failed to compile with 5 errors  These dependencies were not found in node_modules:  * ../fonts/bootstrap/glyphicons-halflings-regular.eot * * ../fonts/bootstrap/glyphicons-halflings-regular.woff2 * * ../fonts/bootstrap/glyphicons-halflings-regular.woff * * ../fonts/bootstrap/glyphicons-halflings-regular.ttf * * ../fonts/bootstrap/glyphicons-halflings-regular.svg   主要是 bootstrap-scss load glyphicons fonts 發生路徑問題，   如果翻一下 node_modules/bootstrap-sass/assets/stylesheets/bootstrap/_variables.scss ，   在 81 行開始可以找到這邊，   // [converter] If $bootstrap-sass-asset-helper if used, provide path relative to the assets load path. // [converter] This is because some asset helpers, such as Sprockets, do not work with file-relative paths. $icon-font-path: if($bootstrap-sass-asset-helper, \"bootstrap/\", \"../fonts/bootstrap/\") !default;   主要是 $icon-font-path 沒辦法正確的指定 bootstrap 正確的路徑，這個問題有三個解法，           啟用 bootstrap-scss 內建的修正 function (推薦)       可以直接開啟 resources/assets/sass/_variables.scss 後新增       bootstrap-sass-asset-helper: true;           給予絕對路徑       開啟 resources/assets/sass/_variables.scss 後新增一行指定 glyphicons 的絕對路徑       $icon-font-path: /path/of/app/node_modules/bootstrap-sass/assets/fonts/bootstrap/           取消整合 bootstrap       開啟 webpack.mix.js 後，將 .sass('resources/assets/sass/app.scss', 'public/css'); 刪除       const { mix } = require('laravel-mix');  /* |-------------------------------------------------------------------------- | Mix Asset Management |-------------------------------------------------------------------------- | | Mix provides a clean, fluent API for defining some Webpack build steps | for your Laravel application. By default, we are compiling the Sass | file for the application as well as bundling up all the JS files. | */  mix.js('resources/assets/js/app.js', 'public/js')    .sass('resources/assets/sass/app.scss', 'public/css');   用範例的 Vue components 動不了   出現 Uncaught TypeError: Cannot read property 'csrfToken' of undefined   在 app.js (bootstrap.js) 被載入前預先在 Blade 內定義以下程式即可解決。   &lt;!-- Scripts --&gt; &lt;script&gt; window.Laravel = &lt;?php echo json_encode([ 'csrfToken' =&gt; csrf_token() ]); ?&gt;  &lt;/script&gt;   Blade 的程式碼大致上如下   &lt;div id=\"app\"&gt;     &lt;example&gt;&lt;/example&gt; &lt;/div&gt;   &lt;!-- Scripts --&gt; &lt;script&gt; window.Laravel = &lt;?php echo json_encode([ 'csrfToken' =&gt; csrf_token() ]); ?&gt; &lt;/script&gt;  &lt;script src=\"{{ asset('js/app.js') }}\"&gt;&lt;/script&gt;   問題在於如果沒有跑過 php artisan make:auth 的話，   在 Laravel 5.4 預設 resources/assets/js/bootstrap.js 內中有使用到 axios ，   其中注意 'X-CSRF-TOKEN': window.Laravel.csrfToken。   22 /** 23  * We'll load the axios HTTP library which allows us to easily issue requests 24  * to our Laravel back-end. This library automatically handles sending the 25  * CSRF token as a header based on the value of the \"XSRF\" token cookie. 26  */ 27 28 window.axios = require('axios'); 29 30 window.axios.defaults.headers.common = { 31     'X-CSRF-TOKEN': window.Laravel.csrfToken, 32     'X-Requested-With': 'XMLHttpRequest' 33 };   window.Laravel 則是是透過使用 make:auth 才會產生出的，   並且定義在 src/Illuminate/Auth/Console/stubs/make/views/layouts/app.stub 內，   引述官方文件   To use the component in your application, you may simply drop it into one of your HTML templates. For example, after running the `make:auth` Artisan command to scaffold your application's authentication and registration screens, you could drop the component into the home.blade.php Blade template   詳細的程式碼可以參考github commit   ","categories": [],
        "tags": ["php","laravel","vuejs"],
        "url": "https://easoncao.com/laravel-5.4-work-with-vue-notice/",
        "teaser": "https://easoncao.com/assets/images/posts/2017/02/laravel-5.4-work-with-vue-notice/laravel.png"
      },{
        "title": "在 Linux 底下刪除以連接符號 - (dash) 開頭的檔案",
        "excerpt":"在 Linux 使用 CLI 刪除檔案直覺想到的就是 rm 指令，   是非常高頻率使用的程式，像刪除一般檔案的指令   rm yourfile   Linux 預裝程式多數提供許多參數選項，只要加上 - 符號 (英文為dash) 以及對應的選項就能發揮對應的功能，   像是 -r 可以讓 rm 這隻程式 recursive，-f 代表 force，   當放一起成為 -rf 參數時可以刪除整個目錄，但使用不慎很可能會發生難以想像的破壞，   rm -rf /myFolder   但如果檔案開頭是以 - 符號開始呢？例如(-sample.txt)   刪除檔案這種乍看簡單的問題就瞬間變很難了，一般直覺的作法是這樣，   rm -sample   但是這樣就會被 rm 認為是加上 -sample 選項，但 rm 並沒有提供對應的功能，而不是以檔名解析，   所以你可能會想到利用 \\ 跳脫，   rm \\-sample   其實這有點像是換行而已，但很遺憾的是這樣也沒辦法讓 rm 正常解析為檔名，   正確作法是加上兩個 dash 符號 --   rm -- -sample   這樣就能正常刪除了，   或是以這種方式也能夠刪除 (給予絕對路徑)   rm ./-sample  ","categories": [],
        "tags": ["Linux"],
        "url": "https://easoncao.com/remove-filename-start-with-dash-in-linux/",
        "teaser": null
      },{
        "title": "D-Link DSL-7740C 啟用 SNMP",
        "excerpt":"一般光纖 100M/40M 家用網路的使用者若想要進行網路流量、路由器監控，   可以在中華電信的 DSL-7740C 啟用 SNMP Agent 達到監控的目的。   首先進入 DSL-7740C 設定畫面，相關帳號密碼可詳閱 上一篇的設定，           進入 Advanced &gt; SNMP 頁面       將 SNMP Agent 設為 enable，並自行選擇是否要啟用 SNMP Trap 。                         DSL-7740C SNMP setting page                    注意 MAINTENANCE &gt; ACL 頁面       Service settings 底下的 Service，找到 SNMP 將 LAN 一欄必須勾選 enable 才能在區域網路連線中使用 SNMP 協定       (恰巧用 nmap 發現預設 ACL 會將 SNMP 過濾，踩了很久的雷)                         DSL-7740C ACL setting page            測試是否正確設定：   以下範例為使用 snmpwalk 進行尋訪 192.168.1.1, version 2c, community 為 public。   snmpwalk -c public -v 2c 192.168.1.1   執行結果：            ","categories": [],
        "tags": ["dlink","hinet"],
        "url": "https://easoncao.com/enable-snmp-agent-on-dlink-dsl-7740c/",
        "teaser": null
      },{
        "title": "從 vim pathogen 無痛轉移到 vundle",
        "excerpt":"取得 Vundle   git clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim   在 .vimrc 內啟用 vundle 及 要安裝的Plugins   \" be iMproved, required set nocompatible  \" required filetype off  \" set the runtime path to include Vundle and initialize set rtp+=~/.vim/bundle/Vundle.vim call vundle#begin()  \" alternatively, pass a path where Vundle should install plugins \"call vundle#begin('~/some/path/here')  \" let Vundle manage Vundle, required Plugin 'VundleVim/Vundle.vim'   相關範例可以參考我的vim設定檔得到更多資訊   安裝 Plugins   打開 vim 後運行 :PluginInstall   Reference:      我的vim設定檔   Vundle   Swapping Pathogen for Vundle   ","categories": [],
        "tags": ["vim"],
        "url": "https://easoncao.com/migrate-vim-pathogent-to-vundle/",
        "teaser": null
      },{
        "title": "SVM Quickstart",
        "excerpt":"Reference:      piaip 的 (lib)SVM 簡易入門   Support Vector Machine 簡介   ","categories": [],
        "tags": ["svm","machine-learning"],
        "url": "https://easoncao.com/svm-quickstart/",
        "teaser": null
      },{
        "title": "/etc/fstab file Quick view",
        "excerpt":"What is /etc/fstab      The fstab(5) file can be used to define how disk partitions, various other block devices, or remote filesystems should be mounted into the filesystem.    /etc/fstab 檔案是Linux kernel在開機過程能夠得知有哪些裝置必須被掛載 (mount) 的重要系統檔案。   檔案格式如下：   # &lt;device&gt;             &lt;dir&gt;         &lt;type&gt;    &lt;options&gt;             &lt;dump&gt; &lt;fsck&gt; /dev/sda1              /             ext4      defaults,noatime      0      1 /dev/sda2              none          swap      defaults              0      0 /dev/sda3              /home         ext4      defaults,noatime      0      2      &lt;device&gt;: 要被掛載的實體裝置，或是遠端的檔案系統。   &lt;dir&gt;: 要掛載的目錄，必須是先建立(mkdir)後才能正確掛載。   &lt;type&gt;: 檔案系統格式，如ext4、ext3、xfs、fat32等等。   &lt;options&gt;: 掛載選項，一般檔案系統在掛載時至少包含一種掛載選項(ro or rw)，ro 就是 read-only 僅讀取， rw 就是 read-write 可讀可寫，            defaults: use default options: rw, suid, dev, exec, auto, nouser, and async.       noauto: do not mount when “mount -a” is given (e.g., at boot time)       user:   allow a user to mount       owner:  allow device owner to mount       nofail: do not report errors for this device if it does not exist.       comment or x- for use by fstab-maintaining programs           UUID   一般檔案系統在完成格式化後會產生一組識別碼，稱為UUID (Universally Unique Identifier)，透過UUID掛載的方式能避免裝置因為更換順序(e.g. 更換硬碟的SATA插線順序)，造成原本掛載的設定因為裝置順序不同，產生跟原本預期設定不同的錯誤。   可以使用 `lsblk -f` 或是 `file -s &lt;device&gt;` 輕鬆查到裝置的UUID。   $ lsblk -f  NAME   FSTYPE   LABEL      UUID                                 MOUNTPOINT sda ├─sda1 vfat     ESP        3A32-950C                            /boot/efi ├─sda2 vfat     DIAGS      BCA2-19D3 ├─sda3 ├─sda4 ntfs     WINRETOOLS ECFAA35AFAA31FB6 ├─sda5 ntfs                C03E97DA3E97C7B4 ├─sda6 ntfs                B03C63223C62E2B8 ├─sda7 ntfs                DEC05B4FC05B2D51 ├─sda8 ext4                c3b19071-7163-41ea-9a8c-4069deb13649 / └─sda9 ntfs     PBR Image  D052AA0C52A9F6FE   $ sudo file -s /dev/sda8 /dev/sda8: Linux rev 1.0 ext4 filesystem data, UUID=c3b19071-7163-41ea-9a8c-4069deb13649 (needs journal recovery) (extents) (large files) (huge files)   掛載方式也很簡單，在 /etc/fstab 內使用 UUID= 即可。   # &lt;device&gt;                                &lt;dir&gt; &lt;type&gt; &lt;options&gt;                         &lt;dump&gt; &lt;fsck&gt; UUID=0a3407de-014b-458b-b5c1-848e92a327a3 /     ext4   rw,relatime,discard,data=ordered   0      1 UUID=b411dc99-f0a0-4c87-9e05-184977be8539 /home ext4   rw,relatime,discard,data=ordered   0      2 UUID=f9fe0b69-a280-415d-a03a-a32752370dee none  swap   defaults                           0      0   Label   如果裝置在格式化時有設定 Label，也能使用 LABEL= 進行掛載。   # &lt;device&gt;      &lt;dir&gt; &lt;type&gt; &lt;options&gt;                                                                                            &lt;dump&gt; &lt;fsck&gt; LABEL=EFI       /boot vfat   rw,relatime,fmask=0022,dmask=0022,codepage=437,iocharset=iso8859-1,shortname=mixed,errors=remount-ro 0      2 LABEL=SYSTEM    /     ext4   rw,relatime,discard,data=ordered                                                                     0      1 LABEL=DATA      /home ext4   rw,relatime,discard,data=ordered                                                                     0      2 LABEL=SWAP      none  swap   defaults                                                                                             0      0   Reference:      archlinux - fstab   fstab(5)   UUID   ","categories": [],
        "tags": ["linux"],
        "url": "https://easoncao.com/fstab-quick-view/",
        "teaser": null
      },{
        "title": "解析 .well-known 資料夾",
        "excerpt":"What is /.well-known/ ?   繼 Let’s Encrypt 提供公眾能夠使用免費SSL簽章服務，在安裝過程發現會產生 .well-known 資料夾，於是好奇之下就展開了解答尋找之路。   .well-known 目錄正式在 RFC5785 被提出，   隨著 WWW 的 Protocol 越來越多，   若 Server 與 Client 雙方需要進行資訊交換時通常必須建立在 TCP / IP 的基礎上進行，常見的作法像是 HTTPS 以 443 Port 進行資訊上的交換、Handshake等，   即使是 HTTP / HTTPS Protocol ，共同定義的 Header 無法提供更足夠的資訊滿足不同 Client-side 的需求，   更何況網際網路的傳輸中，一個 Packet 長度基本上是有限的，單純的 Server-side application 越來越無法現今網際網路的環境，   Client 要足以得知 Server side 的 metadata ，便共同定義了 .well-known 是被許可的子目錄及 URI。   常見的例子像是：      /.well-known/acme-challenge/ : Let’s Encrypt 用於驗證憑證所有者的有效性，ACME 指的是 Automatic Certificate Management Environment   /.well-known/assetlinks.json : Digital Asset Links，像是用於網站告知 Android 系統應該用什麼樣的 app 開啟   /.well-known/apple-app-site-association : Universal Links，類似 Digital Asset Links，主要用於 iOS 識別使用的 metadata 。   Reference:      For what is the “.well-known”-folder?   The “.well-known” directory on webservers (aka: RFC 5785)   ","categories": [],
        "tags": ["networking"],
        "url": "https://easoncao.com/what-is-well-known-folder/",
        "teaser": null
      },{
        "title": "AWS Certified Solution Architect Associate 認證考試準備及心得",
        "excerpt":"                  AWS Solutions Architect Associate            關於考前準備   自考試之前其實我完全沒有過 AWS ，直到去年年底才開始接觸並且使用 AWS 平台，   準備這張大概花了一個月的時間準備，希望能給有意願準備這張認證的人一點參考方向。   認證有效期   因為雲端技術不斷的推陳出新，Amazon Web Services 設定這張認證的有效期為兩年。   費用   考試費用為 150 USD 並不便宜，建議大家可以準備充裕點再去考試才不會白白浪費了錢。   測驗語文、形式、題數及時間      考試語言：我報名時選擇的是英文 (不過現在也有提供中文的試卷)   考試形式：選擇題、多選題   考試題數：約 60 題   考試時間：80 分鐘   及格分數：AWS 認證會依照每次考試的統計分佈進行篩選，當然及格分數抓在 70% 比較保險。   範例試題   作答完會詢問是否要填寫問卷，我直接跳過了。   重點準備   準備考試前建議先了解一次考試的幾個大方向，考試官方頁面可以參考 AWS 官方的認證頁面 ，      (1.0) Designing highly available, cost-efficient, fault-tolerant, scalable systems (60%)   (2.0) Implementation/Deployment (10%)   (3.0) Data Security (20%)   (4.0) Troubleshooting (10%)   詳細內容可以讀過一次 Blueprint 得到更詳細的資訊。   其中我個人考試的經驗，第一項 HA 及 第四項 Security 真的非常重要，當然考什麼樣的應用還是運氣成份為重，   尤其像我考的時候 IAM 的部份考蠻大的比重，連 Active Directory 都出現了，Snapshot、EBS Encryption 等等也考得我滿身汗，   或是像 ec2 instance 如果應用於 MySQL database 的情境，如何同時兼顧 cost-efficient 及 fault-tolerant 等等問題，這部份除了會有用 AWS 的 Solutions 外可能也會出現像是使用 RAID 等等的情境。   如果像我一樣完全沒有使用過 AWS ，非常推薦趁 Udemy 有特價的時候一次買好 acloud guru 推出的 AWS Certified Solutions Architect - Associate 2017，   能夠有系統性的幫助入門了解整個 AWS Cloud ，而且 Udemy 時不時有特價及優惠碼，一次購入原價 NTD$ 7, 000 的課程 NTD$ 300 左右就可以買到。   利用 Udemy App ，我每天早上坐捷運的時候就看個一兩個片段，累積半個月下來其實能夠很有效的理解整個 AWS Cloud 。   而且 Solution Architect Associate 的考試範圍非常的廣，廣到一個非常的難以想像，且考試會有非常多的使用情境，個人考試當天做試題也是戰戰兢兢的慎選每個答案。   推薦大家仔細閱讀過幾個重點服務的 FAQ 常見問答集，有些問題很容易被考出來。      VPC (Internet Gateway / NAT 會出現在 Troubleshooting 的問題)   EC2 (AMI / AutoScaling / ELB / ALB / Spot, Reserved, On-demand 差別)   EBS (Snapshot)   S3 (Glacier / RRS / IA / Eventual Consistency)   IAM (User / Group / Role)   RDS   SQS   DynamoDB   Route53 (Alias / Zone Apex / Routing Policies)   Whitepaper   很多心得可能都推薦大家讀 Whitepaper ，但是 Whitepaper 其實內容不少，所以我考前也是抓 Security Whitepaper 大略看看而已，   當然還是推薦大家仔細閱讀裡面的內容，在解決架構上的設計能有一定的幫助。      AWS whitepapers   AWS Overview   AWS Security Best Practices   考試過程建議大家遇到太長或是不懂的題目先做個 Mark 跳過，先把握拿到比較容易拿的分數，做過一遍後再回來檢查也會比較沒壓力。   最後，祝大家考試順利。   ","categories": [],
        "tags": ["aws","certificate"],
        "url": "https://easoncao.com/AWS-Certified-Solution-Architect-Associate-Preparation/",
        "teaser": "https://easoncao.com/aws-saa-cert.png"
      },{
        "title": "Memory Management and Paging Quick Note",
        "excerpt":"對於 Paging 的疑惑   在讀清大作業系統開放式課程 Memory Management - Paging 一章時對於裡面一個範例產生了疑問，在這邊簡單紀錄一下。      Given 32 bits logical address, 36 bits physical address and 4KB p    age size, what does it means?       Page table size = 2^32 / 2^12 = 2^20 entries   Max program memory : 2^32 = 4GB   Total physical memory size: 2^36 = 64GB   Number of bits for page number: 2^20 pages, 20bits   Number of bits for frame number: 2^36 / 2^12 = 2^24, 24bits   Number of bits for page offset: 4KB page size, 2^12, 12bits   在閱讀這些資料的時候不免疑惑，為什麼是 2^36 Bytes (64GB) 的 physical memory，不是 36 bits logical address， 應該可用的記憶體應該不是 2^36 bits 嗎，而且 Max program memory 可以到 4GB !?   更讓我疑惑的是在計算 Page entries ，明明是不同單位的東西 (32 bits 與 4KB, 4KB 應該是 4096 bytes * 8 = 32768 bits)。   後來經過一些資料的查詢，發現我對於記憶體的管理上有一些誤解，這邊有提到logical address，注意這邊指的是 address ，   可參考 wikipedia 對於 memory address 的解釋：      the more bits used, the more addresses are available to the computer. For example, an 8-bit-byte-addressable machine with a 20-bit address bus (e.g. Intel 8086) can address 2^20 (1,048,576) memory locations, or one MiB of memory, while a 32-bit bus (e.g. Intel 80386) addresses 2^32 (4,294,967,296) locations, or a 4 GiB address space. In contrast, a 36-bit word-addressable machine with an 18-bit address bus addresses only 2^18 (262,144) 36-bit locations (9,437,184 bits), equivalent to 1,179,648 8-bit bytes, or 1152 KB, or 1.125 MiB—slightly more than the 8086.    由此可知，代表說一個 physical memory address 對應到的可用空間為 1 byte ，   我們市面上常見的 32 bits 或 64 bits 處理器指的是處理器核心所能存取及表示的最大記憶體位址，各有 2^32 bits 及 2^64 bits 種組合，詳見 [2]。   總結   所謂的 36 bits physical address，可表示實體記憶的位址為 2^36 bits，因為一個位址可用的記憶體空間大小為 1 Byte，共可用的記憶體大小為 2^36 Bytes。   Reference      Memory address   how long is a memory address typically in bits   國立清華大學開放式課程OpenCourseWare(NTHU, OCW) - 作業系統   ","categories": [],
        "tags": ["operating-system"],
        "url": "https://easoncao.com/memory-management-and-paging-quick-note/",
        "teaser": null
      },{
        "title": "AWS Certified Developer Associate 認證考試準備及心得",
        "excerpt":"                  AWS Solutions Architect Associate            關於考前準備   相比前一個 SA 認證，其實沒什麼準備，這樣講好像有點不負責任。的確，因為考試時間跟學校期末考疊在一起，所以沒有像考 Solution Architect Associate 那麼仔細的唸。   題目的範圍考比較多 DynamoDB 及 SDK / API 的使用，如果之前跟我一樣有先考過 Solution Architect Associate 準備起來會比較輕鬆一點。   考試前一定要花點時間了解 DynamoDB 的 Read / Write Provision Throuput 怎麼計算，考試會考非常多的 Global Index / Sencondary Index 相關的問題。   認證有效期   與 Solution Architect Associate 一樣是兩年。   費用   考試費用為 150 USD (建議大家可以準備充裕點再去考試才不會白白浪費了錢)   考試地點   恆逸教育訓練中心有提供 AWS 認證的考試考場，詳細內容可以參考考試報名。   測驗語文、形式、題數及時間      考試語言：英文 (如果英文怕影響作答可以在報名時選擇中文的試卷)   考試形式：選擇題、多選題   考試題數：約 60 題   考試時間：80 分鐘   及格分數：建議及格分數抓在 70% 比較保險。   範例試題   作答完會詢問是否要填寫問卷，我一樣直接跳過了。   考試報名   AWS 認證目前都從 Kryterion (Webassessor) 的界面移轉到 AWS training，可以透過官方的界面進行考試的報名。   重點準備   考試前建議先了解一次考試的幾個大方向，考試官方頁面可以參考 AWS 官方的認證頁面 ，Blueprint (必讀)。      (1.0) AWS Fundamentals (10%)   (2.0) Designing and Developing (40%)   (3.0) Deployment and Security (30%)   (4.0) Debugging (20%)   Professional experience using AWS technology     Hands-on experience programming with AWS APIs   Understanding of AWS Security best practices   Understanding of automation and AWS deployment tools   Understanding storage options and their underlying consistency models   Excellent understanding of at least one AWS SDK   General IT Knowledge     Understanding of stateless and loosely coupled distributed applications   Familiarity developing with RESTful API interfaces   Basic understanding of relational and non-relational databases   Familiarity with messaging &amp; queuing services   如果具備 Solution Architect Associate / Professional 的背景的話來考這個基本上可以省一半的力氣，Developer Associate 著墨在 Architect 的部份不會太多，   AWS Fundamentals，涵蓋 EC2 / VPC / DynamoDB / SWF (Simple Work Flow) / S3 (Consistency read-after-write) / 基本的網路Troubleshooting，建議針對這些 Developer 考試內容內重點使用的服務進行比較詳細的了解。可以透過官方文件及常見問題得到很多相關的資訊。   如果像我過去沒有使用過 AWS 的經驗，可以透過 acloud guru 推出 AWS Certified Developer - Associate 2017 課程 來快速入門，   能夠有系統性的幫助入門了解 AWS 各式各樣的服務，完整的濃縮。(而且 Udemy 時不時有特價及優惠碼)   推薦大家仔細閱讀過幾個重點服務的 FAQ 常見問答集，因為常見的問題確實就是成為考題的必要。      VPC (Internet Gateway / NAT 會出現在 Troubleshooting 的問題)   EC2 (AMI / AutoScaling / ELB / ALB / Spot, Reserved, On-demand 差別)   EBS (Snapshot)   S3 (Glacier / RRS / IA / Eventual Consistency)   IAM (User / Group / Role)   RDS   SQS   SWF   Lambda   API Gateway   DynamoDB (Index)   Route53   Serverless   目前考試內容我個人是沒有看到太多跟 Serverless 相關的問題，但是畢竟使用雲服務 Serverless 是不可避免的一種解決方案，有興趣的話可以多閱讀 Lambda 等服務相關的資訊。   考試內容會比較多著墨在 SDK 的使用，以及一些會使用的 API，同時 DynamoDB 一直是特別要強調一定會出現的。   考試中建議大家遇到太長或是不懂的題目先做標記跳過，先把握拿到比較容易拿的分數，做過一遍後再回來檢查也會比較沒壓力。   祝大家順利通過認證！   ","categories": [],
        "tags": ["aws","certificate"],
        "url": "https://easoncao.com/AWS-Developer-Associate-Preparation/",
        "teaser": "https://easoncao.com/assets/images/aws-da-cert.png"
      },{
        "title": "Fix node.js cannot update to 8.x or other version on ubuntu 16.04",
        "excerpt":"Node.js upgrade issue   When I was working with few projects with latest npm or related dependencies, sometimes we have to upgrade our node.js version in order to jump out of the dependencies hell especially you are migrating to the latest node.js.   However, when I am updating the node.js with the command apt-get upgrade or apt-get install nodejs on ubuntu 16.04 or other linux distrubition. It always telling me that my nodejs is already up-to-date.   Therefore, here are my few notes regarding the upgrade issue and troubleshooting footprint, hope it would be helpful to you:   0. Check the node.js version and download the latest version via package manager   You can use the option -v to check your current node.js version in your system.   node -v   Also, you may try to install/upgrade your node.js via the package manager:   curl -sL https://deb.nodesource.com/setup_8.x | sudo -E bash - sudo apt-get install -y nodejs   If your node.js still stay at the oldest version, please check the next steps.   1. Check /etc/apt/sources.list.d/nodesource.list   If you installed the node.js before, or ran the update command before. In the /etc/apt/sources.list.d/nodesource.list, you may see the following contents:  deb https://deb.nodesource.com/node_5.x trusty main deb-src https://deb.nodesource.com/node_5.x trusty main   If you are cuurently using the version 5.x, congratulations, that’s why your nodejs always telling you that your node.js is up-to-date but it actually not.   Please change the version to 8.x as the example below:  deb https://deb.nodesource.com/node_8.x trusty main deb-src https://deb.nodesource.com/node_8.x trusty main   Now, you can install the latest node.js via the following command (Debian and Ubuntu based Linux distributions).  sudo apt-get update sudo apt-get install -y nodejs   For more detail on other distributions, you can read the document on node.js.   Reference:      Installing Node.js via package manager   ","categories": [],
        "tags": ["nodejs"],
        "url": "https://easoncao.com/fix-nodejs-cannot-update-to-8-on-ubuntu-16-04/",
        "teaser": null
      },{
        "title": "快速建立 ubuntu 應用程式啟動圖示",
        "excerpt":"建立 ubuntu 應用程式啟動圖示   在以下任意目錄建立 .desktop 檔案能夠協助你建立 ubuntu 應用程式啟動圖示      ~/.gnome/apps   ~/.local/share/applications/   /usr/share/applications/   例如: 在 ~/.local/share/applications 建立 myapp.desktop   myapp.desktop   [Desktop Entry] Name=MyApp Comment=Application launcher for my execution Exec=/path/to/executable_file Icon=/path/to/icon Terminal=false Type=Application Categories=Network;   Reference:      ubuntu documentation - UnityLaunchersAndDesktopFiles   ","categories": [],
        "tags": ["ubuntu"],
        "url": "https://easoncao.com/quickly-create-the-ubuntu-application-launch-icon/",
        "teaser": null
      },{
        "title": "設定 zsh 為 tmux 預設的 shell",
        "excerpt":"設定 tmux 使用的 shell   自從從 screen 無痛轉移到 tmux 後，tmux 強大的功能性實在是令人愛不釋手，這邊筆記一下如何更換 tmux 啟動新的 session 時預設的 shell 。   in ~/.tmux.conf or . Works on Fedora.   使用編輯器開啟 ~/.tmux.conf，如果沒有可以新增一個。或是修改 /etc/tmux.conf 設定所有使用者預設的 tmux 設定檔。   新增以下內容:  set-option -g default-shell /bin/zsh   如果不是使用 zsh ，也可以將 /bin/zsh 換成慣用的 shell，例如: /bin/bash、/bin/csh 等。   Reference:      tmux   How can I make tmux use my default shell   ","categories": [],
        "tags": ["Linux"],
        "url": "https://easoncao.com/set-the-zsh-as-the-default-shell-for-tmux/",
        "teaser": null
      },{
        "title": "Python threading.Thread 錯誤筆記",
        "excerpt":"最近在試著用 Python 寫多線程的程式遇到一點小狀況，範例程式如下：   import time import threading from multiprocessing import Queue  def subProgram(queue):     for i in range(10):         queue.put(i)  def main():      queue = Queue()      thread = threading.Thread(target=subProgram, args=(queue))     thread.start()      time.sleep(2)     while not queue.empty():         print queue.get()  main()   看似沒問題的程式碼，執行後卻發生錯誤：   Exception in thread Thread-1: Traceback (most recent call last):   File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner     self.run()   File \"/usr/lib/python2.7/threading.py\", line 754, in run     self.__target(*self.__args, **self.__kwargs) TypeError: subProgram() argument after * must be an iterable, not Queue   在 stackoverflow 找到了類似的問題跟解法：      You need to add , after s sending just s to args=() is trying to unpack a number of arguments instead of sending just that single arguement.    但是因為對 Python 太不熟了，惡補了一下基本語法跟翻了一下手冊，確定 args 是 tuple 的型態      class threading.Thread(group=None, target=None, name=None, args=(), kwargs={}) This constructor should always be called with keyword arguments. Arguments are:          group should be None; reserved for future extension when a ThreadGroup class is implemented.     target is the callable object to be invoked by the run() method. Defaults to None, meaning nothing is called.     name is the thread name. By default, a unique name is constructed of the form “Thread-N” where N is a small decimal number.     args is the argument tuple for the target invocation. Defaults to ().     kwargs is a dictionary of keyword arguments for the target invocation. Defaults to {}.       If the subclass overrides the constructor, it must make sure to invoke the base class constructor (Thread.init()) before doing anything else to the thread.    tuple 如果只有單一元素 (element) 的話必須加個,逗號才行，不然就會被解讀成單一物件。   參考以下範例會比較了解：   &gt;&gt;&gt; a = (111,222) &gt;&gt;&gt; a (111, 222) &gt;&gt;&gt;  &gt;&gt;&gt; a = (111, 222) &gt;&gt;&gt; a (111, 222) &gt;&gt;&gt; b = (111) &gt;&gt;&gt; b 111 &gt;&gt;&gt; c = (111,) &gt;&gt;&gt; c (111,)   可以看到 b = (111) 被解讀成 111 了，這並不是預期的狀況，改成 c = (111, ) 就會正常解析成 tuple 型態了。   同理，只要在   thread = threading.Thread(target=subProgram, args=(queue))   args=(queue) 補上 , 符號就解決這項錯誤：   thread = threading.Thread(target=subProgram, args=(queue,))   最後修正的程式如下：   import time import threading from multiprocessing import Queue  def subProgram(queue):     for i in range(10):         queue.put(i)  def main():      queue = Queue()      thread = threading.Thread(target=subProgram, args=(queue,))     thread.start()      time.sleep(2)     while not queue.empty():         print queue.get()  main()   Reference:      Thread Objects   stackoverflow  ","categories": [],
        "tags": ["python"],
        "url": "https://easoncao.com/fix-python-thread-args-error-note/",
        "teaser": null
      },{
        "title": "Laravel PHP 優化之路：效能瓶頸的解決方案",
        "excerpt":"前言   最近在開發一些後端專案程式的時候，遇到了一些效能上的挑戰，從功能實作後到重構整個過程蠻有趣的，藉由文字的紀錄自己的優化過程。   案例一：檢查資料庫內重複的資料   在一次的案例中，必須檢查使用者新增的資料在資料庫內是不是有重複的內容，這邊以簡單的留言系統為例，所以就寫了這樣的邏輯並且抽離出 checkCommentIsDuplicate 這樣的 method ，用來檢查該筆資料是不是有在資料表內重複：   foreach ($newComments as $key =&gt; $comment) {     // Check the comment is duplicate in database     if ($this-&gt;CommentManager-&gt;checkCommentIsDuplicate($comment)) {         // Do something, like remove the item from array         unset($newComments[$key]);     } }   一開始暴力解都是用以下作法：   class CommentManager {     public function checkCommentIsDuplicate($insertComment)     {         $condition = [             ['title', '=', $insertComment['title']],             ['content', '=', $insertComment['content']],         ];          return (Comment::where($condition)-&gt;count() &gt; 0);     } }   當然，在本機的資料庫跑得好好的，一切都很理想，連線既沒有延遲，更不用煩惱 PHP Timeout 的問題。   一佈署到 AWS 上，資料庫有小於 100~500 筆的資料看似一切還好，一插入 1000 筆資料問題就來了。   因為 AWS 的 RDS (Relational Database Service) 與 PHP 程式間的連線會有延遲，一個 SQL 查詢其實就是非常昂貴的運算資源。   假設資料庫內有 500 筆資料，今天我要新增 300 筆資料，如果要檢查新增的資料是不是與資料庫有重複。這樣每一筆新增的資料，就要下一次 SQL 查詢，這樣至少要產生 300 次 SQL 查詢，就算資料庫可接受的連線時間，PHP 還是很快的就超過預設的 30 秒執行時間，逾時中止了。   就算調大執行時間，新增的資料如果成長成 1000 筆、甚至 5000 呢？就算程式跑得完使用者不見得等的下去。   於是乎，就會想到，我可以一次查詢後在程式內檢查啊！於是乎程式又被改成了這樣：   class CommentManager {     public function checkCommentIsDuplicate($currentCommentInDB, $insertComment)     {         foreach ($currentCommentInDB as $currentComment) {             if ($currentComment['title'] == $insertComment['title'] &amp;&amp; $currentComment['content'] == $insertComment['content']) {                 return true;             }         }          return false;     } }   開心的改好之後在測試機上測試一下，嗯，500 筆好像還行。   但是當新增的資料量超過 1000 筆，當資料庫內有 4000 筆以上的資料，可能的效能瓶頸又出現了。   因為每一筆資料必須與查詢後的 4000 筆資料進行循序比較，這樣最壞的情況 (都沒有重複的資料)，需要比較 1000 * 4000 次，這個運算量還是挺費時的。   善用 Hashing 解決大量資料的效能瓶頸   於是，不外乎就試著將資料表內的每筆資料雜湊後作為 Hash key，建立 Hash table，利用這個 Hash table 進行 duplicate 的檢查，這樣大幅減少比較的次數，沒有碰撞的情況下(也不應該會碰撞，資料庫內的資料寫入時不會 Duplicate )，比較的時間複雜度可以優化到 O(1)，在本機的測試環境連接 ap-northeast-1 的 RDS (完全能明顯感受到資料庫連線延遲) 得到不錯的執行時間。   測試環境：     CPU: Intel Core i7-4510U (2.00 GHz x 4)   Memory: 8 GB   OS: ubuntu 16.04 LTS x64 (Linux 4.4.0-97-generic #120-Ubuntu SMP Tue Sep 19 17:28:18 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux)   PHP 7.0.22-0ubuntu0.16.04.1 (cli) ( NTS )   實測後，新增 4615 筆資料，並與與資料庫內 9230 筆進行 Duplicate 進行比較，整體從使用者送出 Request 至 Response 執行時間約 6.558937 s，因為是在開發端進行連線，連接到 RDS 有蠻大的延遲，佈署到 AWS 上後應該可以更快。   實測本機單元測試的結果，使用 Laravel 內建的 Factory 產生 90010 筆測試資料：      [1st] stress test: compare 90010 data in database, total use 0.000049 s.   [2nd] stress test: compare 90010 data in database, total use 0.000004 s.   除了第一次產生 Hash table 稍微耗時需 0.000049 s ，第二次開始的執行時間就會明顯降低。   基本上 PHP 的 Array 就是一個很棒能實作 Hash table 的方式，執行速度非常的不錯，以下是實作的概念性程式碼：   class CommentManager {     public function __construct()     {         $this-&gt;CommentHashTable = null;     }      /**      * Check the comment is duplicated in database or not      *      * $currentCommentInDB: the comments in the database.      * $insertComment: the comment will insert, check the      *                 duplication here.      *      * @param  \\App\\Models\\Comment $currentComment      * @param  array $insertComment      * @return bool      */     public function checkCommentIsDuplicate($currentCommentInDB, $insertComment)     {         $hashItem = ['title', 'content'];          if ($this-&gt;CommentHashTable == null) {              // Normalize the $currentCommentArray             if ($currentCommentInDB-&gt;count() == 0) {                 $currentCommentArray = [];             } else if ($currentCommentInDB-&gt;count() == 1) {                 $currentCommentArray = [ $currentCommentInDB-&gt;toArray() ];             } else {                 $currentCommentArray = $currentCommentInDB-&gt;toArray();             }              $this-&gt;createCommentHashTable($currentCommentArray, $hashItem);         }          $insertCommentHashKey = $this-&gt;HashKey($insertComment, $hashItem);          return isset($this-&gt;CommentHashTable[$insertCommentHashKey]);     } }   案例二：後端程式使用 Eloquent ORM Relationships 進行資料多重關聯查詢   另一個效能瓶頸在於 Laravel 的 Relationships，Laravel 5.5 一樣提供了 Eloquent relationships 方便查詢不同資料表內的資訊，以下是使用 Eloquent model 常見的操作：   class UserController extends Controller {     public function getLatestUser()     {         $users = User::orderBy('id', 'desc')-&gt;take(1000)-&gt;get();          foreach ($users as $index =&gt; $user) {             $users[$index]['id'] = $user-&gt;id;             $users[$index]['name'] = $user-&gt;name;             $users[$index]['email'] = $user-&gt;email;             $users[$index]['updated_at'] = $user-&gt;updated_at;             $users[$index]['created_at'] = $user-&gt;created_at;             $users[$index]['recent_post_id'] = $user-&gt;posts-&gt;first()-&gt;id;             $users[$index]['recent_comment_id'] = $user-&gt;comments-&gt;first()-&gt;id;             $users[$index]['recent_orders_id'] = $user-&gt;orders-&gt;first()-&gt;id;         }     } }   因為 Eloquent 動態 Property 屬於 lazy loading 的特性，Laravel Eloquent relationships 的 SQL 查詢是在 foreach 迴圈內每次執行時被建立的。      Dynamic properties are “lazy loading”, meaning they will only load their relationship data when you actually access them. Because of this, developers often use eager loading to pre-load relationships they know will be accessed after loading the model. Eager loading provides a significant reduction in SQL queries that must be executed to load a model’s relations.    也就是說上述的程式如果被轉譯成 SQL 查詢會像是這樣：   select * from users  select id from posts where id = 1 select id from comments where id = 1 select id from orders where id = 1  select id from posts where id = 2 select id from comments where id = 2 select id from orders where id = 2  select id from posts where id = 3 select id from comments where id = 3 select id from orders where id = 3  ... 略   大致列舉查詢的語句，完整語句應該與實際 Laravel 轉譯的結果有些不同。   可見的是，如果今天有 1000 筆的 User 和其關聯性的資料(post, comment, order)，就必須得產生至少 1000 * 3 次的關聯查詢，這樣的做法在 SQL 建立連線和查詢的過程是十分耗時的。   使用 Eager Loading 減少 SQL 查詢的次數   Laravel 5.5 提供了 Eager Loading 可以協助平衡這樣的效能瓶頸，使用 with() 配合 Eloquent relationships 的優點在於資料的查詢方式是一次性的，Laravel 會預先將所有關聯的資料一次性的完成查詢，避免上述迴圈執行時會再重新建立一個新的 SQL 查詢連線，修改後的邏輯大致上是這樣：   class UserController extends Controller {     public function getLatestUser()     {         $users = User::orderBy('id', 'desc')-&gt;with(['posts', 'comments', 'orders'])-&gt;take(1000)-&gt;get();          foreach ($users as $index =&gt; $user) {             $users[$index]['id'] = $user-&gt;id;             $users[$index]['name'] = $user-&gt;name;             $users[$index]['email'] = $user-&gt;email;             $users[$index]['updated_at'] = $user-&gt;updated_at;             $users[$index]['created_at'] = $user-&gt;created_at;             $users[$index]['recent_post_id'] = $user-&gt;posts-&gt;first()-&gt;id;             $users[$index]['recent_comment_id'] = $user-&gt;comments-&gt;first()-&gt;id;             $users[$index]['recent_orders_id'] = $user-&gt;orders-&gt;first()-&gt;id;         }     } }   在 Query 內使用了 with(['posts', 'comments', 'orders']) ，這樣 Laravel 就會在執行查詢時也查詢關聯性的資料。   依照文件上的解釋這樣 Laravel 透過 Eloquent ORM 轉譯成 SQL 語句查詢時會執行像這樣的語句：   select * from users select * from posts where id in (1, 2, 3, 4, 5, ...) select * from comments where id in (1, 2, 3, 4, 5, ...) select * from orders where id in (1, 2, 3, 4, 5, ...)   這樣將原本的查詢縮減到非常小的次數，同時降低資料庫連線建立的成本和避免連線建立延遲放大 PHP 程式等待的速度。   經過這樣小小的更正後，約 600 ~ 1000 筆的資料從原本的處理速度約 10 ~ 20s 不等下降至 0.5ms ~ 2s，這點微妙的時間差就能讓使用者體驗有完全不一樣的感受。使用 Eager Loading 也能減少伺服器查詢的耗時及次數，若有遇到同樣的效能瓶頸可以試著使用這樣的方式來達到效能使用上的平衡。   Reference:      Relationship Methods Vs. Dynamic Properties   Laravel Eloquent Eager Loading   ","categories": [],
        "tags": ["php","laravel"],
        "url": "https://easoncao.com/php-Laravel-optimization-boost-your-code/",
        "teaser": null
      },{
        "title": "AWS Certified SysOps Administrator - Associate 認證考試準備及心得",
        "excerpt":"                  AWS Certified SysOps Administrator - Associate            關於考前準備   相比前面的 Solution Architect 及 Developer 認證，SysOps 比較著重在災難復原和系統監控的部分，比較困難的地方在於這個認證會有比較多長的情境題，做題時需要多花一點時間做準備。   像是 ELB 發生效能瓶頸時會需要看哪些 metrics，基本的 VPC 和 EC2 等還是會考一部分，但是比較多著墨的重點在備份的解決方案以及升級的問題。安全性面，在 Audit 的部分也會考很多 IAM 相關的問題，如果之前跟我一樣有先考過 Solution Architect Associate 和 Developer Associate 準備起來就可以聚焦在比較重點性的服務，像我考試的時候就問到不少關於 CloudWatch 和 OpsWork 之類的問題。   認證有效期   與 Solution Architect Associate、Developer Associate 一樣是兩年。   費用   考試費用為 150 USD (建議大家可以準備充裕點再去考試才不會白白浪費了錢)   考試地點   今年度九月開始 AWS 官方授權的考試代理商從 Kryterion 轉為 PSI ，這次我選擇的考試在 Global Education Association in Taiwan (AMP) (對不起我不確定中文叫什麼，應該是托福相關語言中心相關的考試代理商)。因為是語言相關的考試中心，我去考的時候，是本年度第五場，所以考場設備並沒有像恆逸提供隔間的考場，只有一台筆電和約 30 人的小教室考試。   這次考場比較嚴謹需要查驗護照，這部分在試後跟親切的監考姊姊聊了一下得知前面有三場的應試人因為沒有帶護照被拒絕考試，不過當初恆逸只需要備有身份證件即可，建議大家攜帶護照應考，如果沒有護照建議考前跟考試中心電話確認一下。   當時考試單位在考試的時候沒有提供紙筆是比較困擾的地方，考場若能使用紙筆是非常有用的，特別是題目需要畫出拓墣的時候才能勾勒出對應的系統架構。比較慘的是考試中途網路還發生斷線，虛驚一場。   不過，上述問題在考完之後也跟親切的監考姊姊反應了一下這些部分，包含反應僅需查驗身份證件和過去不用護照的問題，避免大家不要再踩到跟我一樣的坑啊！   測驗語文、形式、題數及時間      考試語言：英文 (如果英文怕影響作答可以在報名時選擇中文的試卷)   考試形式：選擇題、多選題   考試題數：約 55 題   考試時間：80 分鐘   及格分數：建議及格分數抓在 70% 比較保險。   範例試題   作答完會詢問是否要填寫問卷，我一樣直接跳過了。   考試報名   可以透過官方的界面 AWS training 進行考試的報名，考試代理商為 PSI exam，   重點準備   考試前一定要花點時間了解一些基本服務的 metrics     Elastic Compute Cloud   Elastic Block Storage   Elastic Load Balancer   RDS   考試前建議先了解一次考試的幾個大方向，考試官方頁面可以參考 AWS 官方的認證頁面 ，Blueprint (必讀)。      (1.0) Monitoring and Metrics (15%)   (2.0) High Availability (15%)   (3.0) Analysis (15%)   (4.0) Deployment and Provisioning (15%)   (5.0) Data Management (12%)   (6.0) Security (15%)   (7.0) Networking (13%)   Introduction The AWS Certified SysOps Administrator – Associate Level exam validates a candidate’s ability to:     Deliver the stability and scalability needed by a business on AWS   Provision systems, services and deployment automation on AWS   Ensure data integrity and data security on AWS technology   Provide guidance on AWS best practices   Understand and monitor metrics on AWS   AWS Knowledge     Minimum of one year hands-on experience with the AWS platform   Professional experience managing/operating production systems on AWS   A firm grasp of the seven AWS tenets – architecting for the cloud   Hands on experience with the AWS CLI and SDKs/API tools   Understanding of network technologies as they relate to AWS   Good grasp of fundamental Security concepts with hands on in experience in implementing Security controls and compliance requirements   General IT Knowledge     1-2 years’ experience as a systems administrator in a systems operations role   Experience understanding virtualization technology   Monitoring and auditing systems experience   Knowledge of networking concepts (DNS, TCP/IP, and Firewalls)   Ability to collaborate with developers and the general business team/company wide   AWS Fundamentals，涵蓋 EC2 / VPC / DynamoDB / SWF (Simple Work Flow) / S3 (Consistency read-after-write) / 基本的網路 Troubleshooting，一樣建議針對這些考試內容內重點使用的服務進行比較詳細的了解。可以透過官方文件及常見問題得到很多相關的資訊。   這張認證最重要的在於 HA (High Availability) 和災難復原，所以像是 RDS 會考非常多關於 Backup window / Backup strategies 相關的問題，以及 AutoScaling。   如果對於 AWS 的使用並不熟悉經驗，可以透過 acloud guru 推出 AWS Certified SysOps Administrator - Associate 2017 來快速入門，   能夠有系統性的幫助入門了解 AWS 各式各樣的服務，完整的濃縮。   同樣推薦大家仔細閱讀過幾個重點服務的 FAQ 常見問答集，因為常見的問題確實就是成為考題的必要。      VPC (Internet Gateway / NAT 會出現在 Troubleshooting 的問題)   EC2 (AMI / AutoScaling / ELB / ALB / Spot, Reserved, On-demand 差別)   EBS (Snapshot)   S3 (Glacier / RRS / IA / Eventual Consistency)   IAM (User / Group / Role)   RDS   SQS   Lambda   API Gateway   DynamoDB (Index)   Route53   Cloudwatch   OpsWork   還有   考試中建議大家遇到太長或是不懂的題目先做標記跳過，特別是 SysOps 題目非常落落長，先把握拿到比較容易拿的分數，做過一遍後再回來檢查也會比較沒壓力。   祝大家順利通過認證！   ","categories": [],
        "tags": ["aws","certificate"],
        "url": "https://easoncao.com/AWS-SysOps-Administrtor-Associate-Preparation/",
        "teaser": "https://easoncao.com/assets/images/aws-sysops-cert.png"
      },{
        "title": "使用 AWS Lambda 建立 Line bot",
        "excerpt":"這篇文章主要是記錄如何透過 AWS Lambda 的服務，同時利用 AWS API Gateway，配合 Line 提供的 Bot API，打造屬於自己的 Line Bot。   利用 API Gateway 及 Lambda 建立 webhook 用於接收 Line API 發送的資訊   Please refer: Creating an AWS Lambda Function and API Endpoint - Slack   建立一個 Line bot   在正式使用 Line Bot 前，首先會需要一個 Line developer 的帳戶，並且建立一隻 Line 的帳戶。   首先登入 Line developer console 建立一個使用 Messaging API 的帳戶。   如果是第一次建立，會需要新增一個 Provider ，用來提供使用 Line Messaging API 的帳戶的相關資訊。   詳細的快速建立步驟可以參考官方的文件。   創建完 Channel 後，有幾項選項可以在設定內看到:     Channel access token (long-lived) : 用來操作 Channel 的 token   Use webhooks : 開啟或關閉 Webhook 選項，接續下面的 Webhook URL 設定   Webhook URL : 若有向機器人發送訊息、邀請加入聊天室等都會觸發到我們自訂的 Webhook 位址，並傳送對應的 API 訊息   Allow bot to join group chats : 是否允許 Bot 加入群組聊天   為了測試發送訊息的功能，只要在 webhook 一欄填入前面建立的 API Gateway endpoint，並且利用其他帳戶發送訊息或是加入到群組內，   就會觸發 Lambda 接收相關的資訊，可以在 Cloudwatch 內獲得對應的 User ID   Send messages:   curl -X POST \\ -H 'Content-Type:application/json' \\ -H 'Authorization: Bearer {ENTER_ACCESS_TOKEN}' \\ -d '{     \"to\": \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",     \"messages\":[         {             \"type\":\"text\",             \"text\":\"Hello, world1\"         },         {             \"type\":\"text\",             \"text\":\"Hello, world2\"         }     ] }'   利用 virtualenv 包裝 python 相依的套件   mkdir ~/linebot docker run -v ~/linebot:/root/linebot python:3.6.3 /bin/bash   install.sh  #!/bin/bash  curl -sL https://bootstrap.pypa.io/get-pip.py -O python get-pip.py pip install virtualenv   利用 virtualenv 建立 Lambda 部署套件   mkdir /root/linebot/virtualenv virtualenv /root/linebot/virtualenv source /root/linebot/virtualenv/bin/activate pip install requests json exit   完成建立後，就可以離開 virtualenv 的 shell，進入 ~/linebot/virtualenv/lib/python3.6/site-packages 將主程式 lambda_function.py 放入並進行打包:   cp ~/linebot/lambda_function.py ~/linebot/virtualenv/lib/python3.6/site-packages/ cd ~/linebot/virtualenv/lib/python3.6/site-packages/ zip -r linebot.zip .   完成打包之後，將打包的程式上傳至 AWS Lambda 即可。   Reference:      Line developer: Send push message   AWS Lambda: Creating a Deployment Package (Python)   ","categories": [],
        "tags": ["aws","python"],
        "url": "https://easoncao.com/create-a-line-bot/",
        "teaser": null
      },{
        "title": "一個關於我大學專題的故事 - 四軸無人機專案 Parrot Bebop Drone 和 Python library Katarina",
        "excerpt":"前言   大學四年的學習歷程即將告一個段落，邁入人生下個階段，趁著幾天空閒的時間將這些記憶跟過程付諸文章，紀錄自己那些年不凡且獨特的過往。   一個關於無人飛機的專案   在台灣普及的大學學程裡面，大部分都納入了專題研究相關的課程內容，一旦升上大三，通常不管是哪個系所，幾乎開始動工進行專題的工作。可能有很多學生或是系所會將專題視為大學四年內的學習成果，非常重視，不過，畢竟每個學期都在完成不同類型的專案，相對於我自己大一每學期都有專案跟每週都有寫不完的程式相比，對於投入專題工作的心情，其實感受不大，覺得只是在未完成清單裡面多加一項「專題」的待辦事項，加上在實習公司內也有其他重要的事情需要完成，所以對於專題的投入比例並沒有太高，純粹當個好玩的業餘項目在研究。偶而有報告或是接近截止日期時相對投入些，所以就更無憂無慮的可以專心研究自己想深鑽的內容。   雖然心裡這樣說說，但是還是會想著：當然可以也稍微努力做一下，有得獎是好事，沒得獎就算了。於是抱持著這樣的心態選定我自己有興趣的專案題目，尤其我對於影像視覺相關的研究領域很感興趣，從高中開始就使用 OpenCV 做相關的應用，不過這個領域並不是我最擅長的項目，於是乎，既然有這樣的研究機會，我二話不說在大三差不多能找專題老師的時機，就跟同學組隊找了影像視覺應用研究領域的教授來指導我們的專題內容。當初與實驗室教授選定專案題目時，異想天開想搞跟電梯有關的專案，不過後來想想還是有點無用所以中途就換了其他題目，當然也是搞個自己想玩的項目：無人機。   這一搞還好，一玩下去不得了，坑特別多。首先，一般市售的家用無人機，基本上是除了飛行之外能應用於研究實驗用的功能真的是極為稀少，我們從實驗室借到的無人機產品是 2015 主打一般消費市場的飛機，基本上，就是一台遙控飛機在天上飛附上一組鏡頭，而對於飛機所擁有的感測器及軟體，有非常大的不足需要克服。                     Parrot Bebop Drone            (Photo credit: Parrot)   Specification     Video: full HD 1080p   GPS: Yes   Processor: Dual core processor with quad-core GPU   Storage: 8 GB flash storage system   Video resolution: 1920 x 1080p (30 fps)   Photo resolution: 4096 x 3072 pixels   Video encoding: H264   Wi-Fi 802.11a/b/g/n/ac   Wi-Fi Aerials: 2.4 and 5 GHz dual dipole aerials   SDK Release   Product reference     Amazon: Parrot Bebop drone   你可以下載官方提供的 App，就可以透過 Wi-Fi 的方式與無人機進行連線，以手持的方式遙控飛機。那麼一般手持裝置是如何做到控制飛機的？其實背後技術原理是透過發送含有指令的 UDP 封包進行飛機的控制，例如前後左右、旋轉角度等。   一開始打算使用 GitHub 上一些新奇的專案和語言來實做，但是考量我與夥伴由於同時要實習還要兼顧一大堆作業課業報告的緣故，每週能夠開發研究的時間就顯得特別寶貴，於是為了提高開發的速度，我決定使用彼此熟悉的語言和豐富成熟的框架來進行應用的實作：      Python 2.6   OpenCV: 負責影像運算和辨識   Flask: 網頁控制介面開發   Python library for Bebop Drone - katarina: 處理無人機控制飛行和決策   Katarina 是一個開源的 Python 函式庫，是由一群捷克的開發者組成的 Robotika 底下的一項項目，老實說我不是特別清楚團隊的成員背景，但是秉持開源的精神，還是十分感謝他們貢獻這項專案。該項目主要是針對 Parrot 無人機公司釋出的 SDK 提供 Python 的接口，使得 Python 開發者能夠利用熟悉的語言控制該公司的無人機產品。   於是，我改改了幾行代碼   但是這個坑一踩，才知道有多大洞。整個專案最讓我詬病的是，飛機本身的限制造成在專案研究過程很大的障礙，需要逐一克服：      一旦飛機超出一定範圍，Wi-Fi 連線延遲會拉高，影像的回傳就會產生延遲，此時進行的飛行決策很可能是錯誤的。   無人飛機透過四個軸的飛行槳控制，保持飛行的穩定以維持一定的平衡，然而，對於家用的無人機來說，並不能保證其穩定的順暢，很可能因為風阻或是干擾等其他因素飛機會不斷飄移。   由於帶動四軸飛行槳時，馬達運轉需要大量的功耗，然而，家用無人機所攜帶的電池飛行的時間有限，一顆要充將近一小時的電池僅夠支撐室內約 15 - 20 分鐘的飛行，往往研究還沒正式開始測試或是取得需要的數據就得先行換備用電池，不斷的在考驗人性。   飛機為了保持飛行的穩定，其機身設計採用流線型並且限制重量，一旦超出負重，當在空中起飛並盤旋時，飛機會失去本身機身的穩定，所以難以附掛額外的零組件或是電池。   飛機的本身運算能力有限，飛行同時要在飛機本身分析影像內容是一項考驗運算能力和電力的一項挑戰。   同時，最嚴重的是，我發現 Katarina 固然提供豐富的控制方法，然而，他原本使用的影像串流方式十分、十分的慢。回傳的影像可以說是飛機五秒前的位置，一旦 Wi-Fi 傳輸距離與影像串流分析的機器過遠，基本上你就不知道飛機目前飄到那去了。由於我的專案需要即時的影像回饋進行飛機的飛行決策，一旦偵測到目標物體就會往物體靠近飛行並且滯留。如果現在回傳的影像是五秒前的，由於上述提到的致命缺點，飛機很可能因為不穩定已經往左右或其他方向飄移，這時若飛行決策的邏輯還送出飛行指令驅使飛機往該方向前進，一旦附近有障礙物，肯定撞機。所以一旦有幾秒以上的延遲，都是十分致命的。   就算將所有障礙物清空，撇除障礙物問題，還是必須要克服影像串流造成的延遲，因為飛機的位置不一定會是影像當時回饋的相對位置，這都會影響飛行決策是否能正確的往目標物體靠近。但是 Katarina 本身的串流方式就有很大的延遲問題，在 GitHub 上面也有一些關於這個問題的討論：      GitHub issue#3: Improving Speed for Receiving Real-Time Image   經過一番深入研究和測試，我注意到 Parrot 官方提供的 SDK 內其實有配置 RTP 串流的協議和對應的連線資訊：   #define ARDISCOVERY_CONNECTION_JSON_ARSTREAM2_CLIENT_STREAM_PORT_KEY \"arstream2_client_stream_port\" #define ARDISCOVERY_CONNECTION_JSON_ARSTREAM2_CLIENT_CONTROL_PORT_KEY \"arstream2_client_control_port\" #define ARDISCOVERY_CONNECTION_JSON_ARSTREAM2_SERVER_STREAM_PORT_KEY \"arstream2_server_stream_port\" #define ARDISCOVERY_CONNECTION_JSON_ARSTREAM2_SERVER_CONTROL_PORT_KEY \"arstream2_server_control_port\"      libARDiscovery   Parrot-Developers-Stream   此外，我也在網路上找到很有趣的一篇文章：Stream Bebop Video With Python Opencv，這個範例使用 Python 去執行另一個開源一樣提供給 Bebop 以 Node.js 寫成的 node-bebop 專案，利用呼叫 Node.js 版本的函式庫內提供的串流方法進行 RTP 串流，實際上，是蠻有趣的作法。   於是，我就嘗試改改了幾行代碼，經過我的測試並應用在我的專題內，送了一個 Pull Request 給了作者，在與無人機連接時送出必要的影像訊息，在執行時能夠使用 RTP 串流的方式接收影像：      GitHub pull request#14: Enable RTP Streaming on Bebop and add sample code   不久，我就收到了來自 Robotika 的問候：                     Email from Robotika about Katarina project            在我回覆不久，Robotika 的 Martin 就將我的 Pull request 合併進專案內，成為該專案目前唯一一個 Pull request。   收穫？   串流問題解決了，一般來說，OpenCV 的應用程式往往都是單執行緒的運算方式，獲取單張影像後進行運算和特徵判斷，但是這樣的方法往往會在運算速度的緣故發生一些效能瓶頸。於是，我又透過改寫程式利用一些多執行緒的處理技巧，搭配在應用程式裡面設計 Queue 的邏輯，使得接收串流影像是一個單元，真正進行影像判斷和飛行決策的則是另外的單元，並且加入一些判斷機制，盡可能降低因為串流產生的延遲造成的錯誤飛行決策。   不過由於飛機的限制，並沒有深度等等的感測器，整個專案困難的部分也包含影像飛行對於實際距離換算的方法，經過一系列的微調和測試，完成了一個 PoC 的版本：               (這個影片給幾個同學看過後，都被開玩笑其實我們的專題不是無人機收費，比較像是無人飛行武器開發，精準投遞摧毀目標 … lol)   專題展示前幾天至當天早上，我還與夥伴玩起黑客松，逐一的將沒有完成的介面進行收尾以利當天的展示，十分感謝這些年來大大小小專案的磨練，已經練就開始前幾個小時甚至 Demo 當下還在送 Commit / 改程式的功力，不過既然是當成業餘的項目，開心好玩並且從中收穫最重要，比賽反而是其次了。   最後，我並沒有得獎，也許在評審委員教授的眼裡，看見的應用價值是商機和獲獎的必要條件。但是，對我來說，這個專題帶給我的並不是這樣表面的效益和回饋，而是在重重的困難和限制下對於盡力完成研究的方法和價值。我的幾行代碼，卻是貢獻是數個全世界使用 Bebop drone 和 Katarina 的無人機玩家們，即便在不同的國家，我們卻用著相同的語言和同樣的精神在交流、共同解決相同的問題，其所成就感已經超越單一個專題的獎項所帶來的滿足。   我想，這就是一項成就解鎖吧!   ","categories": [],
        "tags": ["python","drone"],
        "url": "https://easoncao.com/a-story-about-my-project-using-bebop-drone-and-katarina/",
        "teaser": null
      },{
        "title": "救回 Windows 上意外關閉且遺失的 Atom 筆記 (1.27.2 x64)",
        "excerpt":"這篇文章主要是記錄下在 Windows 上使用將意外關閉的 Atom 筆記復原。   一般來說，Atom 內建自動復原的功能，但是在某些特殊情況遇到不小心意外關閉 Atom 筆記又很不巧沒有存檔，發生難以復原的情形，可以試試以下方式救回筆記 (版本 1.27.2 x64)。   至以下目錄尋找 Atom 的暫存檔案：   C:\\Users\\&lt;UserName&gt;\\AppData\\Roaming\\Atom\\IndexedDB\\   例如可能會看見像是這樣的目錄結構：  C:\\Users\\&lt;UserName&gt;\\AppData\\Roaming\\Atom\\IndexedDB\\file__0.indexeddb.leveldb   在目錄內，若 Atom 有確實的紀錄你的筆記，可以試著找找 000XXX.log 相關的紀錄檔案，並且使用 Linux 上的 dd 工具將檔案內容復原，就有機會找回遺失的內容：   dd conv=swab &lt; 000715.log &gt; file.txt   Reference:      Atom   Unsaved buffers aren’t restored if there is no project folder added to the window   ","categories": [],
        "tags": ["atom","windows"],
        "url": "https://easoncao.com/recover-atom-note-on-windows/",
        "teaser": null
      },{
        "title": "AWS Certified DevOps Engineer - Professional 認證考試準備及心得",
        "excerpt":"                  AWS Certified DevOps Engineer - Professional            關於考前準備   相比前面的 Solution Architect、Developer 及 SysOps 均屬於 Associate 級別的考試，考試內容相對通用且內容固定，大部分屬於問答式選擇題。   而 Professional 級別的考試難度是不同的檔次，題目不僅長且全部都是情境題，做題時間不僅拉長，做題前更是需要多花一點時間做準備。   認證有效期   與 Solution Architect Associate、Developer Associate、SysOps 一樣是兩年。   費用   考試費用為 300 USD (建議大家可以準備充裕點再去考試才不會白白浪費了錢)   考試地點   今年度九月開始 AWS 官方授權的考試代理商從 Kryterion 轉為 PSI ，台北的恆逸教育訓練中心 有提供相關的認證考場，地點靠近捷運站，於是乎我就選擇了恆逸作為考試地點。   測驗語文、形式、題數及時間      考試語言：英文   考試形式：選擇題、多選題   考試題數：約 80 題   考試時間：170 分鐘 (考試時間幾乎是 Associate 級別的兩倍，同時考驗作答時的耐性與穩定性)   及格分數：建議及格分數抓在 70% 比較保險。   範例試題   考試報名   可以透過官方的界面 AWS training 進行考試的報名，考試代理商為 PSI exam，   重點準備   考試前建議先了解一次考試的幾個大方向，考試官方頁面可以參考 AWS 官方的認證頁面 ，Blueprint (必讀)。      Domain 1: Continuous Delivery and Process Automation (55%)   Domain 2: Monitoring, Metrics, and Logging (20%)   Domain 3: Security, Governance, and Validation (10%)   Domain 4: High Availability and Elasticity (15%)   Introduction The AWS DevOps Engineer - Professional exam is intended for individuals who perform a DevOps role.   This exam validates an examinee’s ability to: Implement and manage continuous delivery systems and methodologies on AWS     Understand, implement, and automate security controls, governance processes, and compliance   validation     Define and deploy monitoring, metrics, and logging systems on AWS   Implement systems that are highly available, scalable, and self-healing on the AWS platform   Design, manage, and maintain tools to automate operational processes   The knowledge and skills required at the professional level include the majority of the following AWS and general IT knowledge areas:   Prerequisites     AWS Certified SysOps Administrator – Associate or AWS Certified Developer – Associate   AWS Knowledge     AWS Services: Compute and Network, Storage and CDN, Database, Analytics, Application Services, Deployment, and Management   Minimum of two years hands-on experience with production AWS systems   Effective use of Auto Scaling   Monitoring and logging   AWS security features and best practices   Design of self-healing and fault-tolerant services   Techniques and strategies for maintaining high availability   General IT Knowledge     Networking concepts   Strong system administration (Linux/Unix or Windows)   Strong scripting skillset   Multi-tier architectures: load balancers, caching, web servers, application servers, databases, and networking   Templates and other configurable items to enable automation   Deployment tools and techniques in a distributed environment   Basic monitoring techniques in a dynamic environment   準備 DevOps Engineer Professional 前，必須理解 Continuous Delivery and Process Automation 涵蓋了非常大的比重，考試前我會推薦熟悉以下服務：      CodeDeploy   CloudFormation   OpsWorks   Elastic Beanstalk   CodeCommit   CodeBuild   CodePipeline   Elastic Container Services   同樣推薦大家仔細閱讀過幾個重點服務的 FAQ 常見問答集，因為常見的問題確實就是成為考題的必要。   就我的考試經驗，CloudFormation 和 Elastic Beanstalk 兩個服務有非常大的機會和題目比重。   這張認證最重要的在於在 AWS 上實踐 DevOps 工作和最佳實務，所以會有很多版本控制、自動化測試整合以及 Deployment strategies 等等相關的問題，由於題目都是情境題，會有不同的實踐方式，所以必須要先對於上述 AWS 基本服務有個了解才比較能選擇最佳的實踐方式。   如果對於 AWS 的使用並不熟悉經驗，可以透過 acloud guru 推出 AWS Certified DevOps Engineer - Professional 來快速入門，   能夠有系統性的幫助入門了解 AWS 各式各樣的服務，完整的濃縮。   此外，準備 Professional 有非常重要的一點，我認為務必完整規劃讀書計畫和時間管理。例如，安排一個月後考試，務必每週的目標和 30 天的讀書計畫，積極實踐，利用每天固定觀看 acloud.guru 的 2 至 3 個影音外也需要花點時間閱讀文件和複習。同時，我也十分推薦上 YouTube 挑選對於 AWS DevOps 相關的 re:Invent 、 Tech talk 影音、閱讀 Whitepapers 等增強對於實務上的最佳實踐：      Whitepapers: Introduction to DevOps on AWS   My DevOps professional playlist   還有   考試中建議大家遇到太長或是不懂的題目先做標記跳過，特別是 DevOps 題目非常落落長，十分考驗耐心，平均每個題目的作答時間僅有 1 分鐘，先把握拿到比較容易拿的分數，做過一遍後再回來檢查也會比較沒壓力。   祝大家順利通過認證！   ","categories": [],
        "tags": ["aws","certificate","DevOps"],
        "url": "https://easoncao.com/AWS-Certified-DevOps-Engineer-Professional-Preparation/",
        "teaser": "https://easoncao.com/assets/images/aws-devops-pro-cert.png"
      },{
        "title": "[Book] 原子習慣：細微改變帶來巨大成就的實證法則 - 我的心得及實作",
        "excerpt":"今年 5 月 (May, 2020) 我讀完 安靜的力量 一書就在 Instagram (aka. IG) 上面問問有沒有人可以推薦書籍來一起交換心得，本書是在美國 UC 念研所的高材生 Chia-Tien 的真心推薦，一講完我就刷中文版進到我的 Kindle 書庫了 (Kindle 中文版竟然還比原文便宜！會中文真好 XD)。   原本抱著對未來總有時間的期待能一次把它讀完，無奈生活、工作一被很多事情塞滿 (說白了應該是偷懶，耍廢的優先級總能比閱讀這種太營養的事情來的高 …)，我其實閱讀這本書的時候都是用很碎片、零碎到不行的時間 (睡前讀個 5 分鐘、幾頁之類的 ….)，今天終於有時間一次完結 (算一算也已經八月了 XD)，順便把 Kindle 上面做的筆記、重點一次給它摘要起來。因此，本篇內容主要簡述我對原子習慣 (Atomic Habits) 的讀書心得及自己的實作分享。   前言    在這篇文章中你將知道      如果你想知道如何正確培養習慣，我會與你分享本書的核心重點。以及，為什麼你該立即透過 Kindle 或是 博客來 收藏本書 (這本書已經成為 21 世紀熱銷排行的前幾名，沒有之一)   你在閱讀後將了解習慣的建立系統   我將與你分享我自己的實作成果                      原子習慣: 細微改變帶來巨大成就的實證法則            概覽   本書著重於習慣的建立，並且歸納出好習慣建立的四大法則。書中舉了非常多各領域透過微小習慣帶來巨大改變的例子，在開頭舉了一個很有趣的案例，是英國自行車選手自從聘用新的國家隊教練 (Dave Brailsford) 透過非常多微小 (小到無法理解的) 的改變，像是：      “重新設計單車座墊，使其坐起來更為舒適”   “輪胎上塗抹酒精，增加抓地力”   “穿上電熱式緊身褲，使肌肉在騎車時維持理想溫度”   “調整賽衣的布料，使選手在比賽時更加輕盈並且符合空氣力學”   “測試按摩油，看哪種能更快幫助肌肉恢復”   “請外科醫師教導選手洗手，以減少感冒機率”   “找出帶來最佳睡眠品質的枕頭與床墊”   等等等等 …. 並且納入選手的訓練中以作為日常習慣的一部分。   甚至是把後勤卡車的內壁刷成純白！以幫助查看到微小的塵埃以避免影響到精準調整的比賽用車！   這些細微的改善，累積起來，竟然大幅度提升英國自行車運動員的運動成績。原本一直吊車尾的英國車隊 (歐洲單車品牌製造商甚至拒絕販賣商品給英國車隊，以免對品牌造成負面影響)，才短短五年，英國自行車隊就在 2008 年北京奧運稱霸，拿下六成金牌，並且更在四年後創下九項奧運紀錄跟七項世界紀錄，聽起來都很不可思議。   以下分享幾項我認為十分有幫助的概念進行摘要。   習慣的複利效應   百分之一的改善並不特別值的注意 (有時候根本不被注意)，但隨著時間過去，微小改善所能造成的變化十分驚人，例如：如果每天都能進步百分之一 (1%)，持續一年，最後會進步 37 倍 [1]。      [1] Note: 我很好奇為什麼是 37 倍，網路上一堆分享似乎都只複製貼上書中的內容但是都沒說說為什麼，終於讓我找出答案是 1.01 ^ 365    相反地，若是每天退步百分之一 (1%)，持續一年，則其會弱化趨近於零 (0.99 ^ 365 ~= 0.03)。   換句話說，習慣就是「自我改善」這件事情的複利，並且效果會在你重複執行的過程中加倍。若隨便挑一天執行習慣的行為來看，其效應似乎很小，然而，一旦經過幾個月、甚至幾年下來，就有可能造成極巨大的影響。                     習慣帶來的複利效應            習慣的建立系統   要在日常生活中體會上述的概念並不容易，並且人的大腦天生設計出來就是通常特別喜歡偷懶、簡單、立即反饋性的事情。這正說明為什麼我們寧可躺在床上滑一小時社群媒體，而不願意走出門外出去跑步一個小時，因為後者相對耗費了更多精力，並且沒有立即性反饋的效應。   滑臉書一個小時，吸收訊息的同時滿足了大腦想接受感興趣訊息刺激的渴望，同時觸發了大腦的愉悅機制，立即被滿足。例如：發佈文章後，很迫切的關注自己的貼文有多少個讚，得到很多個讚後，可以滿足某種層次上想被關注的渴望，於是習慣機制被建立，你不自覺的反覆以下的習慣公式：      自然的拿起手機拍照及錄影 (例如跟朋友吃個飯仍彼此互拍對方及食物，即使在旁人眼裡無法理解，你還是會習慣這麼做) -&gt; 打開社群媒體 App -&gt; 修圖 / 美化內容 -&gt; 發佈文章 / 發佈限時動態 -&gt; 渴望得知獲得的讚數和評價    上述的動作可能短短付出幾分鐘就能得到反饋，這正是為什麼人機介面專家不斷地在努力優化即時反饋功能 (利用通知數及紅色觸發提示)，跟一群資料科學家們，認真的利用機器學習努力的學會識別你感興趣的內容並且嘗試投放你可能會喜歡的資訊，以奪走你的注意力。   反之，出去跑步一個小時，你可能得到的是，身體會非常疲憊，同時，若你剛接觸跑步，你也不可能跑一天就成為跑步大師，短短幾天就能在一小時內跑完 10 公里，甚至從中獲得讚美及成就感滿足你大腦渴望的需求。這個動作的反饋其帶來的成果總是來得不夠快，於是你仍決定回去滑社群軟體一小時而不是踏出門跑步。   你不會因為今天只吃一餐垃圾食物，體重計上的指針就突然大幅度的移動，特別是大腦往往漠視對於當下的單一決定其長期帶來的影響。然而，當日復一日重複百分之一的錯誤，複製不當決策及係為過錯，並且將小藉口合理化，這些小小的選擇隨著複利的威力，變成有害的後果。因此，本書舉了非常多的實例並且具體提出幫助檢視習慣的方式，以了解自己的習慣是否處於正確的軌道，同時提出多項方法，以建立系統化的方式建立習慣。   也許書中內容有一部分為了增加故事性，把很多枝微末節的東西湊起來，以不斷強調微小習慣建立的重要性。但本書核心仍著重於習慣的建立，並且歸納出下列好習慣建立的四大法則：      讓提示顯而易見 (Make it obvious)   讓習慣有吸引力 (Make it attractive)   讓行動輕而易舉 (Make it easy)   讓獎賞令人滿足 (Make it satisfying)   反之，若要學會破除壞習慣，則可以反轉上述法則      讓提示隱而不現 (Make it invisible)   讓習慣毫無吸引 (Make it unattractive)   讓行動困難無比 (Make it hard)   讓後果令人不滿 (Make it unsatisfying)   讓提示顯而易見   行為的改變始於察覺，必須先意識到自己的習慣，才能開始改變它。   我們觀察自己日常的小習慣被觸發的線索 (例如：起床順手拿起手機、肚子餓時就不自覺打開外送 App … etc)，並幫這個習慣評比，同時請考慮最長遠的益處，如果無法決定這個習慣是好還是壞，可以問自己：「這個習慣能幫助我成為我想要成為的那種人嗎？對於我渴望的身份認同，這個習慣是投下同意還是反對票？」。   讓習慣有吸引力   習慣就是多巴胺驅動的回饋迴路。極度容易養成習慣的行為──吸毒、吃垃圾食物、打電動、瀏覽社群媒體──都與較高濃度的多巴胺有關，亦適用於最基本的習慣：飲食、喝水及社交。讓我們採取行動的，是對獎賞的預期。大腦分配給「想要」獎賞的神經迴路 (腦幹、依、腹側被蓋區、背側紋狀體、杏仁核以及部分前額葉皮質)，遠比分配給「喜歡」獎賞的要多。   也許你想要知道最新名人的八卦，但又需要鍛鍊身材，你可以要求自己只能在健身房邊跑步邊看八卦新聞、看實境秀。善用誘惑綑綁，幫助你將獎賞與提示產生連結，以更好地吸引你養成該項習慣。   讓行動輕而易舉   習慣的養成取決於頻率，而非時間，如同身體肌肉會對規律的重量訓練產生反應，大腦的特定區域也會在被使用時增長，在被拋棄時萎縮。每次重複一個行為，你就活化了跟那個習慣有關的神經迴路。   大腦設定會盡可能節省能量，人類的天性仍遵循「最小努力原則」，在兩個類似的選項中抉擇時，人自然傾向選擇花費最少力氣的那個。養成一個習慣所需的能量越少，養成的可能性越高。這意味著，讓習慣簡單到就算沒有意願也會執行至關重要。若能讓執行好習慣更加方便，你就更有可能貫徹。(健身房在上下班路上，你就比較容易去健身，因為順路停下來不會為原本的生活增添太多阻力。要是健身房不在通勤路上，就算只差幾公尺，也會變成像是「特地」去健身，養成固定去健身房的習慣就更加困難。)   讓獎賞令人滿足   生活在現代，你做的許多選擇都不會馬上得到好處。你在工作上表現優異，你會在幾週後收到薪水支票; 今天運動，也許明年就不會過重; 現在開始儲蓄，也許幾十年後就有足夠的錢享受退休。從遠古時期，人類的大腦必須響應立即性的回饋 (吃什麼、在哪裡睡覺、如何躲避獵食者，總是把焦點放在當下或是接近的未來) 這與大腦的設計背道而馳，正是為什麼延遲回饋的習慣特別難容易養成的原因。   因此，習慣必須讓人感受到愉快，我們才有可能持續重複某一行為。   「迴紋針策略」：1993年，加拿大一位股票經紀人，每天早晨，會把兩個罐子放在辦公桌上，一個是空的、另一個則放了 120 個迴紋針。每天一做好開工準備，他就會打一通業務拜訪電話，一旦講完，就立即的把一個迴紋針移動到空罐，重複整個過程。直到所有的迴紋針都被移動到另一個罐子裡。   這種視覺上的測量提供了進步的清楚證據，並且強化行為，且為活動增添一點立即的滿足感。透過追蹤習慣，更利於習慣的養成。   改變習慣最有效的方法，是改變身份認同   大部分人無法堅持一項習慣，通常是因為人們對於習慣的建立，是基於「目標」導向，例如：我必須培養運動的習慣，每週必須跑 10 公里，以幫助我能夠順利在三個月後的路跑活動中順利跑完半程馬拉松。然而，一旦完成該項目標後，原本培養的習慣就難以維持，便很容易復歸 (大腦總會有個聲音：啊！今天休息一下好了，於是在幾天後變成，下個月再跑好了！)，於是習慣的系統瞬間瓦解。   在本書中，特別強調「習慣」這件事，其實就是通往身份轉變的道路。每當你選擇做某個壞習慣，就投了一票給予你想成為的身份 (例如：我選擇每天下班去酒吧來好幾個 shot，這樣我允許我自己成為愛喝酒的人，並且這意味著我願意成為那樣的人。)。因此，想要維持一個習慣，首先，先決定你自己想要成為什麼樣的人：      你想要學習精進自己的習慣？那先改變你自己的身份認同吧！ — 「我是一個終身學習的人」   你想要保持健身的習慣？那先改變你自己的身份認同吧！ — 「我是一個擁有良好運動習慣的人」   你想要保持理財或是存錢的好習慣？那先改變你自己的身份認同吧！ — 「我是一個擁有理財紀律並且是擁有規劃財務習慣的人」   如果你想成為一個健康的人，隨時問問自己：      一個健康的人會怎麼做    這種想法變使得你的大腦在日常生活中進行決策時，不自覺地導入你想養成習慣的相應決策，並且成為你的行為指南：一個健康的人會選擇走路或搭計程車？ 一個健康的人會點墨西哥捲餅或是沙拉？。   擁有上述的自我認同後，便是不斷的透過生活中的各項小勝利來向自己證明 (今天又完成了這個習慣)，永遠將習慣的建立放置焦點在成為某一種人，而非得到某一種成果，如此一來，習慣的建立便輕而易舉。   我的實作成果   先說說我自己的心得，身為一名雲端工程師，工作性質不外乎就是長時間待在電腦前面弄得出神入化，可能一個小時內幫助很多很知名的品牌、線上服務提供非常實用的技術性建議，以處理很多系統故障的狀況、找出客戶開發團隊自己埋的坑，拯救全世界因為網路連結那些孤寂的靈魂和龐大的虛擬需求，但外人完全搞不懂你在衝啥。   不管是軟體工程師、系統工程師、維運工程師、各種打雜工程師，總之，不論身在哪個職位、一般人對於工程師的印象，就是又宅又臭，並且讓人感覺除了自己專業上面的事情，其餘事情就是一竅不通。   但我就是不甘願這種刻板印象 (沒錯，我就是要打！破！它！)，當然，這些習慣有一部分出於對自己所做事情的喜愛，因為不希望自己分享的內容又淪為空泛的談論，因此，本節以我自己為例，以自身的經驗分享我自己的實作成果，分為兩個部分：馬拉松跑者、大力士計畫   馬拉松跑者之路   我自己的目標，起初是希望擁有一個健康的身體，並且想要學習跨出舒適圈，挑戰自己。於是我在 2018 年底，就開始啟動自己的長跑訓練計畫，目標當然是能靠自己完成跑完半程甚至是全程馬拉松的距離。當然，這都是我在接觸這本書之前就有的計畫，但是真的就是一股腦的亂訓練，也沒有正確的學習培養習慣。在大學時期有時候想到運動就會去跑跑，但是距離上可能 5 公里內就差不多了，而且訓練非常看心情，跑步這件事，常常可以有非常多理由就中斷。這件事情在 2019 年初設下想要跑半馬的目標後，真的就是憑一股傻勁在維持：                                                                                                                                                  2018 - 2019 Jan                                                                                                                                                                                                         2019 May - June                                                                                                                                                                                                         2019 July - Aug                                                                  從上面的紀錄可以看到我的訓練其實是斷斷續續的，當初可能就想週末至少跑一下長距離 10 公里。但是仍缺乏維持的系統。所以可能跑一週，一次一股腦衝個兩天，但下週又總能找到理由休一週。直到接近賽季的時候才認真訓練起來 (我的初半馬在十月 - October, 2019)：                                                                                                                                                  2019 Sep                                                                                                                                                                                                         2019 Dec                                                                  然後我也如期完賽了，初半馬跑出 02:20:46 的成績，10 月跑完直接休快一個月，結果繼續到 2019 年底斷斷續續的在維持幾天：                                                                                          2019 Pocari Sweat Run - 21km - 02:20:46       對於跑步這件事情，起初我的想法是喜歡這項運動，特別是執行長距離跑步時，是一種與自己對話的過程，從中學習沈澱自己的思緒和被工作跟一堆雜事打到紊亂的生活節奏，小小的萌生想成為市民跑者的想法，仍而，對於身份認同仍不夠強烈，所以訓練計畫總是斷斷續續的。   直到 2020 年，開始轉變自己對於跑步的心態 — 「我希望自己老了也可以繼續跑步」，直到閱讀原子習慣後更確切自己的身份認同 — 「不以競賽為目標，我想成為一名馬拉松跑者並且不斷的突破自己，將馬拉松的哲學實踐在我的生活中，學習面對生活的各種挑戰」。於是跑步這件事情在我心中，不再是一個在社交圈中跟別人展示自己又參加了哪些馬拉松，心裡的想法十分單純明確：我就是想學習一直跑下去，並且持續的一點一點突破自己 (耐力多提升個 100 公尺、到終點前不要停下來，試著比昨天努力試著衝點間歇)，於是心態更加輕鬆了，身體修復的速度比不上課表，那就減量、降低強度，下週在試一次！於是，維持這項運動就像是一種樂趣。   基於四項原則，我的實作方式如下：      讓提示顯而易見 (Make it obvious): 例如我設定週跑量要滿足至少 20km，一週執行三天。我的做法是，預先在 Google Calendar 設定好重複性的提醒，如此一來，在特定時間 (比如：週日、週三、週五) 就會擁有這項提示，我不管是前一天檢視待辦或是當天，就會在固定時間接收這項提示已觸發行為。                     提示: 我 Google Calendar 上的跑步提醒項目                    讓習慣有吸引力 (Make it attractive): 這一部分仰賴前面的身份認同，並且受跑步獨處的自由吸引 (以及聽振奮人心的音樂)，另一種輔助方式則是，我會 “想要” 增加自己 Nike Run 的成績紀錄，以及，我會預期自己跑完之後，會發一則廢文到社交動態 (例如：Instagram)，或是預期自己未來藉由報名路跑證明自己可以完賽。因為會 “想要” 上傳社交動態，以展示自己很努力的一面，並且幫助大家建立對我自己想要成為的身份認同並且得到尊重，這使得在習慣觸發之前提供巨大吸引力。       讓行動輕而易舉 (Make it easy)：買了一雙好跑的跑鞋，同時，去住家附近的場所跑步，走個幾步就到！   讓獎賞令人滿足 (Make it satisfying)：透過使用 Nike Run App 和上傳成績到社群軟體，有助於我追蹤習慣並且滿足自己裝 B 的需求。一部分是完成習慣後我會願意獎賞自己特調的運動飲料、氣泡果汁，以補充失去的鹽分跟電解質，這刺激了完成習慣的渴望。並且，我會在 Google Calendar 在當天該項提醒事項標註為已完成。                     獎賞: 在 Google Calendar 上標註完成項目                                                                                                                                                           2020 April - total 34.63 km / 3 runs                                                                                                                                                                                                         2020 May - total 38.16 km / 4 runs                                                                                                                                                                                                         2020 June - total 56.27 km / 7 runs                                                                                                                                                                                                         2020 July - total 142.3 km / 16 runs                                                                  於是系統建立後，月跑量就逐步地趨近穩定，一週時間到，就很自動的離開座位、穿上鞋子、戴上耳機，暖身起跑。我在撰寫這篇內容才發現我七月的月跑量隨著這樣的執行，已經不自覺的突破 100km。當然，習慣的建立，其核心仍在於持續，我當然不會要求自己一定要每個月都要到達這個數字，但仍將跑步視為我生活的一部份，可以很自信的說，這確實是一種習慣。                     Aug 9 - 2020 國家地理路跑 - 21km - 半馬大會成績 02:17:37            大力士計畫   我的健身計畫嚴格說起來是 2020 開始學習執行的，我年初連怎麼操作動作真的完全沒有概念。其實背後有類似前面提及的動機，都是想培養一輩子的習慣，礙於篇幅跟打得有點累，以下就快速分享我個人習慣建立的幾項重要記事：                     2020 Jan 開始學習成為一名健人            大力士習慣系統建立的方式如下：      讓提示顯而易見 (Make it obvious): 如同前面的操作雷同，我一部分使用了 Google Calendar 的提醒標註以提供提示        讓習慣有吸引力 (Make it attractive): 操作與前面雷同，一部分仰賴前面的身份認同，我會 “想要” 增加自己健力三項的成績紀錄、打造更強壯的身體，想要有更強健的肌力，獲得更好的生產力、提升跑步表現。並且，預期自己執行完成後，一樣會發一則廢文到社交動態 (例如：Instagram) 凸顯我的力量巨大無比！！！！因為會 “想要” 上傳社交動態，以展示自己很努力的一面，並且幫助大家建立對我自己想要成為的身份認同並且得到尊重，這使得在習慣觸發之前提供巨大吸引力。       讓行動輕而易舉 (Make it easy)：健身房在辦公室附近、下班想轉換心情去信義區晃晃先順路去摔一下槓 … 等等   讓獎賞令人滿足 (Make it satisfying)：透過使用 Strong (App) 追蹤自己的重量變化，為了幫助自己校正動作，我會一併錄下自己的動作。於是，獎賞系統可以變成：      努力訓練 -&gt; 在 Strong 紀錄自己的重量觀察自己的力量成長 -&gt; 完成後來杯高蛋白乳清補充能量 -&gt; 發佈自己的執行動作到社交動態 -&gt; 追蹤自己的成長    2020 由於疫情爆發，大部分時間還是會 WFH (Work From Home)，去健身房瞬間變成一項成本很高的行為 (從我家搭捷運到原本的健身房快 30 分鐘)。但如同前面提及上述習慣系統的建立 (我在去往健身房的路上也加入了一些習慣綑綁的行為，這項時間變成一項額外的享受)，由於健身對於我來說是一項有十足吸引力的習慣，同時完成訓練後可以立即發佈的相應獎賞機制，利用科技助於我追蹤習慣，並且某種程度上滿足讓其他人認同我身份的渴望，仍有十足動力可以驅使我一週至少三天準時往健身房跑。   Squat: 77kg - (1RM: 90kg)               Deadlift: 119kg - (1RM: 119kg)               Note: 上述節錄自近期 (2020 Aug) 的限時動態，健身運動仍是一項長而持續的累積，基於動作習慣，上面的操作仍有進步空間，還在努力提升動作品質，不完全是正確的動作要領。   總結   原子習慣列舉了眾多淺而易懂的實例，描述在生活中習慣建立的前因後果，包含科學及研究理論的導論，具體提供非常多的實務性建議。本書列舉了習慣系統建立的方法，幫助讀者有效的打造習慣，同時提供了破除壞習慣的持續的導引。同時，我在自己的日常生活中嘗試實踐，其理論某種程度上，得以於實務上被印證，該系統能有效幫助習慣的建立，並且得以持續。   本書仍提及眾多習慣建立的準則和注意事項，細節無法一一列舉，作為習慣導引的工具書，是一本實踐後，值得一再閱讀審視的參考文獻。   相關資源   如果你想獲得更多具體的習慣建立方式，可以透過下列連結取得相關的電子、實體書籍版本                                                                                                                       原子習慣: 細微改變帶來巨大成就的實證法則 (Kindle)                                                    數位版優惠連結 - $7.84                                                   獲取優惠                                                                                                                                                    原子習慣: 細微改變帶來巨大成就的實證法則 (博客來)                                                    博客來 79折優惠連結                                                   獲取優惠                                        看更多系列文章      沈默並不代表軟弱：內向的你必須看的一本書 - 安靜的力量 Quiet Power: The Secret Strengths of Introverts   3 項原則讓你變得更有生產力 - 最有生產力的一年 The Productivity Project   原子習慣：細微改變帶來巨大成就的實證法則 - 我的心得及實作   刻意練習 - 實踐刻意練習的 3 項原則，往專家的道路邁進，我的心得及實作   ","categories": [],
        "tags": ["book","personal growth","reading","habit","atomic","kindle","amazon","自我成長"],
        "url": "https://easoncao.com/atomic-habits-reading-feedback/",
        "teaser": "https://easoncao.com/assets/images/posts/2020/08/atomic-habits-reading-feedback/book-cover.jpg"
      },{
        "title": "[Alexa] 靠一張嘴巴維運，我是如何成為出一張嘴的雲端工程師 - 使用 Alexa skill 管理 AWS EC2 防火牆 (Security Group) 規則",
        "excerpt":"隨著 COVID-19 疫情大爆發，科技圈再次掀起了一股遠端辦公的趨勢，遠距工作的形式也逐漸改變許多人的工作型態。身為一名工程師，因應疫情，今年也頻繁的在家辦公也好幾個月了 (還好台灣還很安全)，仍有很多與傳統地域限制型態的工作模式有很多不同的地方。   平常在辦公室，由於直接連接公司內部網路，通常都有特定的 IP 區段可以很簡單的掌握白名單，防火牆規則都非常好設置。但是自從開始遠端工作後，家裡的網路都是使用浮動 IP，有時候工程師的惰性驅使，又很懶得連上 VPN 在那邊拿 MFA Key  驗證身份，光是要設定自己 EC2 資源的白名單常常都要改來改去的。與此同時，在日常工作中也偶爾跟同事屁來屁去講一些垃圾話，注意到一些覺得可以進行自動化、增加生產力的一些想法及提案，秉持著發明家的精神，於是以下我就來說說我是如何靠一張嘴巴滿足我的懶惰的。   簡介   在沒有靠嘴巴維運之前，為了要正確的更改防火牆規則讓我能夠在家中工作時能夠連上跳板機器操作，我是這麼做的：      打開 AWS Management Console   輸入帳號密碼   彈出 MFA (Multi-Factor Authentication) 認證 -&gt; 打開手機 App 確認現在的動態碼 -&gt; 輸入動態碼   打開 EC2 Console   選擇 EC2 / Security Group   更新 EC2 規則 (獲取自己的外部 IP 地址更新上去)   上述的動作常常都要花我 3-5 分鐘，有時候手機丟在臥室不在身邊又要走超遠！為了滿足我的懶惰，以下是我目前的工作流程，先來看一段示範影片               上面的動作，只要正確的發出聲音指令後，Alexa Skill 便可以正確地更新相應的 Security Group 規則 (並且需要符合自己定義的 PIN Code，避免所有人都可以任意的發出命令更改)，並且只開放我家中正確對外的特定 IP 地址。如此一來，我就能直接地在家透過 SSH 連接上對應的 EC2 Instance 進行工作。   什麼是 Amazon Alexa ?   大概就像是 Apple 的 Siri、Google 推出的 Google Home …      Amazon Alexa，簡稱 Alexa，是亞馬遜公司推出的一款智能助理，最初用於 Amazon Echo 智能音箱。它具有語音交互、音樂播放、待辦事項列表、鬧鐘、流播播客、播放有聲讀物以及提供天氣，交通，體育和其他實時信息（如新聞）的功能[3]。Alexa還可以將自身用作智慧家庭系統來控制多個智能設備。該產品由Amazon Lab126開發，是一名女性語音助手。用戶可以通過安裝插件（由第三方供應商開發的其他功能）來擴展Alexa功能。       Alexa的大多數設備允許用戶通過一個特定的詞語（如「Alexa」或「Amazon」）來喚醒，剩下的（如IOS和Andriod上的Amazon移動應用與Amazon Dash Wand）則需用戶通過按按鈕來使之進入聆聽模式。一些其他廠商的手機也同樣支持用戶發出一些指令來喚醒屏幕，如「Alexa」或「Alexa wake」。到目前為止，Alexa的交流和應答僅可用英語、德語、法語、義大利語、西班牙語、葡萄牙語、日語和印地語。Alexa在加拿大可用於英語和法語（包括魁北克法語）。    來源: Wikipedia   架構概覽 (Architecture Overview)                     Alexa Skill - Security Group Manager 架構概覽            上述的架構在我看完 Alexa Skills Kit SDK for Python 的範例後，整體的實作到部署我大概花了 3 - 5 小時實作出來。目前含註解整個代碼不超過 300 行，難度並不會太高，以下具體描述一些實作細節。   實作細節   怎麼開發？   照著 Alexa Skills Kit SDK for Python 快速實作了一個可以動的版本。如果你是第一次玩 Alexa Skill，Color Picker 是一個不錯的範例，你可以找到很多不同語言的相應實做。   怎麼上傳到 AWS Lambda   建立完 AWS Lambda Function 後，便可以打包你的程式碼上傳到 Lambda 執行。   一般來說，AWS 文件可能會建議你使用 VirtualEnv 在本機建立 (如同在之前 使用 AWS Lambda 建立 Line bot 中提到的)，但我其實偷了一些懶，直接用 Docker image 加上一行 Docker 命令打包 deployment package (python):   docker run -v \"$PWD\":/var/task \"lambci/lambda:build-python3.6\" /bin/sh -c \"pip install -r requirements.txt -t package/; cp lambda_function.py package/; cd package; zip -r9 lambda.zip .\"   過程中會生成 package/ 目錄，上傳該目錄底下壓縮完的 lambda.zip 即可。   安全性設置 - IAM Policy   我在 Lambda Function 使用的 Execution Role 中定義了下列規則：   {     \"Version\": \"2012-10-17\",     \"Statement\": [         {             \"Sid\": \"UpdateSG\",             \"Effect\": \"Allow\",             \"Action\": [                 \"ec2:RevokeSecurityGroupIngress\",                 \"ec2:AuthorizeSecurityGroupEgress\",                 \"ec2:AuthorizeSecurityGroupIngress\",                 \"ec2:RevokeSecurityGroupEgress\"             ],             \"Resource\": \"arn:aws:ec2:&lt;REGION&gt;:&lt;ACCOUNT_ID&gt;:security-group/sg-XXXXXXXX\"         },         {             \"Sid\": \"DescribeSG\",             \"Effect\": \"Allow\",             \"Action\": \"ec2:DescribeSecurityGroups\",             \"Resource\": \"*\"         }     ] }   如此一來可以避免我的應用程式未經授權操作其他的 Security Group 資源，並且只允許更改特定 Security Group ID 的相關 入站(Ingres) / 出站(Egress) 規則。   Alexa 如何接受指令？   在 Amazon Alexa Developer Console 中建立完 Alexa Skill 後，可以進行相關的定義。 Alexa 會根據 Interaction Model 設定很多不同的 Intent，每個 Intent 能夠對應的相應操作行為，以下是一個當我想要輸入 PIN code 各種不同的命令範例：                     Alexa Skill - Intent 設置            如此一來，在應用程式中便可以使用動態的名稱 EnterPINCodeIntent 和變數 PIN_CODE 來執行並且獲取一些邏輯。   Lambda 如何更新 Security Group?   當 Alexa 根據觸發 Lambda 的時候，例如：Alexa, update my security group!，根據我的設置，便觸發 “UpdateMySGIntent”，於是在相關的執行邏輯在包含 PIN Code 驗證的情況，可以是以下：   @sb.request_handler(can_handle_func=is_intent_name(\"UpdateMySGIntent\")) def update_my_sg_handler(handler_input):     \"\"\"Check if PIN code is provided in session attributes alues. If provided, then     update security group with invoking source IP address.     If not, then it asks user to provide the PIN code.     \"\"\"     # type: (HandlerInput) -&gt; Response     slots = handler_input.request_envelope.request.intent.slots      if PIN_CODE_SLOT_KEY in handler_input.attributes_manager.session_attributes and handler_input.attributes_manager.session_attributes[PIN_CODE_SLOT_KEY] == pre_defined_pin_code:         speech = (\"PIN code matches, I am updating the security group.\")         handler_input.response_builder.speak(speech)          update_response = update_security_group()          speech = (\"Security group has been updated. {}\").format(update_response)         reprompt = (\"You can ask me your security group setting by saying, \"                     \"what's my security group ?\")     else:         speech = \"You did not correctly specify the PIN code or the PIN code doesn't match\"         reprompt = (\"I'm not sure what your PIN code is, \"                     \"You can say, \"                     \"my PIN code is blah blah blah....\")      handler_input.response_builder.speak(speech).ask(reprompt)     return handler_input.response_builder.response   在 Python 應用程式中，使用 DDNS 解析獲取目前外部 IP 後，更新 Security Group 的行為主要使用了 EC2 - AuthorizeSecurityGroupIngress API 執行了這項操作：   def update_security_group():     ec2 = boto3.resource('ec2', region_name=security_group_region)     security_group = ec2.SecurityGroup(security_group_id)     source_ip = get_source_ip()     cidr_ip = source_ip + '/32'      security_group.authorize_ingress(IpProtocol=\"tcp\",CidrIp=cidr_ip,FromPort=22,ToPort=22)      response = (\"The address {} has been added to the security group {} in region {}\").format(source_ip, security_group_id, security_group_region)      print(response)      return response   Alexa Skill 如何觸發 Lambda?   在 Amazon Alexa Developer Console 中可以設置自定義的 Lambda function endpoint：                     Alexa Skill - 設置 Lambda endpoint            Lambda 如何知道目前的使用者外部來源 IP   根據我的觀察，由於 Alexa 觸發 Lambda Function 時，是由 Voice Server 去戳 Lambda，並且也沒有附帶相關的 IP 訊息。因此，為了達成我的目的，我主要使用了如同架構中描述的方式獲取 DDNS 中的紀錄取得真實外部 IP 地址後，進行更改。   透過路由器韌體通常都支援更改 DDNS 的設定，通常好一點的路由器都支持一些很奇耙的功能，如果你會設定的話可以完成蠻多有趣的事情 (例如：在中華電信提供的 D-Link DSL-7740C 啟用 SNMP)。我的網路環境使用了 D-Link DSL-7740C，透過 D-Link 韌體提供的功能，能夠輕鬆的設定並且直接幫助更新我的 Dynamic DNS record，再由 Lambda Function 邏輯中主動解析獲取。   同理，另一種方式是你可以在你的環境中運行一隻小程式 (agent) 或是透過 Cronjob 定義的 Shell Script，幫助你更新 DNS 紀錄，也是一樣的方法。   若你知道 API Gateway 是什麼的話，也許可以利用 API Gateway 搭建 endpoint 並且在上個動作的階段改用 Custom HTTPS endpoint 觸發，或許在交付客戶端的 Alexa device (比如 Echo dot) 觸發時，是由客戶端主動進行訪問，這種情況下，在附帶的請求訊息中也許能知道相關的 IP，但是我沒試過，如果你試了，也歡迎在底下分享你的發現。   總結   本篇內容簡介了一項使用 Alexa Skill 進行系統維運的實作方法，展示了工程師的懶惰成性，並且分享一項參考架構，提及如何靠一張嘴巴更改防火牆規則，同時提及相關的實作細節。透過聲音命令簡化並且自動化繁瑣的更新步驟，減少了每次花費 3-5 分鐘的操作時間 (操作 10 次省下 30 分鐘、100次省下 300 分鐘 … 請自行誇飾及想像)，幫助提升日常工作中的相應生產力。   若你對於這項實作感到興趣或是有其他建議，也歡迎在底下留言與我分享！  ","categories": [],
        "tags": ["aws","amazon web services","EC2","Elastic Compute Cloud","amazon","alexa","alexa skill","echo","echo dot"],
        "url": "https://easoncao.com/security-group-manager-alexa-skill/",
        "teaser": "https://easoncao.com/assets/images/posts/2020/08/security-group-manager-alexa-skill/security-group-manager-alexa-skill-architecture.png"
      },{
        "title": "CoreDNS(kube-dns) resolution truncation issue on Kubernetes (Amazon EKS)",
        "excerpt":"This article is describing the thing you need to aware for DNS resolution issue can occur on Kubernetes. Especially when your Pod is relying on CoreDNS(kube-dns) to resolve DNS record when connecting to Amazon ElastiCache or target with large response payload, the issue potentially can happen.   Note: To help you understand the detail, I was using Amazon EKS with Kubernetes version 1.5 and CoreDNS (v1.6.6-eksbuild.1) as example.   What’s the problem   In Kubernetes, it provides an extra layer of the DNS resolution so containerized applications running on Kubernetes cluster basically heavily relying on using own DNS service to provide extra beneficial of service discovery by default, which is kube-dns add-ons.   And most common use cases are usually using CoreDNS as the default DNS resolution provider by deploying and running CoreDNS Pods within the cluster.   Containerized applications running as Pod can use autogenerated service name that map to Kubernetes service’s IP(Cluster-IP), such as my-svc.default.cluster.local. It provides more flexibility to Pods to do internal service discovery as they can use the hostname to resolve the record without remembering the private IP address within the application when deploying to other environment. The kube-dns add-ons usually have ability to resolve external DNS record so Pods can also access service on Internet.                     An overview of kube-dns running on Kubernetes - source / Service discovery and DNS (Google Cloud)            Symptom   Basically, everything runs good for general use case and you propely won’t see any issue when running your production workload. But if your application need to resolve some DNS record with large DNS response payload(like sometimes your endpoint of ElastiCache response larger payload), you might notice the issue happen and your application never correctly resolve them.   You can use some simple method by installing dig in your Pod to test and debug if you can see the difference from the result:   # Get it a try to see if the external DNS provider # # Please make sure your Pod should have accessibility to reach out to Internet # Otherwise you have to change 8.8.8.8 as your own private DNS server that Pod can reach out $ dig example.com @8.8.8.8   # Get it a try to see if CoreDNS can correctly resolve the record $ dig example.com @&lt;YOUR_COREDNS_SERVICE_IP&gt; $ dig example.com @&lt;YOUR_COREDNS_PRIVATE_IP&gt;  # Get it a try to see other record is having this issue or not $ dig helloworld.com @&lt;YOUR_COREDNS_PRIVATE_IP&gt;   For example if I have running CoreDNS Pods and kube-dns service in my Kubernetes cluster   NAMESPACE     NAME                                          READY   STATUS    RESTARTS   AGE     IP              NODE                                              NOMINATED NODE   READINESS GATES kube-system   pod/coredns-9b6bd4456-97l97                   1/1     Running   0          5d3h    192.168.19.7    XXXXXXXXXXXXXXX.compute.internal   &lt;none&gt;           &lt;none&gt; kube-system   pod/coredns-9b6bd4456-btqpz                   1/1     Running   0          5d3h    192.168.1.115   XXXXXXXXXXXXXXX.compute.internal   &lt;none&gt;           &lt;none&gt;  NAMESPACE     NAME                 TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)         AGE    SELECTOR kube-system   service/kube-dns     ClusterIP   10.100.0.10      &lt;none&gt;        53/UDP,53/TCP   5d3h   k8s-app=kube-dns   I can use commands like below to check which point can cause failure:   dig example.com @10.100.0.10 dig example.com @192.168.19.7 dig example.com @192.168.1.115  dig helloworld.com @10.100.0.10 dig helloworld.com @192.168.19.7 dig helloworld.com @192.168.1.115   If you are getting result which is both are getting failed but other DNS record is working even using CoreDNS as name server. As a DNS resolver(CoreDNS), we can identify something went wrong when CoreDNS is trying to help you forward the DNS quries for some specific target, and this is the issue we would like to discuss. However, If the Private IP of CoreDNS is working but Service IP (Cluster IP) is getting failure, or none of one are successful, you should pilot your investigation target on checking the Kubernetes networking encapsulation, such as: CNI plugin, kube-proxy, cloud provider’s setting or else that can break your Pod-Pod communication or host networking translation.   How to reproduce   In my testing, I was running Kubernetes cluster with Amazon EKS (1.5) with default deployments (such as CoreDNS, AWS CNI Plugin and kube-proxy). The issue can be reproduced when following steps with commands below:   $ kubectl create svc externalname quote-redis-cluster --external-name &lt;MY_DOMAIN&gt; $ kubectl create deployment nginx --image=nginx $ kubectl exec &lt;nginx&gt; $ apt-get update &amp;&amp; apt-get install dnsutils &amp;&amp; nslookup quote-redis-cluster   My deployment with one nginx Pod and two CoreDNS Pods already running within my EKS cluster:   NAMESPACE     NAME                          READY   STATUS    RESTARTS   AGE    IP               NODE                                                NOMINATED NODE   READINESS GATES default       pod/nginx-554b9c67f9-w9bb4    1/1     Running   0          40s    192.168.70.172   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX.compute.internal   &lt;none&gt;           &lt;none&gt; ... kube-system   pod/coredns-9b6bd4456-6q9b5   1/1     Running   0          3d3h   192.168.39.186   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX.compute.internal   &lt;none&gt;           &lt;none&gt; kube-system   pod/coredns-9b6bd4456-8qgs8   1/1     Running   0          3d3h   192.168.69.216   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX.compute.internal   &lt;none&gt;           &lt;none&gt;   And here is the problem: when using nslookup to resolve the domain (set the DNS resolver as CoreDNS Pod 192.168.39.186 instead of using Cluster IP of kube-dns, this can exclude any issue can caused by Kubernetes networking based on iptables).   The test result only return the canonical name (CNAME), without IP address (example.com):   $ kubectl exec -it nginx-554b9c67f9-w9bb4 bash root@nginx-554b9c67f9-w9bb4:/# nslookup quote-redis-cluster 192.168.39.186 Server:         192.168.39.186 Address:        192.168.39.186#53  quote-redis-cluster.default.svc.cluster.local   canonical name = example.com.   Note: The domain name example.com basically has normal A record with many IP address. (The real case is that the example.com was an Amazon ElastiCache endpoint, with returning IP addresses of ElastiCache nodes)   However, when testing other domain, basically can successfully return the IP address even using nslookup, in the same container, with same DNS resolver (192.168.39.186):   $ kubectl create svc externalname quote-redis-cluster --external-name success-domain.com  $ kubectl exec -it nginx-554b9c67f9-w9bb4 bash root@nginx-554b9c67f9-w9bb4:/# nslookup my-endpoint 192.168.39.186 Server:         192.168.39.186 Address:        192.168.39.186#53  my-endpoint.default.svc.cluster.local     canonical name = success-domain.com. Name:   success-domain.com. Address: 11.11.11.11 Name:   success-domain.com. Address: 22.22.22.22   And this is the issue I would like to talk about. Let’s break down and understand why having difference in the result.   Deep dive into the root cause   Let’s start to break down what happen inside. To better help you understand what’s going on, it is required to know:      192.168.70.172 (Client - nslookup): The nginx Pod, in this Pod I was running nslookup to test the DNS resolution ability.   192.168.39.186 (CoreDNS): The real private IP of CoreDNS Pod, play as DNS resolver for kube-dns service.   192.168.69.216 (CoreDNS): The real private IP of CoreDNS Pod, play as DNS resolver for kube-dns service.   192.168.0.2 (AmazonProvidedDNS): The default DNS resolver in VPC and can be used by EC2 instances.   On EKS, the DNS resolution flow can be looked like:                     The DNS resolution flow on EKS            First, the Pod will issue a DNS query to CoreDNS. Once the CoreDNS receives the query, it will check if have any cache DNS record exists, otherwise, it would follow the setting mentioning in the configuration to forward the reqeust to upstream DNS resolver.   The following is that CoreDNS will look up the DNS resolver according to the configuration /etc/resolv.conf of CoreDNS node(In my environment it was using AmazonProvidedDNS):   apiVersion: v1 data:   Corefile: |     .:53 {         forward . /etc/resolv.conf         ...     }   Based on the model, responses will follow the flow and send back to the client. The normal case(happy case) is that we always can query DNS A records and can correctly have addresses in every response:                     Normal DNS resolution packet, can see A record responsed(Using nslookup)            Right now, let’s move on taking a look what’s going on regarding the issue:   1) On the client side, I was collecting packet and only can see the response with CNAME record, as we expected on nslookup output:                     The network packet collected from client - only get the response with CNAME even asking for A record.            2) On the CoreDNS node, I also collected the packet and can see:      The CoreDNS Pod was asking the record with AmazonProvidedDNS   In the response, it only have CNAME record   192.168.70.172 -&gt; 192.168.39.186 (Client query A quote-redis-cluster.default.svc.cluster.local to CoreDNS) 192.168.39.186 -&gt; 192.168.0.2    (CoreDNS query A quote-redis-cluster.default.svc.cluster.local to AmazonProvidedDNS) 192.168.0.2    -&gt; 192.168.39.186 (AmazonProvidedDNS response the record, with CNAME) 192.168.39.186 -&gt; 192.168.70.172 (CoreDNS Pod response the CNAME record)                     The network packet collected from client - only get the response with CNAME even asking for A record.            And if look the packet closer collected on CoreDNS node, here is they key point: The truncated flag (TC flag) was true, which means the DNS response is truncated.                     The message is truncated in the DNS query response (CoreDNS Node)            At this stage, the issue can be identified the DNS response was truncated.   Why the DNS response (message) was truncated?   When you see the message truncation, you probably will say: “Holy … sh*t, DNS response is missing, upstream DNS resolver must eat the payload and did not working properly! “. However, the truth is, this is expected behavior according to the design of DNS when it initially comes to first 19s.      DNS primarily uses the User Datagram Protocol (UDP) on port number 53 to serve requests. Queries generally consist of a single UDP request from the client followed by a single UDP reply from the server. — wikipeida    The basic payload can be allowed in DNS query generally won’t 512 bytes. It basically can perfectly work in first 19s, however, lately 20s, with the scale of Internet was growing, people start to aware the original design unable to fully satisfy the requirement and they would like to include more information in DNS query(like the usage of IPv4). According to RFC#1123, it initiated the standard in case if a single DNS payload contain over 512 bytes limit for UDP:      It is also clear that some new DNS record types defined in the future will contain information exceeding the 512 byte limit that applies to UDP, and hence will require TCP. Thus, resolvers and name servers should implement TCP services as a backup to UDP today, with the knowledge that they will require the TCP service in the future.    Therefore, in RFC#5596 basically mentioning the behavior of “DNS Transport over TCP”. Solutions can be: use EDNS or retransmit the DNS query over TCP if truncation flag has been set (TC Flag):      In the absence of EDNS0 (Extension Mechanisms for DNS 0), the normal behaviour of any DNS server needing to send a UDP response that would exceed the 512-byte limit is for the server to truncate the response so that it fits within that limit and then set the TC flag in the response header.       When the client receives such a response, it takes the TC flag as an indication that it should retry over TCP instead.    Therefore, when the length of the answer exceeds 512 bytes(The upstream server should set TC flag to tell the downstream the message is truncated), when both client and server support EDNS, larger UDP packets are used including in additional UDP packet. Otherwise, the query is sent again using the Transmission Control Protocol (TCP). TCP is also used for tasks such as zone transfers. Some resolver implementations use TCP for all queries.   How to remedy the issue?   The symptom generally happen when Pods was trying to resolve the DNS record in UDP through CoreDNS. If the domain name contains payload exceeds 512 bytes, it can hit the default limit of UDP DNS query. When the payload over 512 bytes, it is expected to get the response with truncation has been set (TC flag).   However, when receiving payload with TC flag set up and can think of the response is truncated, by default(on Amazon EKS), CoreDNS doesn’t apply the retransmit behavior by using TCP, instead, CoreDNS only response the truncated message and sent it back to the client. This workflow cause the client can aware the DNS query message was missing.   Therefore, to remedy the issue, here are possible solutions can be adopted:   Solution 1: Using EDNS0   In common use case, the default 512 bytes generally can satisfy most usage because we will not expect that our DNS shouldn’t contain too much IP addresses information. However, in some cases, such as:      To balance my workload, I have the resolution will response many targets, because I am using DNS to do round-robin.   It is an endpoint of ElastiCache with many nodes.   Other use case can include long message in DNS response.   If you can expect the DNS response will have larger payload, basically, client still able to send additional EDNS information to increase the buffer size in single UDP response. This still able to ask CoreDNS to forward the additional section using EDNS0.   The workflow can be:      1) Resolve the domain by querying CNAME   2) Once get the mapping domain name, can send another A record query with EDNS option   (You can implement the logic in your own application. Because it has many different way to enable EDNS option, please refer to the documentation provided by your programming language or relevant library.)   Here is an example regarding the output can see when using dig   $ dig -t CNAME my-svc.default.cluster.local ... (Getting canonical name of the record, e.g. example.com) ...  $ dig example.com ;; Got answer: ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 51739 ;; flags: qr rd ra; QUERY: 1, ANSWER: 22, AUTHORITY: 0, ADDITIONAL: 1  ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 4096 ; COOKIE: 7fb5776972bf2aa4 (echoed) ;; QUESTION SECTION: ; example.com. IN A  ;; ANSWER SECTION: example.com. 15 IN A 10.4.85.47 example.com. 15 IN A 10.4.83.252 example.com. 15 IN A 10.4.82.121 ... example.com. 15 IN A 10.4.82.186   In the output, we can see that, by default, the dig will add optional setting to increase allowed payload size in UDP query, in this case it was using 4096 bytes:  ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 4096   Below is a sample packet using dig with EDNS:                     Request with EDNS0 (Query) - Can see the payload size has been set up as 4096 bytes in additional section                              Request with EDNS0 (Response) - Can see the total DNS response size is up to 3296 bytes, which exceeds default 512 bytes limit            As the method generally need to implement in the application. If you would like to increase the default buffer size for every UDP quries sent by CoreDNS, you can use bufsize plugin to limits a requester’s UDP payload size.   Here is an example to enable limiting the buffer size of outgoing query to the resolver (172.31.0.10):   . {     bufsize 512     forward . 172.31.0.10 }   However, it would ask CoreDNS to allow larger payload size in every DNS queries, it may cause DNS vulnerabilities potentially with performance degraded. Please refer to the CoreDNS documentation to get more detail.   Solution 2: Having TCP retransmit when the DNS query was truncated (Recommended)   As mentioned, the normal behaviour of any DNS server needing to send a UDP response that would exceed the 512-byte limit is for the server to truncate the response so that it fits within that limit and then set the TC flag in the response header. When the client receives such a response, it takes the TC flag as an indication that it should retry over TCP instead.   So far, by analyzing the network flow with packets, we can certainly sure CoreDNS doesn’t help us to perform the retransmit over TCP if getting message truncation. So the question is, can we ask the CoreDNS should retry with TCP if getting message is truncated?      And the answer is … YES!.   Since 1.6.2, CoreDNS should support syntax prefer_udp to handle the truncated responses when forwarding DNS queries:   The explanation of the option prefer_udp:     Try first using UDP even when the request comes in over TCP. If response is truncated (TC flag set in response) then do another attempt over TCP. In case if both force_tcp and prefer_udp options specified the force_tcp takes precedence.    Here is an example to add the option for forward plugin:   forward . /etc/resolv.conf {     prefer_udp }   This option generally can be added in your configuration if you can aware a truncated response is received but CoreDNS doesn’t handle it. However, it is still recommended to get it a try and see any performance issue can cause. Consider scale out your CoreDNS Pods in your environment would be helpful if having large scale cluster.   Conclusion   In this article, it dive deep into an DNS resolution issue regarding CoreDNS when running workload on Amazon EKS and break down the detail by inspecting network packet. The root cause relates to the message was truncated due to the response payload size exceeds 512 bytes, which result in the client (Pod) was unable to get the correct result with IP addresses. The response payload will return detail with TC flag set up.   This issue generally related to the design of DNS in UDP and it is expected to get the message truncation if having larger payload. In addition, as mentioned in RFC#1123, the requester should have responsibility for handling the situation if aware that TC flag has been set up. This article was mentioning the detail and the flow according to packet analyzing.   To remedy the problem, this article also mentioned several methods can be applied on client side or CoreDNS, by using EDNS or apply TCP retransmit, both are able to be applied in CoreDNS.   References      CoreDNS Pull Request#3110  ","categories": [],
        "tags": ["aws","amazon web services","amazon","Kubernetes","k8s","EKS","Elastic Kubernetes Service","EDNS","DNS","CoreDNS","kube-dns","RFC"],
        "url": "https://easoncao.com/coredns-resolution-truncation-issue-on-kubernetes-kube-dns/",
        "teaser": "https://easoncao.com/assets/images/posts/2020/10/coredns-resolution-truncation-issue-on-kubernetes-kube-dns/eks-dns-resolution-flow.png"
      },{
        "title": "Run application on EC2 and gather metric to Amazon Managed Service for Prometheus (Amazon Prometheus / AMP)",
        "excerpt":"What’s Amazon Managed Service for Prometheus (Amazon Prometheus / AMP)      Amazon Managed Service for Prometheus is a serverless, Prometheus-compatible monitoring service for container metrics that makes it easier to securely monitor container environments at scale. With AMP, you can use the same open-source Prometheus data model and query language that you use today to monitor the performance of your containerized workloads, and also enjoy improved scalability, availability, and security without having to manage the underlying infrastructure. source    There has a good article was dscribing the service feature on AWS Blog Post:      Getting Started with Amazon Managed Service for Prometheus   What if I would like to gather metric without having Kubernetes/ECS cluster?   The most of example was using EKS/ECS or Kubernetes Cluster as example. What if I would like to simply gather metrics for my application and got benefit without managing Prometheus so AWS would ensure the high availability? Generally, the idea is simple, however, it still takes me some times to do some research and get it a try. So it inspired me to write down the detail steps here.   If you would like to , you should have:      Application: Your application should follow the data model that supported by Prometheus (e.g. go_gc_duration_seconds_count 62) and expose your metrics with HTTP server, end with path /metrics.   AWS SigV4 Proxy: By default, when using remote_write supported  The AWS SigV4 Proxy will sign incoming HTTP requests and forward them to the host specified in the Host header.   Standard Prometheus Server (or other agent to gather metrics): The Prometheus Server requires to be installed so it can from your application (/metrics) and ship metric to the URL as specified in remote_write section.   Overview                     Architecture overview               Monitoring Server (let’s say it is EC2 instance A): This instance is running Grafana dashboard to see my metrics   Application Server (let’s say it is EC2 instance B): The instance is running my application and standard Prometheus(gathering metrics)   A Workspaces in my Amazon Prometheus (AMP) in us-east-1: Used to receive metrics and provide consist readable endpoint so Grafana was able to query metrics   Configuration steps   To demonstrate the entire working flow, I am going to use several docker images to quickly show how to do that. If you requires to run standalone application, you can use those Docker images, or build the binary by yourself by referencing the Dockerfile and documentations.      prom/prometheus: Standard Prometheus container image, binaries can be found on official documentation here.   grafana/grafana: Grafana dashboard   prometheus-golang: Sample application from sysdig for Prometheus metrics. (Source)   public.ecr.aws/aws-observability/aws-sigv4-proxy: AWS SigV4 Proxy to sign incoming HTTP requests and forward them   1) Create a workspace in Amazon Prometheus (AMP)   If you got the preview access, the first step is to create a workspace in Amazon Prometheus:                     Create a workspace in AMP            So far it is simple and you can easily click one button to complete the creation. It usually takes few minutes as it was doing provisioning in the backend.   2) Set up IAM user/role permission for your Grafana dashboard   Access to Amazon Managed Service for Prometheus actions and data requires credentials as AMP is using IAM for ensuing the data security. Therefore, it is required to have SigV4/IAM authentication when accessing the endpoint as it provides a consistent query endpoint for your AMP resource once you created a workspace. For example, the AMP resource in us-east-1 region can provide endpoint below:      https://aps-workspaces.us-east-1.amazonaws.com/workspaces/ws-XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX/api/v1/query   When adding the data source in my Grafana dashboard, it needs to follow the authentication model to access the data. To provide the access for my dashboard, in the example, I simply created a IAM user(amp-gra-user) with plain Access Key &amp; Secret Key. To esnure it has permission to access AMP resource, I attached managed policy AmazonPrometheusQueryAccess with following rules to provide readable access:   {     \"Version\": \"2012-10-17\",     \"Statement\": [         {             \"Action\": [                 \"aps:GetLabels\",                 \"aps:GetMetricMetadata\",                 \"aps:GetSeries\",                 \"aps:QueryMetrics\"             ],             \"Effect\": \"Allow\",             \"Resource\": \"*\"         }     ] }                     Create an IAM User for Grafana dashboard            You still can use IAM role/attached EC2 IAM role as Grafana generally can use those permission if enabled loading AWS SDK config, as in my next step.   As the managed policy might be changed once the service is generally available (GA), please refer to the Amazon Prometheus document - IAM permissions and policies to get more detail.   3) Run Grafana dashboard on my monitoring server (EC2 instance A)   This step I used Docker to run my Grafana dashboard. As Amazon Managed Service for Prometheus is integrated with AWS Identity and Access Management (IAM) to ensure that all calls to Prometheus APIs, such as query and ingest, are secured with IAM credentials.      By default, the Prometheus data source in Grafana assumes that Prometheus requires no authentication. To enable Grafana to take advantage of AMP authentication and authorization capabilities, you will need to enable SigV4 authentication support in the Grafana data source. Reference    To enable SigV4 on Grafana, I run my Grafana with the AWS_SDK_LOAD_CONFIG and GF_AUTH_SIGV4_AUTH_ENABLED environment variables set to true. The GF_AUTH_SIGV4_AUTH_ENABLED environment variable overrides the default configuration for Grafana to enable SigV4 support. sigv4_auth_enabled   $ docker run -d \\     -p 3000:3000 \\     --name=grafana \\     -e \"GF_AUTH_SIGV4_AUTH_ENABLED=true\" \\     -e \"AWS_SDK_LOAD_CONFIG=true\" \\     grafana/grafana   Once the Grafana is up and running, the next thing is that go to the AMP console then copy and paste the endpoint URL in your Grafana. You can find section Endpoint - remote write URL &amp; Endpoint - query URL in the console:                     Endpoints in AMP console            Open http://localhost:3000 (or http://&lt;Grafana Dashboard IP&gt;:3000), you should see the login page, use the following default username and password to enter the Dashboard:   Username: admin Password: admin   You can use same password if you are doing testing purpose. (Please change the password if you are running dashboard in production environment due to it will have security concern without changing it, any attacker can enter and view your metrics by using default passwords.)   The Grafana requires to use query URL to read the metric, so go to the Grafana Dashboard and add a new Data Source. You can find the setting in the left navigation bar:                     Grafana Configurations            Select ‘Prometheus’ as new data source to add, fill the several information as below:                     Grafana add data source               HTTP &gt; URL: fill the endpoint URL you just copied (Endpoint - query URL), please remove the /api/v1/query string that is appended to the URL, because the Prometheus data source will automatically append it. For example:            Endpoint (query URL): https://aps-workspaces.us-east-1.amazonaws.com/workspaces/ws-XXXXX-XXXX-XXX-XXXX-XXXXXX           Auth &gt; SigV4 auth: Enable the selection   SigV4 Auth Details: Select Authentication Provider (Using Access &amp; Secret key or else). In my testing I was filling Access Key ID &amp; Secret Access Key with the credential of my IAM User (amp-gra-user).   Then click Save &amp; Test, if everything works fine, you will see the message Data source is working:                     Data source is working            If not and shows other error messages, please refer to the following documentation to do troubleshooting:      Set up Grafana open source or Grafana Enterprise for use with AMP - Troubleshooting if Save &amp; Test doesn’t work   At this step we can ensure Grafana can query our metrics on AMP, but there has no data point yet, so the next step is to gather and write metrics to AMP.   4) On application server (EC2 instance B, with private IP address: 172.31.21.133)   I attached an IAM Role to my EC2 instance B with following IAM policy (To write metric, at least to ensure you have aps:RemoteWrite permission, as AmazonPrometheusRemoteWriteAccess), this can allow AWS SigV4 proxy can use the permission and writes metrics to AMP:   {     \"Version\": \"2012-10-17\",     \"Statement\": [         {             \"Effect\": \"Allow\",             \"Action\": [                 \"aps:RemoteWrite\",                 \"aps:QueryMetrics\",                 \"aps:GetSeries\",                 \"aps:GetLabels\",                 \"aps:GetMetricMetadata\"             ],             \"Resource\": \"*\"         }     ] }   When your Prometheus server is ingesting metrics on your EC2 instance B, to secure the ingestion, it is requires to use SigV4 authentication when writing metrics to AMP. However, the Prometheus server generally only can use basic auth to do Authorization for remote_write. Therefore, it is required to run a SigV4 proxy to provide access on port 8005 when forwarding remote write traffic.   $ docker run -d -p 8005:8005 public.ecr.aws/aws-observability/aws-sigv4-proxy:1.0 --name aps --region us-east-1 --host aps-workspaces.us-east-1.amazonaws.com --port :8005   So the proxy will provide service on port 8005 and can be accessed via localhost:8005 or 172.31.21.133:8005.   Note: If you are not running resource in us-east-1 region, replace option --region us-east-1 and --host aps-workspaces.us-east-1.amazonaws.com as your own.   Once the SigV4 proxy is up and running, I am going to run a sample Go applcation:   $ git clone https://github.com/sysdiglabs/custom-metrics-examples $ docker build custom-metrics-examples/prometheus/golang -t prometheus-golang $ docker run -d --rm --name prometheus-golang -p 80:8080 prometheus-golang   The Go application will expose the metric with path/metrics, so I can query them if using curl:   $ curl http://localhost/metrics | head  # HELP go_gc_duration_seconds A summary of the GC invocation durations.-     0 # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 2.9336e-05 go_gc_duration_seconds{quantile=\"0.25\"} 3.1688e-05 go_gc_duration_seconds{quantile=\"0.5\"} 3.459e-05 go_gc_duration_seconds{quantile=\"0.75\"} 4.1515e-05 go_gc_duration_seconds{quantile=\"1\"} 8.7687e-05 go_gc_duration_seconds_sum 0.00251097 go_gc_duration_seconds_count 62 ...   5) Set up the Prometheus server to collect metrics   I created a configuration for Prometheus and scrape metric for Prometheus server itself (http://localhost:9090/metrics) and my Go application (Go application will expose metric through 172.31.21.133:80/metrics):      remote_write: The section below can send metric to the remote endpoint. In this case, the url need to be specified through SigV4 proxy.   [conf.yml]   #global config global:   scrape_interval:     15s   evaluation_interval: 5s   scrape_timeout:     10s   external_labels:     monitor: 'monitor'  # Scrape configs only contain one scrape target scrape_configs:   - job_name: 'prometheus'     # Override the global default and scrape targets from this job every 5 seconds.     scrape_interval: 5s     static_configs:       - targets: ['localhost:9090', '172.31.21.133:80'] remote_write:   - url: 'http://172.31.21.133:8005/workspaces/ws-XXXXXX-XXXX-XXX-XXXX-XXXXXXX/api/v1/remote_write'   Then, start the Prometheus server to scrape metric:   $ docker run \\      -p 9090:9090 \\      -v $PWD/conf.yml:/etc/prometheus/prometheus.yml \\      prom/prometheus   Once the Prometheus server is up and running, you would expect to see targets and know the health status:                     Prometheus targets            5) View the metric !   Right now, if the Prometheus server can correctly write metric through AWS SigV4 Proxy, you would expect to view the metrics on Grafana dashboard:                     View collected metrics on AMP in Grafana dashboard            Troubleshooting   How to use curl to query my Amazon Prometheus to check if the connectivity, or, IAM authentication is working or not?   To test the Sigv4, you can run the proxy and test the function with curl command. If you also would like to specify the IAM credential, choose either one of method to test the proxy and see if it can route the traffic for you:   # Env vars $ docker run --rm -ti \\   -e 'AWS_ACCESS_KEY_ID=&lt;YOUR ACCESS KEY ID&gt;' \\   -e 'AWS_SECRET_ACCESS_KEY=&lt;YOUR SECRET ACCESS KEY&gt;' \\   -p 8005:8005 \\   public.ecr.aws/aws-observability/aws-sigv4-proxy:1.0 --name aps --region us-east-1 --host aps-workspaces.us-east-1.amazonaws.com --port :8005  # Shared Credentials $ docker run --rm -ti \\   -v ~/.aws:/root/.aws \\   -p 8005:8005 \\   -e 'AWS_PROFILE=&lt;SOME PROFILE&gt;' \\   public.ecr.aws/aws-observability/aws-sigv4-proxy:1.0 --name aps --region us-east-1 --host aps-workspaces.us-east-1.amazonaws.com --port :8005   Once the aws-sigv4-proxy is up and running, you can simply to use curl to test the local endpoint:      An example with normal request but did not have query:   $ curl http://localhost:8005/workspaces/ws-XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX/api/v1/query -vvv  *   Trying 127.0.0.1... * TCP_NODELAY set * Connected to localhost (127.0.0.1) port 8005 (#0) &gt; GET /workspaces/ws-XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX/api/v1/query HTTP/1.1 &gt; Host: localhost:8005 &gt; User-Agent: curl/7.53.1 &gt; Accept: */* &gt; &lt; HTTP/1.1 400 Bad Request &lt; Content-Type: application/json &lt; Date: Tue, 09 Feb 2021 15:02:56 GMT &lt; Server: amazon &lt; X-Amzn-Requestid: XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX &lt; Content-Length: 125 &lt; * Connection #0 to host localhost left intact {\"status\":\"error\",\"errorType\":\"bad_data\",\"error\":\"invalid parameter 'query': 1:1: parse error: no expression found in input\"}      An example with normal request by feeding query according to HTTP API:   $ curl http://localhost:8005/workspaces/ws-XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX/api/v1/query?query=up -vvv  *   Trying 127.0.0.1... * TCP_NODELAY set * Connected to localhost (127.0.0.1) port 8005 (#0) &gt; GET /workspaces/ws-XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX/api/v1/query?query=up HTTP/1.1 &gt; Host: localhost:8005 &gt; User-Agent: curl/7.53.1 &gt; Accept: */* &gt; &lt; HTTP/1.1 200 OK &lt; Content-Type: application/json &lt; Date: Tue, 09 Feb 2021 15:10:49 GMT &lt; Server: amazon &lt; X-Amzn-Requestid: XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX &lt; Content-Length: 63 &lt; * Connection #0 to host localhost left intact {\"status\":\"success\",\"data\":{\"resultType\":\"vector\",\"result\":[]}}      An example with failed response due to lack of IAM permission(aps:QueryMetrics) for my IAM user/role:   $ curl http://localhost:8005/workspaces/ws-XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX/api/v1/query -vvv  *   Trying 127.0.0.1... * TCP_NODELAY set * Connected to localhost (127.0.0.1) port 8005 (#0) &gt; GET /workspaces/ws-XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX/api/v1/query HTTP/1.1 &gt; Host: localhost:8005 &gt; User-Agent: curl/7.53.1 &gt; Accept: */* &gt; &lt; HTTP/1.1 403 Forbidden &lt; Content-Length: 200 &lt; Content-Type: application/json &lt; Date: Tue, 09 Feb 2021 15:07:55 GMT &lt; Server: amazon &lt; X-Amzn-Errortype: AccessDeniedException &lt; X-Amzn-Requestid: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx &lt; X-Amzn-Requestid: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx &lt; * Connection #0 to host localhost left intact {\"Message\":\"User: arn:aws:iam::111111111111:user/myIAMUser is not authorized to perform: aps:QueryMetrics on resource: arn:aws:aps:us-east-1:111111111111:workspace/ws-XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\"}   Conclusion   In this article, it shows a example to use Amazon Managed Service for Prometheus (AMP) to gather metrics when running standalone application on EC2 instance, rather than having Kubernetes to deploy. As it might be difficult to understand what things need to be noticed, so I shared configuration and steps. Giving the overview and share some tips you have to know if you are trying to push metrics to AMP.   If you are interested to learn more, I also try to summarize a couple of things you may want to know as an online learning material, feel free to click the link to get more detail:      Learn Amazon Prometheus in 1 day   References      Demo Video - Amazon Managed Service for Prometheus (AMP) &amp; Amazon Managed Service for Grafana (AMG)   AWS SigV4 Proxy   Prometheus configuration  ","categories": [],
        "tags": ["aws","amazon web services","amazon","Prometheus","AMP","Amazon Managed Service for Prometheus","EC2","Elastic Compute Cloud"],
        "url": "https://easoncao.com/run-app-on-ec2-and-gather-metric-to-amazon-prometheus-amp/",
        "teaser": "https://easoncao.com/assets/images/posts/2021/02/run-app-on-ec2-and-gather-metric-to-amazon-prometheus-amp/ec2-with-amp-overview.png"
      },{
        "title": "身為 DevOps 你會想知道的 AWS 技巧 - 使用 AWS Lambda 和 Amazon SNS 取得來自 AWS CodeCommit (Git) 的檔案變更通知",
        "excerpt":"這篇內容主要是轉載我 2019 年 2 月公開發佈在 AWS 官方 DevOps 部落格的內容，在這篇內容中，主要展示了如何以 AWS Lambda 及 Amazon SNS 接收來自 AWS CodeCommit (Git Repository) 的檔案變更通知。由於屆時將滿 2 年 (時間過得真快)，覺得有必要翻譯成中文文件，以幫助中文的讀者也能夠了解這項內容。   由於原內容為英文，如果有興趣，原文請見：      Using AWS Lambda and Amazon SNS to Get File Change Notifications from AWS CodeCommit。   簡介   通知一直是 DevOps 工作流程中很重要的一環，幾乎很多牽扯維運相關的工作都少不了主動通知的行為。當然，你可以在任何 CI/CD 的階段中透過你已知的方法於任何邏輯中設置。但在這篇 Blog Post 中，我將會展示如何整合 AWS Lambda 和 Amazon SNS 以擴展 AWS CodeCommit 的功能性。特別的是，這篇解決方內容案描述了當 AWS CodeCommit 一旦有任何更新，如何從 Amazon SNS 中接收檔案變更和 Commit 訊息。以下主要簡介相應使用到的 AWS 服務：           Amazon SNS: Amazon Simple Notification Service (Amazon SNS) 是一項全受管簡訊服務，並且能夠幫助你發佈訊息至訂閱者。其非常容易使用並且支援任何規模大小的使用場景。            AWS Lambda: 是一種無伺服器的運算服務，可讓您執行程式但不必佈建或管理伺服器、建立工作負載感知叢集擴展邏輯、維護事件整合或管理執行階段。使用 Lambda，您可以透過虛擬方式執行任何類型的應用程式或後端服務，全部無需管理。在這篇內容中，我使用了 Lambda Function 以推送訊息至 Amazon SNS 以發佈檔案更新。 Amazon CloudWatch            Amazon CloudWatch 提供資料和可行的洞見以監控應用程式、回應整個系統的效能變化、優化資源使用情況，以及透過整合的檢視來查看運作狀態。你可以也設定簡易的規則來偵測 AWS 資源的變更。在 CloudWatch 捕捉到來自你 AWS 資源的事件更新後，便能觸發特定的目標執行相應的操作 (例如：觸發一個 Lambda Function)       為幫助你快入了解並且部署這項解決方案，我同時建立了一個 AWS CloudFormation template 以供這篇內容使用。AWS CloudFormation 是一個管理工具並且能夠使用通用的語法幫助你描述並且部署 AWS 相關的基礎建設和資源。   概覽 (Overview)                     架構概覽            AWS CodeCommit 支持了多項實用的 CloudWatch Event，透過 CloudWatch Event，這能夠幫助你監控 AWS 資源的使用事件變更並且進行通知。透過設定一些簡單的觸發規則，你便能夠偵測有關 branch 或是 Repository 的變更。   在這個範例中，我為一個 AWS CodeCommit Repository 建立了一個 CloudWatch event rule (事件規則)，如此一來，任何相應的變更事件便會觸發一個 Lambda Function。當對於 CodeCommit 的變更執行時，CloudWatch 便偵測該事件並且執行自定義 Lambda Function 的觸發。   當這個 Lambda Function 被觸發，下列的行為將被依序執行：      使用 CodeCommit API 中的 GetCommit 操作取得最後一次的 Commit 紀錄。因為我想要比較原先上一次的 Commit ID 和最新的一筆，以進行變更的檢查。   對每一個 Commit 紀錄，使用 GetDifferences API 操作取得任何紀錄追蹤檔案的新增、變更和刪除資訊。   從比較的結果中，合併相關的變更資訊，並且，將這項資訊依照定義好的 Email 訊息格式推送到 Lambda Function 中環境變數中定義的 Amazon SNS (SNS topic) 資源。   允許 Reviewers (可能是 Code Reviewers, operation team … 等) 訂閱該 SNS Topic。如此一來，任何有關 CodeCommit 相應的更新都能推播到相關的訂閱者。   這個範例使用了 Python 和 Boto3 實作這項功能。完整的程式碼已被公開在 GitHub 上，你可以在 AWS 官方的 GitHub 上找到 - aws-codecommit-file-change-publisher 該範例。   開始動手做   為了幫助你快速搭建這項解決方案，該專案包含了一個 AWS CloudFormation template (codecommit-sns-publisher.yml)。這個 template 使用了 AWS Serverless Application Model (AWS SAM) 用以定義 CodeCommit 通知 Serverless 應用程式必須的組建，並且使用簡潔的語法表示。   一旦部署後，這個 template 會被直接轉譯成 AWS CloudFormation stack 資源並且建立一個 SNS Topic, CloudWatch event rule 和一個 Lambda Function。這個 Lambda Function 程式碼已經展示了一個簡易的通知功能用例。你可以使用這項範例程式自行定義你的邏輯，甚至是使用其他 AWS SDK for Python (Boto3) 提供的 API 和方法擴展功能。   預先準備工作   在開始部署該範例之前，你必須先建立/擁有一個 CodeCommit repository，以便後續使用 AWS CloudFormation template 執行相應的操作。在這篇文章中，我在 Ohio 區域 (us-east-2) 建立了一個乾淨的 CodeCommit Repository (sample-repo) 以便展示一個 CodeCommit Repository 在特定 branch 上有檔案修改更新。   如果你已經擁有一個 CodeCommit Repository，你可以繼續往下閱讀下列步驟以部署 template 和 Lambda Function。   部署 AWS CloudFormation template 及 Lambda function           下載 aws-codecommit-file-change-publisher 上的原始碼            登入至 AWS Console 及 選擇你 CodeCommit Repository 所在的區域。並且，手動建立一個 S3 Bucket 並且上傳 AWS Lambda deployment package (封裝好的 zip 文件 - codecommit-sns-publisher.zip)。如果你不確定如何建立 S3 Bucket，請參考 Amazon S3 Console 的操作手冊 - How Do I Create an S3 Bucket? 以引導你完成            上傳 Lambda deployment package 至你剛剛建立好的 S3 Bucket       在這個範例中，我在相同區域 (Ohio, us-east-2) 建立了一個 S3 Bucket 名為 codecommit-sns-publisher 並且透過 Amazon S3 上傳 Lambda deployment package：                     上傳 Lambda deployment package 至 S3                    在 AWS Management Console, 選擇 CloudFormation 導引到該服務。你也可以直接使用這個連結訪問 - https://console.aws.amazon.com/cloudformation            選擇 Create Stack            在 Select template 頁面，選擇 Upload a template to Amazon S3，指定剛剛下載的 codecommit-sns-publisher.yml template 檔案上傳進行下一步                         選擇 CloudFormation template               在指定參數項目中，填寫以下資訊：            Stack Name: codecommit-sns-publisher (你可以指定自己的名稱)       CodeS3BucketLocation: codecommit-sns-publisher (指定你剛剛在建立 S3 Bucket 步驟中上傳 Lambda deployment package 的 S3 Bucket 名稱)       CodeS3KeyLocation: codecommit-sns-publisher.zip (這是上傳 Lambda deployment package 的名稱, 物件應為 zip 檔案)       CodeCommitRepo: sample-repo (你 CodeCommit repository 的名稱)       MainBranchName: master (指定你想觸發事件的 branch 名稱)       NotificationEmailAddress: user@example.com (指定要訂閱 SNS topic 的 Email 地址, 這個設置可以讓 CloudFormation template 建立一個 SNS topic 以推送通至訂閱者)                             指定參數 Parameters                    選擇 Next            在 Review 頁面中，於 Capabilities 項目底下，勾選以下選項：             I acknowledge that AWS CloudFormation might create IAM resources.       I acknowledge that AWS CloudFormation might create IAM resources with custom names.                             選擇 Capabilities               在 Transforms 項目，點擊 Create Change Set。AWS CloudFormation 便會開始執行 template 轉譯的工作並且建立一個 Change Set                     建立 Change Set               在完成轉譯後，選擇 Execute 以建立 AWS CloudFormation stack                     執行建立 CloudFormation Stack            在 Stack 建立完成後，若資源有正確建立，你應該可以預期會在信箱收到 SNS 訂閱確認信，請點擊確認，看到以下內容即成功訂閱：                     SNS 訂閱確認成功訊息            在你訂閱了 SNS Topic 之後，你便可以在 AWS CloudFormation Console 檢查對應建立出來的資源。如果你想要監控 Lambda Function 的執行狀態，點擊 Resources 可以開啟 Lambda Function(SNSPublisherFunction)：                     CloudFormation 部署的資源            現在，你可以在本機嘗試推送一個 Commit 至遠端的 AWS CodeCommit Repository   Step 1. 下載你的 (git clone) CodeCommit repository 至你的本機電腦。更多有關連接到 AWS CodeCommit 和驗證的資訊，請參考 AWS CodeCommit 使用手冊中的 Connect to an AWS CodeCommit Repository 內容幫助你設定。在這個範例中，展示了如何下載位於 Ohio 區域 (us-east-2) 名為 sample-repo 的 repository：   git clone ssh://git-codecommit.us-east-2.amazonaws.com/v1/repos/sample-repo   Step 2. 進入至該專案目錄並且見一粒一個純問自檔案   cd sample-repo/ echo 'This is a sample file' &gt; newfile   Step 3. 新增一個 Commit 並且紀錄這次的修改   git add newfile git commit -m 'Create initial file'   [輸出]   [master (root-commit) 810d192] Create initial file 1 file changed, 1 insertion(+) create mode 100644 newfile   Step 4. 推送到遠端的 CodeCommit Repository   git push -u origin master:master   [輸出]   Counting objects: 100% (3/3), done. Writing objects: 100% (3/3), 235 bytes | 235.00 KiB/s, done. … * [new branch]      master -&gt; master Branch 'master' set up to track remote branch 'master' from 'origin'.   在本機的 Commit 更改推送到遠端 CodeCommit Repository 後，將會觸發 CloudWatch event 並且偵測到這次的更新。你通常可以在訂閱的 Email 帳戶中預期看到以下的通知訊息：   Commit ID: &lt;Commit ID&gt; author: [YourName] (YourEmail@example.com) - &lt;Timestamp&gt; +0000 message: Create initial file  File: newfile Addition - Blob ID: &lt;Blob ID&gt;   總結   在這篇內容中，我展示了如何使用 AWS CloudFormation template 快速部署一個範例的解決方案，能夠幫助你的維運或是開發團隊追蹤任何有關 CodeCommit Repository 的更新。本篇示例的 CloudFormation template 及 Lambda Function 同時也在 AWS 官方的 GitHub 上被公開 - aws-codecommit-file-change-publisher。你可以依據你的需求參考這個範例程式幫助你自定義 Email 的內容 (例如加上 HTML 樣式)，亦或者是新增其他有用的訊息至你的 Email 訊息中。   若你對於這項實作感到興趣或是有其他建議，也歡迎在底下留言與我分享。當然，如果有任何關於開源專案的反饋，也歡迎開啟 GitHub issue 甚至是開啟 GitHub pull request 貢獻！  ","categories": [],
        "tags": ["aws","amazon web services","Lambda","Lambda Function","severless","CodeCommit","AWS CodeCommit","SNS","Amazon SNS","Git"],
        "url": "https://easoncao.com/using-aws-lambda-and-amazon-sns-to-get-file-change-notifications-from-aws-codecommit/",
        "teaser": "https://easoncao.com/assets/images/posts/2021/02/using-aws-lambda-and-amazon-sns-to-get-file-change-notifications-from-aws-codecommit/architecture.png"
      },{
        "title": "我是如何在還沒畢業就錄取並進入到 Amazon 工作",
        "excerpt":"很多人好奇我是如何進到 Amazon 工作，並且在還沒畢業前就拿到 offer。今年 (2021) 是我加入 Amazon 這家公司的第三年 (把當 Intern 跟當兵的時間也算進去的話 XD)，所以一次把故事寫在這裡。                     我是如何在還沒畢業就錄取並進入到 Amazon 工作            人生第一份履歷   2016 年底，大三，我投遞了人生第一份履歷。其實在前面我做了一些研究，當時的心態是希望能夠跳脫校園舒適的環境，並至少在畢業前有一些實務的經驗 (感受職場的殘酷)，並且實際了解產業的運作。(結果畢業了更想回去學校唸書)   當時我應徵了下列的職缺：      Software Development Intern (The News Lens)   Cloud Support Engineer Intern (Amazon Web Services)   為什麼是這兩個，第一家原因，是因為當時也在媒體紛亂的時代，使得我對於獨立媒體產業很有興趣；並且創辦人 Joey Chung 當時也有來到學校分享 (不過那個講座超少人參加)。想要成為改變媒體亂象的念頭深植我心，加上更了解企業運作跟文化後，我才知道原來 The News Lens 是一家很有個性的新創公司，當時打死都不接受商業媒體贊助，竟然還能活得這麼好，因此一直深感在這樣的公司裡面工作應該能學習到很多。   點燃實際跨出找實習的契機，當時我在講座對 Joey Chung 問了一個問題 (具體內容我忘記了)，大意就是不太確定如何培養實務經驗跟具備企業所需要的能力，我獲得簡潔有力的回答：實際去 Internship。   他也說到：      Harvard 在你一開始入學時就將所有 tutions / fees 各項雜支計算給你，因此你必須很清楚你來學校的目的，並且努力善用你擁有的資源。     (現在想想真的是廢話，但當時真的是沒有那麼宏觀的格局，所以仍然十分感激這樣寶貴的建議)    加上學校對於畢業設立需要到業界實習的門檻 (真是優良的傳統)，這要求了每個學生在畢業前一定要去業界實習，並且透過老闆給的考核給予學分。雖然我當時找的時間點有點早 (同學們都還在煩惱中午吃什麼)，再加上大三又是課業最沈重的一年，雖然有點累，但想想仍其實利大於弊。因此待一切時機成熟，留意到有實習的職缺後，一個不猶豫有機會就投遞試試。   我現在努力回想只記得去 The News Lens 面試軟體開發實習生時，問了幾個問題：      過去用 PHP 做了哪些專案？   你解決過最難的技術問題是什麼，你如何解決？   我當時臨時只想到我在寫 PHP 專案時為了要設計選單式目錄，做了一些研究並想了怎麼規劃資料表，最後用遞迴的方式列舉出來覺得很酷。   總之最後，獲得感謝信一封，我很慶幸 The News Lens 當時沒錄取我，讓我連猶豫的機會都沒有。   差點錯過的機會   身為一名在資訊圈打混的人，多少都知道 Amazon Web Services (AWS) 就是一個聽起來就很炫砲的技術，會用 AWS 就像是站在技術之巔一樣。   當時，AWS 第一次在台灣開啟校園招聘計劃，我也有注意到 AWS 在學校發布對應的招聘訊息。我看了招聘訊息就真的是超級熱血沸騰，即使實習職缺的說明會地點在台大，我都覺得想去試試。   當時十分想去，但遺憾的是，時間點跟學校的課程衝突。而且，最重要的，招聘資訊上也沒有可以投履歷的窗口 (Email) ！！！。   避免你覺得我在唬爛，我還有留當時招聘的文宣 (可見當時有多氣憤，可…可惡)：                     AWS 第一次校園招聘與差點錯過的機會            結果就以為這麼沒了。   (是不是看完，沒有看到 Email？我還在想會不會藏第一題測驗問題，在圖片藏什麼解碼問題，還試著用純文字編輯器打開看看有沒有什麼有趣的地方。)   陰錯陽差的面試   結果好巧不巧，當時招聘的團隊裡，有畢業的 Eefy 學長，幾天後在 Facebook 放了相同的招聘訊息。於是我二話不說，找了機會搭上線，看能不能投遞履歷。學長也很熱心的幫我把履歷轉給 HR (真的十分感激！)。   約莫 1-2 週，我就收到一封信，裡面包涵了幾個線上測驗的問題。題目類型是情境題，給了一組 IAM 帳戶 (AWS 的帳戶) 要你登入進去 AWS Console 搭建環境。但說實話當時我連 AWS 的帳號都沒有，那次是我第一次使用 AWS 服務，更別提什麼 VPC。   所以我也是在期中考那週，花幾個小時，研究並把環境搭建起來，並且使用我人生第一個 Load Balancer (ELB)。不過由於過去就有管理過機器，使用過像是 Linode、虛擬主機，設定 Linux，所以對我來說學習的門檻並不會很高。還記得當時秉持著接觸新知的心情在研究文件上的資料，反覆檢查自己的設定符不符合題目設計的要求，搞得比自己的期中考還緊張。   再過了幾個星期，我就收到 HR 邀請安排面試的電話跟信件 (還是從北京發來的)！當時掛完電話收到 Email，就得知我即將迎來至少三關的面試。當時還很猶豫要怎麼穿面試服裝，最後還特地穿了個白襯衫加皮鞋。   因為實在是太興奮 (OMG 我要在世界前幾大的公司面試啊！)，提早了快 30 分鐘到。那時候 Amazon 剛在台灣進駐，連辦公室都沒有，所以那時還是在共享辦公室安排面試。我還記得我到指定地點，還以為自己被詐騙 (因為混著不同公司的人，沒有人知道 Amazon 的位置在哪)，直搗前台獲得引導才放下心中的忐忑。   三關的面試，其中包含了兩關的與 Technical Interviewer 的技術面試，以及一關 Hiring Manager 的面試。   技術面試問了很多 Linux 及網路相關的問題，主要目的都是測試對於這些知識的掌握程度。面試問題，說實話真的是很硬 (考官臉也很硬)。當時 Linux 的考官 (也是我現在的老闆)，剛見到面的氣場就完全鎮壓，面試從來不告訴你對還是不對，就是一直瘋狂猛問。劈頭開場就快把 Linux 運作原理挖透了 (我的知識也快被掏空)。   網路相關的問題，則問了很多基本網路概論，聊著聊著還分享了自己過去學習這些知識點的經歷、學習維運系統會做的哪些事情、自己當時系統因為用的套件有漏洞被 Hack 中間學到了哪些事情 (怎麼發現被 inject javascript、被放 DoS 的 PHP 程式還研究了一下樣本… etc)，當時大概就是說著說著眼裡都可以閃爍著光芒的那種程度。當時就只有一種想法，很慶幸能有機會與前輩交流，然後感受到在外商工作的人英文真的是很會，知道自己還有什麼樣的差距。   面試到後面，主管進來就說前面的 Interviewer 評價給得還不錯，有打算想先給我個口頭 offer。所以你要說我僥倖錄取，也許吧，就這麼剛好能多少回答面試官的問題，上至基本開發到 Linux、網路，下聊到電腦視覺。技術問題真的是被電歪，小緊張是會的，但是當時心情是很興奮且雀躍的，因為又感覺自己進步，並且又了解更多東西。   我還記得當時面試完我的腎上腺素飆高，打電話給我爸說我得到口頭 offer，結果還被我爸潑了冷水：「人家只是講講啦！啊你這樣會不會很忙，我是覺得你不用去實習啦。」真是幸虧我一直都很叛逆不怎麼聽話。   真的收到正式 offer 也差不多隔了快一個月，當時打開信看到一堆英文加上很多 statements (完全沒有中文)，覺得非常新鮮 (結果現在英文文件已經看到爛且習慣了，但第一次的感覺還記憶猶新)，而且面試過感覺每個人都很強，還是難掩說不出的興奮。   我的天！我真的獲得進入國際大公司工作的機會！   到正式入職當天 (我第一天報到還沒出門就超嗨)，Amazon 就馬上有了新的辦公室 (真的是決策很快)。我是第一批錄取的實習生，第一天到辦公室報到時，我以為會有一批實習生一起工作，並且未來的日子裡，將會跟電影情節一樣，有個很快樂美好的 Party 跟夥伴 (完全被 The Internship 誤導)。   結果就是，全部都是幻想 ….   後來才知道，當時邀請面試前，就先刷了一批人 (AWS 環境都搭不起來)，技術面試又再刷了一堆人。結果我進去之後，才發現原來當時我同事們竟然拿正職的考題來問我 (難怪一堆人被電歪)，只有我跟另一位台大的學長 William 倖存 (當時全台灣 Intern 就只有我們，這樣聽起來好像很厲害)。   於是領了電腦、螢幕，有了專屬的座位，就開始了我在 Amazon 實習生的歷程。      有時候就是一個機會，你無法預測現在做的決定，在未來是否仍是最好的選擇，但你永遠有權決定，是不是要把握這樣的機會。    轉成正職   我的前主管是非常厲害的一個人，並且用著很不一樣管理思維在看待實習生計畫。他認為實習生最大的任務，除了一起加入專案的開發幫助改善團隊的生產力外，其餘就是學習、甚至是在公司提供的資源下拿到 AWS Certificates。並且試著從團隊的目標中，在幫助實習生成長的過程裡，找到交集的可能。   我覺得在我實習的日子裡，最感激 Amazon 有著很成熟的師徒制度 (Mentor and Mentee)、一堆優秀的同事，並且有著一輩子學習不完的訓練資源幫助你成長，所以你總能找到人為你提供建議，並向他們學習。   我當時最喜歡的電影是 The intern 及 The Internship。一個是年過 80 的退休人士在新興網路公司工作的歷程，而另外一個則是兩位中年大叔轉職去 Google 當實習生的電影。這兩部電影著實給我很大的啟發，我有時會無限回放，想著哪些原則是可以套用在自己身上，並不斷優化。我真的很感謝這兩部電影的製作團隊，這麼好的作品，真的都成為我學習人生課題一部分的重要素材。   也因為這樣，當實習生的日子，我不怕丟臉，我的心態就是努力做、努力學習，像個海綿一樣。雖然大三是課業繁重的一年，但當時我在週一到週五排課，想辦法空出一個全天，以及週六週日其中一天時間到辦公室工作。由於那段時間真的是沒有休息日，其實還有點黑暗，但我常常自主在辦公室裡讀著文件、學習材料，常常一待就快 12 個小時，跟著前輩討論技術問題。每次覺得又獲得更多知識，這個過程是有趣的。   我在加入之後，其實也從不把自己當實習生看。我一直認為我也需要有能力跟前輩們一樣解決困難的問題，所以也主動找機會觀察團隊目前在進行的工作是什麼，幫助其他前輩們回答客戶問題、一起解決現實中客戶他們所遭遇的技術挑戰。也記得我以實習生的身份獲得客戶給的正面評價那種快樂 (估計客戶不知道是一個實習生回覆的)，當然也遭遇過很棘手的狀況、被其他團隊的同事洗臉，但都促使我有能力從這些過程學習更多。   在這短短一年內，我也推進自己通過AWS 五張主要的核心認證。當時在台灣其實並沒有那麼多人獲得，在別的部門裡，都知道有個不太正常的實習生竟然在一年內全部都拿到 (變相成為部門主管們 Push 績效的故事)。   實習就這麼來到快一年的時間，我的學分也在大四也早就修滿。所以在整個大四，就直接跟系上申請校外實習學分，讓我能夠專心的在 Amazon 工作。基於政策，Amazon 是不會有實習那麼久的情況。即使如此，我的前主管很努力說服很多團隊，讓我仍繼續待在崗位上，努力往下一個階段邁進 (因為我還沒有畢業)，實在是很感激！中間當然也在「要不要考研究所」、「出國留學」、「轉換機會」之間掙扎，但在綜觀考慮下，還是決定進到轉正式職位的過程，於是，又開啟另一波準備面試的流程。   Amazon 實習生轉成正職的階段，並不會因為已經過去錄取，就過過水讓你轉成正職。仍然需要經過一定的方式進行考核。所以在我的面試中，同樣又安排了三關：技術面試、HR、Hiring manager。   我的技術面試是西雅圖的同事幫我面的，又是另外一個境界的考題。考了很多 AWS 實務上、設計系統架構、執行部署的策略、細至解釋容器網路的行為等等 …..；HR 則了解人格特質、表明薪水談判的價碼跟期望待遇；Hiring Manager 則是我的前主管再一次的用更複雜的 behavior question 了解我的答案。   總體而言，並不會因為自己已經是實習生就比較輕鬆。但相對而言，因為經歷一年的大風大浪跟磨練，比起剛步入職場的菜味，相比下，能用更平常的心態面對這些問題。   一般剛畢業的學生，由於與業界所需求的能力仍有一段差距，所以能獲得的 offer 通常都是 Cloud Support Associate，也就是助理職位。然而，在我的面試官們綜觀討論結果後、包含過去在實習上的表現、有能力解決企業客戶遭遇的問題，前主管非常肯定我的績效、HR 很驚訝一個實習生竟然可以一年內全拿 5 個核心認證 (還與績效無關)、技術考官也覺得我的技術能力不輸一般在外面工作 3-5 年的工程師，所以最終決定以 Engineer (正式工程師) 給予我 offer，開啟我人生一個新篇章。   聽到這樣的好消息，真的是放下心中的大石頭，就準備畢業當天上工，直到接兵單中間再去服役。                     在 Seattle, US 參加 New Hire Training 換到的新 Badge。順帶一提，Amazon 的 Badge 有個有趣的小巧思可以幫助你識別這個人到底是不是老屁股            成長心態   在投遞這份工作之前，我並不認為自己很有可能會上，當時只是想著：「希望這是一個成長的機會，即使失敗也是一個很寶貴的經驗。」直到跨出那一步嘗試後，才發現其實自己並沒有想像的糟。   我回顧這些日子以來，我不敢說自己是最優秀的，但很努力是肯定的。在所有同學還不知道畢業後要幹什麼之前，我願意放棄放任時間流逝的機會，即使當時實習沒有學分，還是願意犧牲自己的假日，跨出那一步去學習我有興趣的知識。   很多人無法理解為什麼我可以錄取這麼大的一間公司，我只能說，其實這得多虧前面長期做了很多累積，在很多人不理解的環境下，仍堅持並持續學習。   我必須承認，真實世界 80% 的問題都不是學校會教的 (包含我自己面試遇到的問題也是)，學校只會告訴你課本上的答案，並且只是擔任領路人的角色，帶著你入門。我在學校學習的計算機概論、作業系統，考的也是一堆專業術語跟名詞 (e.g. 物件導向三大特性：encapsulation, polymorphism, inheritance / 作業系統怎麼處理 I/O 跟中斷 … )，而且我當時考題還是英文填空，拼錯就沒分 (管你是不是英文母語人士)。   這種評分機制下，我作業系統跟計算機概論成績還只是 B~C (大概只是剛好及格的程度)，你不見得能夠知道會這些東西有什麼用，但我很清楚背名詞術語跟其用途，只是用來拿分的工具。如果你問我 X 語言怎麼寫出封裝、設定繼承衍生物件，我可以直接給你或是找到對應程式碼的範例。亦或是告訴你我在 Linux 看到哪些指標，具體可以知道現在系統 I/O 處於瓶頸影響到應用程式效能。   很大一部分都是我在過去自己學習 Linux、操作實務上所累積的知識 (我從高中在 Linode 開啟了第一個虛擬機器並還在管理系統)。網路相關的知識也是過去經歷競賽，學習 CCNA 強化 Layer 1-3 的網路知識，並且在系統維運上也有對應的經驗 (雖然都是小規模)。我對於學習資訊技術本身就有濃厚的興趣，會在網路上搜尋開放式課程，更是把讀 O’Relly 系列的書視為聖經 (不得不說那個質量跟很多台灣出版商發佈的電腦書籍差太多了)。   在我實習面試過程的問題，大部分都是依照過去經驗回答，在當初實習生的面試前，花一大部分時間讀鳥哥複習 Linux 的知識，但是學校不會把鳥哥寫的書列為參考書單，講講實務上可能會遭遇的問題 (至少我當時是這樣，現在我相信很多老師正努力改革！)。而一直沿用在 1983 年出版第一版、已經出版 20 年以上的 Operating Systen Concepts (恐龍書) 投影片講到退休，所以同學們上完這些課，感想大概就是你聽過但不知道這個東西能做什麼。   這是台灣教育最有趣的一大特色，我有自信現有的教育制度，絕對能訓練出會考試的學生，但無法培養能夠解決未知問題的學生。所以我十分鼓勵你對有興趣的主題，透過實際遭遇的問題，找找線上資源充實你的求知慾。   現在很多很棒的線上學習資源，圖書館也有非常多的好書。我相信學習有很多途徑，你也能挖掘到適合你的渠道。   在這短短幾年，我見識到了很多優秀同事工作的方式，並且從中學習好的部分，學習深入研究及思考問題，幫助自己不斷跨出舒適圈。我一直感受到心態其實也是影響事情結果很大的一項因素。在大部分的情況下，很多人總覺得自己不可能錄取，於是就選擇放棄行動且學習跨出那一步 (定型心態)。但學習以成長心態看待事情，往往可以發掘很多成長的機會，並且努力思考及行動，讓自己更貼近自己理想中的自己。   當初畢業前我總是心心念念覺得自己應該成為一名軟體開發工程師，但在接觸這項工作內容後，我挖掘到了另一個面向發展的可能性。但當時很多人質疑我選擇這份職位，是否是一個正確的決定？   我的前主管告訴我，他過去也從一名研究生、決定工作、後覺再到英國全球前幾名的學校完成 Geography 博士學位 (中間再決定多修一年 Computer Science)、再到創業管理團隊，最後選擇到 Amazon 接下主管職位。每一個選擇總是有捨及有得，因此，你能做的，就是將目前可能的選擇列出來，然後選擇一個你比較滿意的，你的心中，自然會有答案。   總結   希望我的故事能帶給閱讀到這邊的你一些啟發。我始終相信人生是一段長而持續的累積，如果你正為了在某個人生的分岔點感到徬徨，請記得，如果五年、十年後往回來看，這不過是人生旅途的一部分，並且，是最有趣的部分。   往往我們總無法選擇最完美的結果，但我們能夠選擇當下最好的決定，並且努力思考及行動。正是因為這樣的過程，才學習如何強大、感受命運帶來的驚喜及餽贈、認知自己的使命，並明白自己要走的方向。   看更多系列文章      我在 Amazon 學到的 10 件事   我是如何在還沒畢業就錄取並進入到 Amazon 工作   我是如何在一年內通過 AWS 五大核心認證   Amazon Cloud Support Engineer 到底是在做什麼 (Amazon Web Services / AWS)   關於 Cloud Support Engineer 職位的常見問題 (Amazon Web Services / AWS) - AWS Cloud Support Engineer FAQs   在 AWS Cloud Support Engineer 面試中脫穎而出：必備的技術能力和重要特質   身處 Amazon 工作 5 年學到的事：在 AWS 擔任 Cloud Support Engineer 是什麼樣的體驗   ","categories": [],
        "tags": ["amazon","aws","amazon web services","work","Cloud Support","Cloud Support Engineer"],
        "url": "https://easoncao.com/how-am-I-get-into-amazon-before-graduate/",
        "teaser": "https://easoncao.com/assets/images/posts/2021/02/how-am-I-get-into-amazon-before-graduate/amazon-macaron.jpg"
      },{
        "title": "我是如何在一年內通過 AWS 五大核心認證",
        "excerpt":"這是我在 2019 年與同事們分享的內容。當時我們團隊，只有少數人有去考 Solution Architect Associate。而我，是還在當實習生的時候，在短短一年內，通過 AWS 五張主要的核心認證 (All five)：      Certified Developer   Solution Architect Associate   SysOps administrator Associate   DevOps Engineer Professional   Solution Architect Professional   我在我同事的推薦下，當時還在內部辦了一個講座，分享自己的學習心得給大家，也讓很多同事陸陸續續獲得想要的認證。   順帶一提，我是 2017 年三月加入 AWS 才第一次擁有 AWS 帳號並開始學習。所以我想下這個標題分享我當時講了什麼，應該是蠻圖文相符的。   Certificate Path   我的第一個認證 (Solution Architect Associate) 是在 2017 年五月拿到的，在這之後我就連續安排了學習計畫及考試：                     我在一年內的 AWS 認證歷程            難易級別   當時 2019 年剛開始出現 Specialty (專家級) 類型的認證：                     2019 年的 AWS 認證種類            當然 AWS Certificate Team 也不是什麼事情都不做，這中間幾乎每 6 - 12 個月就誕生一個新種類。截至我寫這篇內容為止 (2021)，現階段又多了很多 Specialty (專家級) 的認證類型。                     2021 年的 AWS 認證種類            我個人第一張認證是 Solution Architect Associate，但再轉考 Certified Developer Associate 時，唯獨大概要學習怎麼算一下 DynamoDB 的 Capacity，因此覺得特別簡單 (因為都只是考 API)。   但如果依照難易度種類區別，我會把其難易度分為以下，這也是廣泛 AWS Certificate SME (認證專家) 認知的難易程度：                     AWS 認證難易度 (級別為個人意見僅供參考)            我的學習歷程   我的準備策略除了依循上述的難易級別循序考上去之外。以下分幾點列舉出我在準備及學習 AWS 歷程上，對我十分有幫助的幾項重點：   1. 建立正確的心態   我考取認證的主要心態，並不是「為了考取認證」、「為了獲得認證」這種想法而去選擇準備，而是：      我希望我能透過認證的方式，有系統性的學習 AWS 服務   我並不認為通過認證就代表真的非常有能力在 AWS 上建構系統，並且在 AWS 上所向無敵，但相對而言，擁有基本且足夠的知識，能夠幫助你知道如何解決當前所遭遇的問題，我僅將其視為一項過程   我認為考取認證是充實不同面向知識的一種方式，並且希望從學習過程中在面對問題時，汲取「如何 / How」相關的經驗及知識   對我來說，考取認證不是目的，而是學習的一部分。所以我並不認為一次的沒通過算什麼 (雖然當時要求自己可以的話就試著「一年全數通過」)。相反，我反而能更加了解自己不太熟悉的內容是什麼。      (不過我每次都盡可能在考試日前，甚至犧牲假日努力準備跟複習，所以至少都有及格)    而且這種考試根本與什麼定生死的學測不同，沒過還可以 Retake。   所以其實將其視為一種學習的循環，相較而言，準備起來更為輕鬆，更像是一種時時刻刻檢視自己學習的過程 (不過當時為了不想浪費錢，要跳向 Professional 的考試真的給他拖有點久)。   2. 釐清考試目標及大綱   因此，我會推薦 Blueprint (考試指南) 一定要閱讀，這能在你安排準備該認證時，有清楚的藍圖知道這個認證著重要學習的重點是什麼。你通常可以在認證頁面找到對應的位置下載：                     檢視 AWS 認證提供的指南            如果你仔細注意，你一定可以知道每個認證項目著重的重點是什麼，例如 DevOps Engineer Professional：                     AWS DevOps Engineer Professional 考試指南 (2021 年)            從裡面你可以確實注意到 CI/CD 相關的項目佔了不小的成分。如此一來，我就會知道需要努力學習 AWS 上能夠滿足 DevOps 相關的解決方案及 Stack，並且透過 Whitepaper、re:Invent 等影音，知道如何實踐 CI/CD 等策略。例如：CloudFormation、Beanstalk、CodeSuite (CodeCommit, CodeBuild, CodePipeline) 等等。   但如果你看了 Solution Architect Professional，你會發現就幾乎是什麼都要沾一點邊：                     AWS Solution Architect Professional 考試指南 (2021 年)            所以我也認為 Solution Architect Professional 其考試真的有一些難度，當時的方法就是把產品頁面展開，然後看一看這些產品都是在做什麼。並且基於 Solution Architect Associate 的基礎再更進階有關高可用性等問題，大量透過實際案例做更深入的閱讀及學習理解。   Associate 類型的考試      閱讀 Whitepaper 並且針對你有興趣學習的服務打開AWS 文件閱讀你感興趣的章節。   由於 AWS 服務非常多，有些教育單位會提供模擬試題，盡可能了解回答及錯誤的 AWS 服務，並且再回頭看看文件或是做做 Lab，幫助你加深印象。   Professional 類型的考試      沒有什麼訣竅能夠幫助你快速理解所有 AWS 服務。我推薦的方式是在 YouTube 上找找 re:Invent 系列的影片 (尤其是 Deep Dive 類型) 並且安排時間學習。re:Invent 系列的影片常常會包含許多實務應用範例及使用情境，甚至可以學習客戶的使用案例，這有助於幫助你了解一些複雜問題下該如何實踐最佳實務。   觀看 re:Invent 影片後推薦實際去玩一玩這些 AWS 服務，這有助於加深印象。   Professional 級別的考試因為題目又臭又長，每題都是情境題，因此更需要正確規劃作答時間。如果第一眼不是那麼確定，可以先選一個概略的答案，並且在答題系統上標記，等完成後再回來檢視。   3. 分散式學習   我的學習場域大部分都是在捷運上 (沒錯，就是捷運)：                     我的學習場域            在我的學習過程中，常常借助了大腦比較喜愛的學習模型 (這有機會再寫文章探討)。我會習慣將學習材料切割成多天分散學習，以幫助我在建構這些知識時，大腦有充分時間能夠組織及強健知識：                     分散式學習               有的人可能習慣在考前一天抱佛腳 (但往往考完就什麼都忘了)   有的人可能習慣在考前一週集中 (這通常也是考試導向，往往最終獲得的知識狀態也不見得很融會貫通)   或是分散幾天一小時 (有的人大腦需要一些時間喚醒才能進到之前學習的狀態)   學習並沒有最佳做法，只有最適合你的方式。但已經有許多研究顯示，分散學習確實有助於建立大腦記憶區塊。   在我的案例中，我大部分時間仍然是透過通勤時間 (20 - 30 分鐘) 聽著及看著學習材料幫助我了解不同項目，然後到辦公室繼續做其他事，假日有時間再額外看看或是做做 Lab。   我一直認為通常說的「沒時間」其實只是表示「我覺得這件事情不重要」。當你認知這件事情有需要去做時，你總能安排時間。   總結   在這篇內容中，我分享了我自身在過去如何於一年內獲得五張 AWS 核心認證的經驗，並且與你分享一些實際上可以參考的應用方式。如果你正在準備 AWS 認證，希望這樣的內容對你有幫助。   如果你覺得這篇內容不錯，可以分享或是按個 Like / Clap。   看更多系列文章      我在 Amazon 學到的 10 件事   我是如何在還沒畢業就錄取並進入到 Amazon 工作   我是如何在一年內通過 AWS 五大核心認證   Amazon Cloud Support Engineer 到底是在做什麼 (Amazon Web Services / AWS)   關於 Cloud Support Engineer 職位的常見問題 (Amazon Web Services / AWS) - AWS Cloud Support Engineer FAQs   在 AWS Cloud Support Engineer 面試中脫穎而出：必備的技術能力和重要特質   身處 Amazon 工作 5 年學到的事：在 AWS 擔任 Cloud Support Engineer 是什麼樣的體驗   ","categories": [],
        "tags": ["amazon","aws","amazon web services","work"],
        "url": "https://easoncao.com/how-i-pass-aws-all-five-certificate-within-one-year/",
        "teaser": "https://easoncao.com/assets/images/posts/2021/02/how-i-pass-aws-all-five-certificate-within-one-year/certificate-path.png"
      },{
        "title": "我在 Amazon 學到的 10 件事",
        "excerpt":"                  Every day is day 1            今年 (2021) 是我加入 Amazon 這家公司的第三年 (把當 Intern 跟當兵的時間也算進去的話 XD)。在加入這個組織這短短 3 年中，我明顯感受到自己的成長與變化，畢竟 Amazon 也是存活了 20 幾年的公司，在全世界雇用了上百萬名員工，並且仍不斷在成長。在組織運作執行上確實是有非常不得了的一套，許多原因使得我仍願意與企業組織一同成長，以下列舉幾項我至今覺得很寶貴並且感知受用的幾件體會：   1. 快速解決問題比起使用什麼技術來得重要 (完美是更迭出來的)   在過去，我完全就是一個有技術潔癖的人 (比如我是一個 Python 開發者我就一定要用 Python 的 tool stack 完成我所有的工作)，我很執著在解決問題前思考需要使用什麼樣的技術，目的可能是考慮了：擴展、比較嚴謹、之後可能比較不會出問題、想趁機會學習新東西、可以變成一項話題 (比如可以發表或是展現技術應用等) …… 等等。   總之不管什麼原因，可能在處理一個問題時會審慎思考自己用的技術 (比如：需要爬一些網頁資料、整合一些資訊變成另一種形式的操作模型 (比如輸出成報表、戳自己的 webhook 發通知)、設計應用跑運算)，或是基於完美主義覺得一定要所有事情一氣呵成。   拿爬網頁資料來說，我可能要：      構建 Python 應用程式   查一下需要的套件跟操作方法，比如 requests   跑 pip install 安裝需要的套件   測試 Python 應用程式是否能正確運作   Debug 再回去修改應用到爽   這還只是拿 Python 當範例，事實是可能來來回回都花了兩個小時，包含編譯打包做了一大堆工作，但是真正要解決的問題才有可能被解決。   但是在隨著這樣的處理模型下，我發現人們更在乎的是「解決問題」，而不是你使用了什麼樣的技術。客戶的需求跟問題只會每天地不斷地在變化，對於小問題，人們更注重於能否在有效的時間內解決問題。   所以現在，在工作上我可能傾向於使用 Linux 命令加上 Shell script 就可以完成我想做的大部分工作，可能只耗費我 30 分鐘做一個版本，只是步驟會被拆解成：      拿 curl 把 html 資料爬回來   grep 一下！可能在用個正規表達式過濾一下我想要的訊息   把結果貼到 Sublime / 文字編輯器在處理下篩選我要的內容   需要重複這個操作，Shell Script 寫個幾行就搞定   亦或者是我想要定期爬 facebook 上的資料，如果是用原生語言硬幹，我可能會：      構建 Python 應用程式   查一下需要的套件跟操作方法，比如 requests   跑 pip install 安裝需要的套件   模擬使用者登入並且處理 facebook 上的驗證操作   測試 Python 應用程式是否能正確運作   登入之後在爬爬感興趣的 HTML 資料進行字串處理   測試 Python 應用程式是否能正確運作   將有興趣的資料進行下一步處理 (比如觸發 Webhook)   Debug 再回去修改應用到爽   然而我只要在我的執行環境中使用 Greasemonky，並且跑一台 VM 開著瀏覽器，完全可以做到上述的工作：      安裝 Greasemonky   寫一寫 Javascript 把 DOM 跟感興趣的內容撈出來 (完全不用搞驗證)   Greasemonky 可以操作跨站存取 (CORS)，所以我可以把撈出來的資料吐到其他地方或是觸發 Webhook   在 Greasemonky 腳本裡面插一點檢查機制，發現資料撈不出來可以發個通知手動檢查下   雖然問題拆了幾個部分，並且不是那麼漂亮 (沒有一氣呵成的感覺)，但是，整體開發跟配置相對簡化非常多工作。   如果只是一些小規模或是立即性的需求，這種工作模型卻足以滿足大部分的工作。而且會發現，其實人們對於使用組合技 (特別是對於技術人員來說)，普遍接受程度並沒有自己想像中的低 (因為畢竟大家都只專注在解決問題)。   一旦真的出現規模需要或是下一步更進階的使用需求後，再來設計原生語言的套件也不是一件特別困難的事情。此外，我發現這種模型間接幫助你驗證整體的業務邏輯，再改用原生語言進行實作，其實在開發上像是有了一個規格，也相對「清楚要做什麼」，並且容易許多。   2. 這個世界變化的比你想像中的快 (… and, it’s always day 1)   Amazon 提供的雲端服務 (Amazon Web Services) 提供上百種不同的服務及解決方案，這其中都是上上下下數千個團隊跟不同部門合作下一起構建 (而且是不同跨時區下協同，幾乎整整 24 小時都有人在進行)。   常常過幾個星期就又有團隊迸出新的功能或是服務要上線、一覺醒來又有新的變革，亦或是在你還沒準備好了解這項變動之前，已經有客戶想知道這些釋出的功能的具體細節 (我從沒有跟上客戶的腳步過)。   在還沒加入這樣規模的組織前，我其實無法想像這個世界是多麽積極的在變化，尤其在台灣這樣的小島，每天媒體告訴你、周圍朋友在 Instagram / facebook 告知發生的事情，其實都大同小異，圈圈內流通的資訊更迭的速度其實並沒有那麼快，大家都很被動的感受自己接收的資訊。   但在跨時區分工合作的運作下，你必須習慣睡覺醒來一切又有變化的事實，並且是超級快速，每一天都像是第一天 (Day 1)。這迫使你會需要練習快速學習的能力以適應這個世界的更迭，不斷主動更新自己的知識跟技能。   3. 學習必須有效並深入核心而不是只停留於表面 (Dive Deep)   在 Amazon 提及的 14 條 Leadeship Principles，有一個我感知最深的項目就是 Dive Deep (追根究底)。   我在面試很多候選人後，我發現很多科技圈的人才都有一個普遍的慣性，就是對於新技術或是知識的理解都停留於 Surface Level (表面)，即使是自己熟悉的技術或能力也是。很多人往往對於接受一個知識或技術的理解都停留於表面就感到已經完全理解，但在我的工作中，往往是面對未知甚至是很多應用的 Bug，並且找到一個適當的解決方案。如果保持這樣的思考慣性，很容易導致在遇到問題時無法切入並解決核心問題。   以大家很常說自己會的 Kubernetes 舉例來說，通常問以下問題 95% 的候選人都回答不出來：      為什麼 Kubernetes 在同一個 Pod 中，不同的容器可以使用 localhost 彼此訪問？    你通常就是看書上說說知道 Pod 是什麼，並且會說是一個 Kubernetes 特有的元件。但往往就是這麼一個簡單的問題 (網路上也一堆解答)，讓我發現很多人對於接受一項知識的理解往往停留在：文件如此寫、會操作 kubectl 命令並且部署、看範例就是如此、Kubernetes 直接劃分一個可共用的網路環境 (然後就無限鬼打牆 … 例如：它就是一個抽象元件 等答案)。   但如果你真的試著想要進一步了解其底層運作原理，你會發現其實 Pod 並不是什麼特別的東西，網路的共用特性與 Docker 相同技術定義的 Network sandbox / ECS 定義的 Task 相似，這使得其可以使用 localhost，並且都基於 Linux Kernel 提供的功能執行類似虛擬化的操作。一旦你試著對知識刨根究柢，這在處理有關 Pod 網路相關的問題時，才會有更清楚的脈絡知道要往哪個層級剖析 (是容器？系統？還是外部網路？)。   當然我也不是一開始就如此，而是在經歷過各種亙古難題，並且每天都得想辦法解決未知問題的環境訓練下而養成。也因為如此，我更重視自己在接受知識時，必須以更深層次思考的習慣，並與現有理解嘗試融會貫通，並不斷反思自己現有的知識跟理解是否正確及深入。   這個 Dive Deep 也不是指要你鑽牛角尖，而是了解以更實際及應用的層次，逆推回去學習並引導自己往更核心的底層近一步理解。正是意識到這樣的能力培養在日常工作中的必要性，我仍不斷學習並強化自己的知識理解，進一步培養自己對於問題切入剖析核心的技巧，幫助我解決所遭遇未知的問題。   這樣的原則我感受到不同領域上如此應用，通常能引導自己能提出更深層次的解答、或是嘗試在挖掘更多具體我所需要的資訊，並且有效的行動。   4. 不必太執著於工作，但工作起來必須很執著   Amazon 有一句膾炙人口的標語：      Work hard, Have fun, Make history    看到這裡你覺得 Amazon 就是一家非常 Work hard 的血汗工廠 (加上一堆新聞都說 Amazon 很血汗)。但事實是 Amazon 並不希望自己的員工 Overtime 加班，並且盡可能優化不同團隊之間工作效率。   因此，在內部我們不斷的每天都在想著如何改善產品、改善服務、改善所有不太 OK 的事情，並且專注這些目標，努力在工作崗位上做出一些改變，而不是滿足於現狀，這是我們所謂的 Work hard。   在這裡，老闆會耳提面命希望你不要一直加班，並且要求你必須注重自己的私人時間及生活，否則很快就燃燒殆盡 (Burnout)，領導階層也會時時刻刻了解是不是有任何工作負載過於集中的問題 (有點類似避免單點故障的概念 / Single point failure)。   透過維運的角度盡可能幫忙你找到對應的 backup (換句話說，在身處周遭都是優秀的同事，其實你總能被取代，無需在自己的私人時間太執著於工作，並且需要相信你的隊友)。   當然，該認真工作時絕對是很可怕的。在工作上，除了會有各式的績效及 KPI 你會需要想辦法滿足 (其實並不是特別困難)。但更重要的是，因為身邊的同事都十分優秀，你必須很認真的思考自己的職涯規劃並設定目標，想辦法讓自己成長、努力工作改善現有的問題及自我，並把自己跳出舒適圈往更高的階段推，而非滿於現狀，否則很快面臨瓶頸。如果你是一個很樂於學習及成長的心態，在這個組織下工作是十分有趣的。(反之，你可能待不到幾個月就想走了 XD)   在這裡，大家不是搏感情比誰更努力工作加班，而是比誰能更有效率的完成事情。   5. 在必要的地方花錢不手軟，而不是無限度擴張福利      (我的解讀為：錢要花在刀口上)    在 Amazon 工作，你真的會覺得很「摳」，你會發現組織對於「免費午餐」、「員工旅遊」這類的事情錙銖必較。在過年過節也不會有所謂的三節獎金、上班提供按摩之類的服務 ….。當初 Package 跟你談好多少就是多少，而且不多也不少 (在 Leadeship Principles 有一條 Frugality，完全就是體現這項原則)。   但是相對的，若是對員工生產力、有助於客戶的事情，花錢絕對不手軟，例如：      需要擴充硬體設備進行開發   員工手機帳單可以報帳以提供在工作上穩定的網路服務   需要跨國出差，只要不是亂花錢，都願意全部包機票住宿及食宿給你飛過去 (我有幾次來回美洲幾星期，光一趟就報帳報掉快 7000 USD，折合約 10 - 20 幾萬台幣….)   並且在教育資源及訓練上投入大量的資源，十分專注幫助員工成長。目的都是為了提供給予客戶更好的服務及產品、解決方案。   有時候大家選擇工作可能優先都以公司提供什麼樣的福利及薪資為考量，這並沒有什麼問題，但最怕的是往往沒有意識到談來的薪水可能是一攤死水。然而，Amazon 招聘最為厲害的地方在於，其在吸引人才的招聘政策永遠不是用薪資及福利作為主要的手段 (當然薪水我相信在市場上也是很有競爭力的，但比起其他頂尖的外商我相信有更誇張的數字)，其更重視的是候選人願意用成長的角度加入這家公司，並且積極冒險及試驗，你會更感受到你跟公司的關係更像是合作夥伴，並且珍惜你手中握有的股票，這正是 Amazon 持續十幾年來一直在做的事情，致使你會願意參與這家公司的成長 (然後看著它市值一直一路往上，像是看著自己的孩子長大一樣)。   6. 做出初始版本跟寫好一頁的文件比起做好投影片重要  在 Amazon，我們很少做投影片，你會發現公司上上下下沒有人在專注弄絢麗的投影片樣板 (除非是給外部客戶看的，不然通常都單調並且樸實無華)。大家反而更專注把自己的 Document (文件) 寫好，如果你要說服你的老闆、提交升職、提出一個計畫或改進，在這裡做簡報並把一切描繪(吹噓)的多美好，是不太會有人理你的。   文件一般來說，通常會是 1 頁 (內容不超出一頁)，至多也不會超過 6 頁。在文件的內容上，都明確寫下了具體的 data point (需要有事實的資料陳述) 還有你的計畫、或是績效，因此，寫好一份文件比設計投影片更來得困難。因為 …. 你會發現做了一堆事結果可能在文件上只有一兩行字 ……   構建美好幻想不如實際做出一個初始版本，並且收集到相應的資料 (就算沒有初始資料也必須擁有相應的資料點幫助陳述你的計畫說服其他人)，並且讓他人閱讀你的文件後進行評論。在接受這樣的工作模式幾年後，我也覺得這種方式是一個很有效率的操作，由於你會需要累積足夠的 data points 置入，會更清楚知道自己的目標跟預期計劃是什麼，而不是埋著頭一直做，再讓老闆憑感覺同意你說的。   在我的團隊，大家分享內容後，比較常聽到的是「我把今天提到的內容、相關的資訊也整理成 wiki 跟文件 (或錄影，可以使用 1.5x 倍觀看)，有問題可以再讓我知道」而不是「簡報我已經分享在 …，有需要可以自己去下載」   7. 能不開會就不開會，要開也盡可能開得快   在 Amazon，員工每天都會匿名接受調查對於管理層的相應執行績效 (我們每天都會為管理層執行評分)，其中很常問的類似問題就是 The meeting I've is ... ? (類似可回答的答案: effective / non effective) 或像是 my workload is manageable?  這類的問題。   你可以注意到 Amazon 一直在嘗試減少不必要會議的數量，並且盡可能幫助員工有效地執行工作，包含我所在的團隊，通常只有 team meeting 為慣例會議，並且主管也是快速用幾分鐘講講近期的更新或變動就直接進 Round table (讓團隊成員看看有沒有問題需要提出來的)，一週平均會議時間都低於 2 小時，在其他地區有的團隊也是實行 Stand-up meeting (站著開會，所以開太久會站很酸)，可見大家真的很不愛會議。   即使 Manager 召集的會議，但若有其他重要事項在處理，如果沒什麼特別的事項，是有權拒絕參加的，並且由他人幫忙轉達 (而且通常大家都偏好能不開會就不開會，這點管理層或是上上下下的團隊大部分都很有共識)。通常會議的目的就是進行決議，或是傳遞必要訊息，工作上也會統計每週花在 meeting 上的時間，如果太多，你可能會需要審慎思考是不是真的有必要開這些會。   其他例子像是：所有 interviewer 面到後面投票決定不錄取一位面試者，HR 事先也已經透過意見調查收集大家的共識，會議就會直接取消，而無需裝忙開會。   8. 搞懂 Priority (優先順序) 跟重要性比起做一堆 KPI 來得重要      (如果不是很重要，能不做就不做，而不是一昧瞎忙)    在上萬人的組織中工作，你會發現每天要做的事情真的是很多，且每天收到的 Email 就像雪花般的飄進來。由於每個人都很忙，每個團隊都有自己的問題需要解決，有時候你做了一堆 KPI 跟數字，卻到頭來發現並不能長遠解決團隊所遭遇的問題，以及契合目前公司營運的發展目標。這體現了正確工作的重要性，因此每次在新的季度，領導階層一定會告訴大家 KPI 跟目標是什麼。   在每天被塞爆的工作中，你需要時時刻刻檢視自己正在做的事情是不是真的有必要，並且是完成重要的工作。在這裡達到 KPI 是應該的，並沒有什麼特別。   大家反而會不斷提出的問題是：「這真的是我們需要做的嗎？真的是重要的嗎？長遠來看對團隊是有幫助並能改善問題的嗎？」   因此，正確的配置任務的優先順序，並且有效平衡你的時間運用。正確滿足 KPI 需求之外，同時需要契合你的成長目標更顯重要；而不是一昧地瞎忙，或是出於人情幫忙做了一堆事情 (搞得自己表面很忙)，卻不符合團隊的營運目標。   9. 在很重要的事情十分快速，在不重要的事情無限拖延   Amazon 真的是道道地地的美國企業。你完全可以在這裡感受到外國人做事的效率 (在有些事情上真的是超 …. 級 …. 慢 ….)。像是我曾經為了在 AWS 官方部落格發佈一篇文章，整整花了半年 (其實也就 2 個季度、6 個月，我已經見識過擺至少 1-2 年的待辦事項，仍懷著感恩的心)。   像是在台灣你訂個包裹可能等個 3 天就快受不了了，但自從我在 Amazon 工作後，有些卡在其他團隊的事情，如同前面提到的，每個團隊都很忙。如果不是那麼緊急的事情，我在幾天至一個星期內得到回覆，真的是說不出的感激，並且覺得很快。在這樣的環境下，完全顛覆我過去的時間觀念，並且練就一身好耐性。   在這裡，大家會對重要的事情十分快速，並且立刻做出相應的行動 (例如發現有 Bug 需要 Roll back 以解決一個非常嚴重的影響)。但如果優先順序並不是那麼急迫，或是影響並不是那麼大，那你得預期可能會是一場持久戰，甚至很可能並不會被解決，並且需要抱持著不斷騷擾人的心理準備。如果想加快，你必須用 data point (數據) 說服其他團隊為你做事，而不是只因為你想或是你職位比較大。   事實上，我認識很多國外的同事們並不愛加班、到晚餐時間一堆商店都關門，但這樣做出來他們的工作結果並不差。反過來真的會思考亞洲人拼命的文化到底是在拼什麼 (大陸的 996 工作制度真的有比較好？)，太執著於細節或是一些小事情，似乎並沒有帶來更大的效益，也許這也是值得你我學習的工作模式。   10. 永遠思考對客戶是否有幫助及符合長遠的目標，而不是只因短期利益選擇做事   在我的工作中，時常會在不同的解決方案中建議客戶選擇合適的項目。若是一般的商業利益考量，大部分會為了短期績效及利益，可能建議客戶使用不見得適合他們且昂貴的方案。當然，這確實有助於增加年度營收。然而，這並不符合 Amazon 追求對於客戶服務的目標。在這裡，我們會想著如何幫客戶省錢 (例如: Amazon EKS 折 50% 的定價、AWS Fargate 降價)，並且思考如何提供更好的服務及產品反饋給客戶，與客戶建立信賴關係。同時，為其帶來長遠的收益 (AWS 幾乎用了整整 10 年創新，並由虧轉盈)。即使可能短期效果並不是立即的反應，但這一直是 Amazon 做事的風格。   總結   最後讓我用 VP - James Hamilton (同時也是分散式系統的專家) 在 2016 年發表的文章進行總結，與你分享我在這幾年切身感受的體會：      As a member of the AWS engineering team, my first impressions are probably best summarized as fast. Decisions are made quickly. New ideas end up in code and available to customers at a speed that just makes the pace of enterprise IT look like continental drift. In a previous role, I remember (half) jokingly saying “we ship twice a decade whether customers need it or not.” Now new features are going out so frequently they are often hard to track.       作為AWS工程技術團隊的一員，新環境給我留下的第一印象就是一個“快”字-決策制定流程非常迅速，新思路能夠很快以代碼形式推出，並立即被交付至客戶手中 。這一切都讓傳統企業IT的響應速度看起來像是大陸板塊漂移。我記得自己曾經半開玩笑地回憶過往角色稱呼：“我們在十年中只發布了兩次客戶可能需要，也可能不需要 的更新。”現在新功能正以驚人的頻率推出，我們甚至很難追踪其推進節奏。       Another interesting aspect of AWS is how product or engineering debates are handled. These arguments come up frequently and are as actively debated at AWS as at any company. These decisions might even be argued with more fervor and conviction at AWS but its data that closes the debates and decisions are made remarkably quickly. At AWS instead of having a “strategy” and convincing customers that is what they really need, we deliver features we find useful ourselves and we invest quickly in services that customers adopt broadly. Good services become great services fast.       AWS的另一種有趣的特質在於對產品和工程技術相關的處理方式。各種爭議會不斷出現，而且AWS內部的辯論之聲要遠遠超過任何其他企業。這些決策的流程讓我可以選擇， AWS除了擁有卓越的數據處理能力外，也能夠快速中止逐步並存並採取出征性意見。在AWS中，我們不再自以為是地制定“戰略”並強行說服客戶認同其適用性，而又推出了適合自身業務環境 的方案，並通過面向服務的快速投入幫助更多客戶快速享受至由其帶來的便利。如此一來，優秀的服務能夠快速取代為卓越的服務。       (source: A Decade of Innovation / 中文: AWS的十年创新之路)    看更多系列文章      我在 Amazon 學到的 10 件事   我是如何在還沒畢業就錄取並進入到 Amazon 工作   我是如何在一年內通過 AWS 五大核心認證   Amazon Cloud Support Engineer 到底是在做什麼 (Amazon Web Services / AWS)   關於 Cloud Support Engineer 職位的常見問題 (Amazon Web Services / AWS) - AWS Cloud Support Engineer FAQs   在 AWS Cloud Support Engineer 面試中脫穎而出：必備的技術能力和重要特質   身處 Amazon 工作 5 年學到的事：在 AWS 擔任 Cloud Support Engineer 是什麼樣的體驗   ","categories": [],
        "tags": ["amazon","aws","amazon web services","work"],
        "url": "https://easoncao.com/ten-thing-I-learned-in-amazon/",
        "teaser": "https://easoncao.com/assets/images/posts/2021/02/ten-thing-I-learned-in-amazon/day-1.png"
      },{
        "title": "Amazon 的 Cloud Support Engineer 到底是在做什麼 (Amazon Web Services / AWS) ",
        "excerpt":"AWS Cloud Support Engineer 主要面向的客戶受眾便是使用 AWS (Amazon Web Services) 服務的客戶，並為這些客戶提供訂閱制的支持計畫。(沒錯，也就是說，我們是付費的服務。)   由於這項服務屬於訂閱制，費用可以單月從 Developer Support Plan (29 USD) 至 Enterprise Support Plan (15,000 USD) 以上不等。因此，在我的工作裡，我每天會接觸各式各樣規模的客戶。小至獨立、新創開發團隊，大至市值規模全球前 10 大的公司都有。      (有的客戶可能這輩子只開一台 EC2 Instance，但同時，有的客戶可能單一個 AWS Account、單一個 AWS Region，就擁有數百至數千個大規格的 EC2 Instance)                      我敬重的同事 Teddy Chen            面對的客戶                     AWS Support Plan 定價 - 來源: 比較 AWS Support 計劃            15,000 USD 光換算台幣就已經 40 幾萬，什麼服務都還沒有用就先燒一堆錢，聽起來好像傻子才去買 Enterprise Support。但很多時候，我們的客戶會十分願意花錢買我們的 Enterprise Support，你可以繼續往下看，就知道原因是什麼。   首先，AWS Support 針對不同級別的客戶提供了不同程度的響應時間：                     AWS Support Plan SLA - 來源: 比較 AWS Support 計劃            以 Premium Support 服務來說 (也就是 Cloud Support Engineer 的工作)，一旦購買 Support Plan，最大的優勢就是你可以開 Case 進來詢問我們團隊任何有關 AWS 相關的技術問題，並會有對應的專家提供解答。但這時候購買什麼 Support Plan 的差異就出現了，如果你是 Enterprise Support 的客戶，其回答的優先權絕對是很高的，即是只是詢問一般性指導問題 (e.g. A 服務怎麼使用、使用 B 有沒有什麼需要注意的細節)，服務 SLA 最久的保證時間是 24 小時內，你一定可以獲得回覆。此外，針對嚴重的問題，會有更快的響應速度。   若屬於最嚴重的案例 (業務關鍵系統當機，通常是遭遇 service outage)，在客戶開啟案例的同時，就會有資深的技術支持工程師在 15 分鐘內響應協助客戶解決。並且持續追蹤、提供相應的技術建議，以幫助快速定位問題，並盡快幫助客戶恢復系統業務的工作。   另外，若是簽訂 Enterprise Support，Enterprise Support Plan 的客戶會擁有專有的 Technical Account Manager，不斷地幫助客戶向 AWS 內部團隊反饋問題 (像是客戶的專屬窗口)、Solution Architect Team 也會協助客戶檢視系統架構設計的可行性。   同時還會有 Concierge 團隊幫助你怎麼優化每個月的帳單、提供怎麼訂閱 RI (Reserved Instance) 的優化建議，對於 500 人以上的大規模企業，借助 AWS 的資源，總體可以幫助客戶節省非常多的費用。   並且，這某種程度上幫助降低客戶端維運團隊的複雜性，專注在發展重要功能，並交付 AWS 的專業團隊及經驗快速幫助定位、協助解決很多超難又複雜的問題，並從中與我們合作互相學習成長。這正是許多客戶選擇購買 Enterprise Plan，以幫助他們加速業務成長的主要原因。   Cloud Support Engineer 的日常   Meet our Global Mandarin Premium Support Team at AWS:   (以下影片有點久遠，不過可以大略了解這份職位的特性)               (What’s it like to work at Amazon Web Services?)               在我撰寫這篇內容的同時，AWS 已經擁有超過 100 種不同的雲端服務及相關的解決方案產品。由於不同產品有其複雜性，因此，Cloud Support Engineer 的工作主要是協助客戶在使用這些服務時所遭遇的問題給予相關的技術建議及指導。   同時，在工作中也會需要協同不同團隊 (Development Team、Solution Architect Team、Account Team / Account Manager / Technical Account Manager) 亦或者是其他團隊，幫助解決客戶所遭遇的問題。由於 Cloud Support Engineer 最主要負責的技術是 AWS 相關的產品，每個工程師都會是相關服務的領域專家，因此，有的時候也可能是在協助 Amazon 內部其他團隊在使用 AWS 相關服務的問題。   在你第一天入職時，Amazon 就會有非常完善的技術訓練計畫，並且擁有累積多年的實務經驗，你還會有專屬的 Mentor。因此在前幾個月你會非常專注學習相關的知識，學習過去不同 Case 的處理方式，並在幾個月後完全的有能力處理不同規模客戶的案例。   這些案例問題涵蓋的範圍眾多，除了一般可能詢問怎麼設定、API 怎麼使用、客戶剛入門的級別 (我們稱之為很甜的案例)，大部分情況，我們處理的問題通常都不是 “Happy Case”，客戶會問的問題也都不是寫在文件裡面的。大部分時間我們都在挖掘真實世界的問題並且給予實質建議，比如：      “服務中斷”   “網站掛點, 救命!”   “資料庫連不上”   “好像有東西不太對勁並且無法正確運行”   “為什麼我的應用程式跑了一陣子就會自己 Crash?”   “為什麼我的生產環境 / 應用無法解析 DNS?”   “如何升級的時候不要有服務中斷?”   “為什麼我的生產環境 / Cluster遷移到 AWS 就不能工作?”   “救命, 我的應用程式 / 服務在遭遇大流量的時候會崩潰”   在我的工作上，得需要在短時間內學習新技術的技能，並且持續不斷的學習 (由於 AWS 團隊很多，產品迭代速度很快，往往我們都還不會之前客戶就已經在問了)。同時，很多情況客戶會混合不同服務一起使用，亦或者是大規模的集群有東西壞掉。因此，你必須要有能力剖析在複雜架構下，真正問題的核心點是什麼，並且有效進行問題的定位。   同時，很多情況下，基於資料安全性及隱私權政策，往往我們都不會有權限存取客戶的資料、了解他實際運行的邏輯是什麼。這也意味著：我們沒有權限 SSH/登入 到客戶的環境裡面看設定、不知道客戶的 Code 是跑什麼、不確定客戶到底連接了哪些服務。所以你必須在這種情況下，還得知道如何有效的幫助客戶解決問題。   但我們的團隊在上述的情況下，還可以明確地告訴你要收集哪些東西，然後開啟以下對話 …：     哦！我從你收集回來的 kernel dump 確定是你的 Python 應用程式在 UTC 時間 XX 有問題，可能是有 memory leak，你要不要檢查一下   哦！你抓回來的封包明顯看得出來你的應用程式主動發 FIN 關閉連接耶，估計是超出應用程式可允許的等待時間。所以這不是 MySQL Server 關的，你要不要確認一下你語言 / Library 預設用的 timeout 時間?   哦！你的 Kubernetes Node 一直是 NotReady 是吧？從你收集回來的東西很明顯就是 kubelet 壞了啦！你說怎麼壞的？從我的分析可以注意到 Disk performance 不太 OK，你是不是跑了 I/O Bound 的應用啊？ …. 你說你不知道開發又寫了什麼埋坑讓你不能下班？好吧，所以你可以試試 …. etc   (我們通常不會跟客戶這樣說話，但大意大概就是如此)   很多人可能會以為這份工作就是一般的客服人員 / 低階接線生，就我在這個團隊幾年下來，我只能說這是大大的誤解，並且抱持偏見的角度在批判這份專業性的工作。   因此，要用其他方式描述我們的工作內容，我一直認為類似於「急診室的醫生」是滿貼切的說法。在客戶遭遇系統嚴重影響 (比如系統中斷、故障、service outage) 的情況。醫生也是秉持其專業需要在短時間內判斷下一步的動作是什麼，以盡快的緩解病患所遭遇的問題，並且適當的安排正確的處理優先順序 (所以為什麼在忙碌的急診室要排隊看發燒)。在我們的工作中，也會根據客戶所遭遇的問題嚴重等級正確區分 Priority，一直以來都視客戶關鍵性業務系統當機為優先，以幫助降低客戶遭遇系統中斷而導致營收受損的影響。   在我們的工作中，提供了 24 小時 x 7 天 x 365 的工作模型，這意味著 Premium Support Team 在無時無刻都會有人在線上協助客戶所遭遇的問題。基於這種工作模型，我們團隊屬於跨國的工作型態，在全世界各地都有相應的團隊執行交接。因此在台灣的下午及晚上，我們會將業務移轉至歐洲及美洲時區的同事執行跟進。   我的工作中會使用中文及英文兩種不同語言協助客戶的問題。由於用中文在 AWS 服務客戶仍然是一個很稀缺的技能 (在看這篇的你如果有訂閱 AWS Support Plan，請記得我們支持用中文開 Case，只需要在標題加上 [Mandarin] 即可！)，所以一大部分我的團隊會協助使用中文的客戶解決他們所遭遇的問題。   另一部分仍是協助全球世界各地使用英文為主的客戶、工程師亦或是 Amazon 內部的團隊。   特殊活動監控   遇到 Enterprise 客戶有大型活動或是線上業務特別熱鬧的時候 (例如：Black Friday、雙 11、搶票活動 …. 等等)，這時候就是我們會特別祈禱別發生鯊魚咬斷電纜之類的事件。有時候對於非預期的大規模流量導致任何非預期情況發生時，資深的 Cloud Support Engineer 就會進場幫忙排除可能的問題是哪些、釐清可能觸及到的系統限制、幫助客戶緩解問題，降低停機時間的影響。   Training &amp; SME   Cloud Support Engineer 擁有完善的訓練計畫，並且有豐富的資源及經驗使得你可以接受到非常深入的技術訓練 (強度頗高)。在我們的組織中，同時也有 Subject Matter Expert (SME) 的角色存在，很多 Cloud Support Engineer 都會很努力的爭取該項角色，其代表的是某些特定 AWS 服務的領域專家，並且分佈在全球世界各地 (但一個服務如果越新，全球不到 5 位 SME 是有可能的)。   不過你通常也不需要擔心沒有人可以為你提供相關的建議。這使很多情況我們會需要跟不同區域的外國同事交談，以討論深入的技術問題。   一個 Cloud Support Engineer 要成為 SME 有一定的門檻，但總體而言，在成為 SME 前必須要累積一定數量及技術水平的 Show Case (實際的客戶案例)，並進行至少由兩位現有專家的案例審查。通過之後，會另行安排技術面試 (時間可能是半夜或是早上，通常是配合其他時區的專家)。面試的考官除了有現有專家外，還會有開發那個服務的資深開發工程師加入，全程以英文對話來測驗你對於服務的了解及深度，最終再由考官們投票看看是否一致通過。這過程真的是有很多曲折離奇的故事能寫，但我相信 Amazon 對於工程師的技術標準要求仍是有一定的水準，所以絕對不是一個純接線生這麼簡單。   Cloud Support Engineer 如果成為某個領域的專家，通常也會想辦法貢獻自己的知識 (透過內部文件、製作訓練教材或是幫忙其他團隊審核公開發佈的內容)，並也有機會成為 Trainer，參與跨國訓練其他地區同事的機會。   負面情緒的客戶與第三方軟體   這一定每個行業都會有的，在我的工作中，常會收到負面情緒的客人通常都是購買 Developer Support Plan 的客戶，常常會挨著說每個月要充值 29 USD 太貴、問一般性問題都只能回 Email、能不能直接登入/SSH 到我的機器幫我設？   就我的觀察，這種客戶類型通常也是寧可花時間耗，也不是想解決問題，大部分的目的都是抱怨，通常也不願意花力氣學習 AWS，並總希望有人幫忙幹到好。這種客戶典型會問的問題也像是：為什麼我的 EC2 關了還是會一直重開，你們是不是亂動我的帳戶 … 等等。   (常見的情境通常是進場看個 3 秒，就注意到客戶開了 EC2 Auto Scaling，客戶卻完全不知道自己在幹嘛)      小知識：AWS 非常重視 Secuirty &amp; Privacy，特別關注客戶存放在雲端上資料的機密性及安全性。AWS Support 沒有權限更改客戶的資料/SSH 進入到客戶的機器，在協助客戶問題時，光要看客戶一些你都覺得沒什麼的配置 (比如這個帳戶在某個區域開了幾台 EC2)，都有嚴謹的稽核制度。    在我的工作中，通常處理一個案例，我們都得想辦法引導，甚至還得拜託客戶提供及收集一些資訊，以幫助我們確認下一步的動作或是進行分析。常常有個笑話說著：「對於完全不懂 Auto Scaling 的客戶或是會把 SSH private key 放進 GitHub 備份的技術人員，接觸 AWS，就像是手裡握著核彈的嬰兒具有破壞性。」一般來說，我們通常也會建議客戶找找相關的 Managed Professional Services 或是合作夥伴提供的支持計畫，也許能夠幫助這類型的客戶滿足建置的需求。   此外，還有些客戶會很喜歡詢問第三方軟體的一些問題 (比如 Terraform)。由於有些第三方軟體並不是我們能夠協助，也不是由 AWS 開發，這通常已經超出 AWS 所能協助的範圍。但在我的工作中，不可避免的有些客戶會跑來問也許你不是很了解的東西。這種情況下，一方面除了自己學習，通常都只能竭盡所能回答，並且根據我們能分析和掌握的範疇，提供非常有限的資訊。然後你總是發現，即使我們可能看一眼知道怎麼修正，並且提供一些可能的建議，我們只能提供有限的技術性指導，再無奈地請你關閉 Case，同時建議諮詢對應的服務提供者協助 (如果是 AWS 有合作的夥伴並且涵蓋在支持清單，我們會協助轉交至對應的團隊)。   畢竟我們並不是該產品的專家，如果你遇到 Bug，我們真的無法負責，這是一種心有餘但力不足的哀傷。   技術挑戰   其中，日常工作中會出現的情況之一，是我們會需要跟 AWS 開發團隊合作，以改進產品上所遭遇的問題。在我的工作上，很多時候可能是客戶遭遇了服務功能不支持、或是產品有一些已知問題。如果 Cloud Support Engineer 想到能提供其他解決方法，我們會建議客戶採取相應的行動，例如我之前在網站上發佈的幾篇內容，都是我們客戶實際遭遇，並且提供一些可用案例的例子：      CoreDNS(kube-dns) resolution truncation issue on Kubernetes (Amazon EKS)   [AWS][EKS] Zero downtime deployment(RollingUpdate) when using ALB Ingress Controller on Amazon EKS   上述過程涵蓋的技術分析只是部分的案例，對於我們內部工程師在分析問題時，這通常是我們會需要從中挖掘的深度，並在你分析後發現是一些坑、或是一些不同技術之間互相依賴關係所產生觸及令人意想不到的限制，還需要嘗試提供可用建議給客戶以解決他們所遭遇的問題。但如果是要建議開發團隊修復的已知問題，同樣也會提供類似上述的分析報告，並且協同開發團隊在下一個版本中修復。   這種長期在挖掘我們家產品的 Bug，每次甩分析報告過去建議他們怎麼修 Bug 的模式，其實已經某種程度上形成良好的循環，讓我們贏得開發團隊的信任，跟開發達成良好的合作關係。(我甚至也認識很多很猛的同事是直接幫忙貢獻代碼的)   在我的團隊中，能參與這樣的過程並能從中學習成長，實在是非常有成就感的一件事情。   因此，很多情況下，我們會需要學習用宏觀的角度分析並且切入問題核心，並且給予正確建議，而非只看單一問題亂槍打鳥，這是我認為這份工作最困難也最有趣的地方。   跟開發 (SDE) 差在哪   我們跟開發團隊相同共享存取服務原始程式碼的權限。所以有的時候，比較資深或是厲害的工程師，會協助開發找出應用程式的 Bug，並且指出要修正的細節。即使在我的團隊，仍有很多同事過去的背景從事開發、維運等不同角色。但在篩選標準上，技術的水平仍與 Amazon 開發團隊擁有著一致的標準，只是這個工作角色對於編程 (Coding / Programming) 的能力並不是必須。   但往往有時候擁有開發的經驗，在執行這份工作上，也能幫助你更加有效的定位問題的可能 (若屬於應用程式的問題的話)。與開發團隊最大的差異便是我們的工作不是在寫 code、做 feature，而是在解技術問題、每天都在 troubleshooting！(有的開發團隊工程師甚至不見得知道怎麼 troubleshooting，需要我們耐心引導協助客戶調查核心問題，這是也最有趣的部分)   並且工作型態固定，偏向 work-life balanced。   (但這並不代表你不能開發，很多 Cloud Support Engineer 還是會自己兼著做很多好用的工具，內部還是有很多專案能幫忙做的)。   總結   即使擔任雲端技術支持工程師約 1-2 年，我仍然對每天幫助人們應對棘手的技術挑戰感到興奮。我還是為了有機會每天學習這些實際案例而高興，並且能夠想辦法幫助不同產業客戶很多很偉大的業務達到成功 (大規模數據運算, 購物, 手持應用, Streaming, Travling, 加密貨幣交易 … 等)，確保客戶的服務運作在 AWS 上面保有高可用性和可靠性，以持續能運作 24 小時 x 365 天。最有趣的特別是面對一些未知問題最終發覺是個 Bug (不管是 K8s, Docker …)。   在 AWS / Amazon，在全球真的有很多優秀的人、超級酷的 Manager 還有超強的同事。在這裡工作就像是玩一場又一場遊戲，這個遊戲需要我們花很多力氣分享很多分析報告並且嘗試打爆每一個看起來不是那麼友善的問題，只為了提供更好的產品跟技術服務給到客戶。我很高興能夠參與超級多場類似這種遊戲，並且能跟很多優秀的工程師和開發團隊合作。   如果你正在疑惑 Cloud Support Engineer 是什麼樣的工作，希望這篇的內容能夠有助於你了解我們的工作日常。   若你對於這樣的工作環境及內容有所興趣並躍躍欲試，我們仍在持續招聘優秀的人才加入我們。我同時也在 NEX Foundation 為串連台灣人才於國際舞台上的職涯發展貢獻己力，你可以透過 NEX Work 附上 CV 提交內推申請 (需註冊登入) 以引薦更多像你這樣的優秀人才，或是透過我的 LinkedIn 與我聯繫。      NEX Work：申請內推 (需登入)   如果你覺得這樣的內容有幫助，可以在底下按個 Like / 留言讓我知道。   看更多系列文章      我在 Amazon 學到的 10 件事   我是如何在還沒畢業就錄取並進入到 Amazon 工作   我是如何在一年內通過 AWS 五大核心認證   Amazon Cloud Support Engineer 到底是在做什麼 (Amazon Web Services / AWS)   關於 Cloud Support Engineer 職位的常見問題 (Amazon Web Services / AWS) - AWS Cloud Support Engineer FAQs   在 AWS Cloud Support Engineer 面試中脫穎而出：必備的技術能力和重要特質   身處 Amazon 工作 5 年學到的事：在 AWS 擔任 Cloud Support Engineer 是什麼樣的體驗   ","categories": [],
        "tags": ["amazon","aws","amazon web services","work","Cloud Support","Cloud Support Engineer"],
        "url": "https://easoncao.com/what-is-cloud-support-engineer-doing-in-amazon/",
        "teaser": "https://easoncao.com/assets/images/posts/2021/02/what-is-cloud-support-engineer-doing-in-amazon/amazon-bear-chen.png"
      },{
        "title": "3 項原則讓你變得更有生產力 - 最有生產力的一年 The Productivity Project",
        "excerpt":"          最有生產力的一年   每一天，我們都有 24 小時的時間，過有意義的生活。然而，你我都有許多應盡的義務，它們佔去了我們大部分的時間，剩下來的時間便寥寥無幾。   每個人都想著如何在有限的時間內提高自己的產能，以盡可能完成更多事情。然而，在閱讀完最有生產力的一年 (The Productivity Project) 這本書後，我有了不同的啟發，改變了我對於生產力這件事情的觀點。   以下我將摘要書籍的內容，並列舉 3 項十分受用的方法。      在這篇文章中你將知道      如果你是一位熱衷於生產力的人，我會與你分享為什麼你該立即透過 Kindle 或是 博客來 收藏本書   生產力的真正定義   生產力的 3 項原則    概覽   作者 Chris Bailey 大概是地表上癡迷生產力數一數二的人了。   為了追求生產力，並探索生產力技巧這項遠大的目標。Chris Bailey 於 2013 年 5 月，從 Carleton University 畢業不久，決定拒絕了兩份優渥且高薪的全職的工作機會。並且開始了長達一年的計畫，名為「最有生產力的一年」(A Year of Productivity)。   在這一整年，作者不僅大量收集及閱讀任何有關生產力的資訊，並著手實驗，將所有的學習及心得更新至個人網站 (alifeofproductivity.com)。並且計劃在這整整 365 天中：      盡可能閱讀所有生產力相關書籍和學術期刊文獻、深入探討相關的研究   採訪生產力大師，了解這些人是如何有效率地過每一天   在自己身上進行各種生產力實驗，進而找出提高生產力的各種方法   過去實驗中也不乏很瘋狂且無厘頭的項目，包含：      一週冥想 35 小時   一週工作 90 小時   每天早上 05:30 (是在當兵吧 ….)，測試早起對生產力的影響   一週觀看 70 小時的 TED 演講   增加 5 公斤的淨肌肉量   完全與外界隔離的生活   一整個月只喝水，不喝其他飲料   最後在這段期間，匯總個人多年的生產力技巧及精華，寫入至該本書中。這本書的目的很簡單，為的就是要告訴你如何：      辨識出工作中不可或缺的任務   更有效地做好這些任務   像忍者一樣管理好你的時間   戒掉拖延惡習   聰明工作，不再白忙一場   培養出心無旁騖的專注力   一整天都保持禪定般的清晰思維   擁有過去從未有的豐沛精力   真正有「生產力」的定義      在現今，我們有著比以往任何時候更多的事情必須完成，周遭令我們分心的事物排山倒海而來，緊張和壓力從四面八方襲擊，甚至不得已下班後回家還得繼續工作。劫持我們專注力的響鈴和提示充斥我們周遭，而且我們比先前任何時候更無暇做一些養精蓄銳的事 (運動、均衡飲食、充足睡眠等等)。    但很多時候，我們常常會著迷於要把很多事情塞滿自己一天的行程表，乍看之下好像非常的高效，並且十分忙碌，然而，在本書中，點破了一個非常重要的問題，即是人們在努力提高生產力的過程中，常會犯一個很大的錯誤：   那就是持續的「自動化」工作：眼前有什麼任務就做什麼，絲毫不假思索。(這類似於 我在 Amazon 學到的 10 件事 提到搞懂重要性比起做一堆績效來得重要)。   事實是：      生產力跟你「做」多少無關，它只跟你「成就」多少有關。    最具生產力的人，其工作速度快到足以完成每件事，同時又慢到足以讓自己辨識最重要的事，然後從容不迫且用心地執行。   真正有生產力的定義，在於我們在時間內完成計畫的事項，並且帶來一定的影響。真正影響生產的不見得在於「時間不夠」，若你沒有足夠的精力 / 能量 (Energy) 或是專注力 (Concentration)，即使給你再多的時間，可能執行的效率仍低落。                     生產力的真正定義 - 時間、精力及專注力            這代表著你需要比以往任何時候更聰明地工作，以及更有效管理你的時間、專注力和精力。   3 項原則讓你變得更有生產力   雖然好像很多人都將「早起」與「成功人士」劃上等號，例如，你很常看到類似的標題：      為何成功的人都喜歡早起？8個名人的早晨習慣全公開，超乎凡人的高效率就從這來！   為什麼成功人士都愛早起？   成功人士的背後都有「早起」好習慣                     早起 = 成功人士?            但在作者經歷一年的研究，透過自己實驗每天 05:30 起床的計畫，不僅是生產效率並沒有特別顯著的提升，並且常常有一至二小時是無法工作的狀態。在採訪多位高效人士後，他發現，早起並不是提高生產力的主要原因。      一個人的社經地位高低，跟他是早起者還是夜貓子，一點關係都沒有。每個人的生理結構本來就不一樣，沒有一定哪個習慣就特別好。決定你有無生產力的關鍵，其實在於你清醒的時候做了什麼。    在之前，總認為無法早起的人就是懶惰、不自律的表現。但在這幾個月來讀過 Why We Sleep 一書，甚至閱讀到這些內容後，完全顛覆了我的舊有觀念，並從中調整自己的生產模式。以下是我實作後覺得很有效的 3 項核心原則：   1. 並非每件事情都同等重要   我相信每個人多少都聽過 80/20 法則 (80/20 rule, Pareto Principle)：通常有 20% 的變因操作著 80% 的局面。   因此，你必須先決定自己每天需要聚焦在哪些事情上面，如此你最有生產力的基礎才算真正穩固。      每天一開始，把心念快轉到一天結束之時，問問自己：當這一天結束，我希望做完哪三件事情？並把這三件事情寫下來    列舉出每日必做的 3 件事，你在一天中，便能有清晰的藍圖明白接下來 24 小時，你的時間應該花在哪。   三項成就之所以有效，是因為我們的大腦從很早以前即被訓練用「三」思考：開始、中間集結尾。例如，軍隊用「三」幫助人們記住存活的資訊：「你可以三分鐘沒有空氣、三天沒有水、三週不進食」。   如何刪減不重要的事物？方法其實很簡單：      A. 列出一份你應做的工作清單   B. 列出所有工作內容之後，問問自己：如果一整天只能做清單上的一項工作，哪一樣工作會讓你在同樣時間內達到最大成就 (對你自己最有價值？)   C. 再問問自己，如果你至多選兩樣工作做一整天，在相同時間獲致第二、第三大成就的會是哪兩樣工作？   衡量生產力最好的方法，就是在每天結束時，自問一個很簡單的問題：我完成了多少原定計劃做的事情？當你做完原定計畫的事情，表示你很清楚自己的生產力目標、並按部就班加以完成，在我看來，這才是有生產力的。   並非每件事情都同等重要，換句話說，在你的工作裡，明明花費的時間都一樣，但某些事情就是比其他事情讓你獲致更多成就。例如：      做好一週的規劃   指導新進員工   投資在自己的學習上   推掉無主題的會議   推掉徒勞無功的工作   安排重複性的工作自動完成   明明花一樣的時間，但你做上述事情所獲致的成就，會比以下這些事情還要多：      參加毫無意義的會議   時時關注社交媒體的最新動態   不斷察看你的電子郵件   閱讀網路新聞   跟別人八卦閒聊   你在重要事情上面投注越多的時間、精力和專注力，所獲得的成就會越多，你也會變得愈來愈具生產力。一項任務、計畫或是承諾之所以重要，通常基於以下兩點：      A. 它對你有意義、與你的價值觀密切關聯   B. 它對你的工作有很大的影響   作者提到，如果從未坐下來、認清哪些才是對我工作影響最大的任務，並且用心將之做好，則不可能有高的生產力。   這類似於美國暢銷書作家 Rory Vaden 在 2015 年的 Ted Talk 中，提到的概念 (我在這裡也附上了相關的影音)：      Your multiply your time by giving yourself the emotional permission to spend time on things today that will give you more time tomorrow.     我簡略翻譯為：你通過積極地給予那些能讓你明天擁有更多時間的事情上，使得你可以倍增你的時間                事實是，每個人仍一天只有 24 小時。但透過正確的檢視你的任務，同時刪減不需要、自動化或是委派的項目，並且專注於重要的工作使其帶來效益，能為你的明天贏取更多的時間。這正是在這短短 18 分鐘分享裡，提到的 Focus Tunnel 所要傳達的訊息：                     Focus Tunnel            為什麼我們總是覺得時間不夠用？其實你應該審視你的工作清單，並把精力專注在真正重要的事情上。   2. 追蹤你的時間到底都去哪      「我沒空做」是世上最大的藉口。當有人說他們「沒空」做某件事時，他們真正想表達的是，那件事並不如他們手上其他事情來得重要，或是具吸引力。每個人每天都有 24 小時的時間，他想要怎麼運用這 24 小時完全是他個人的選擇。    研究顯示，當你紀錄自己的飲食習慣，所減去的體重會多出一倍。像是我也會善用 MyFitnessPal App 有空隨手紀錄一天吃的飲食熱量、營養素和蛋白質攝取，以了解是否達到目標水平。這確實在潛意識中有效的提醒自己應該正確的攝取和飲食：                                                                                          我在 MyFitnessPal App 上的飲食紀錄       同樣地，當你開始做時間紀錄後，也會有類似的加乘效果。例如：我也曾經在一天結束後，隨手寫下自己當天大概做了哪些事情，為期大約一週。這確實有助於我在檢視自己將時間花在哪些地方：                     隨手紀錄自己的時間也是個追蹤的好方式            除了追蹤自己的時間都跑去哪之外，也同時需要好好管理生產力三大元素：      時間 (Time)：觀察自己如何明智運用時間、一天當中做完多少事情，以及拖延的頻率已多高   專注力 (Concentration)：觀察自己專注在哪些事情上、專注力是否集中，以及是否常會分心   精力 (Energy)：仔細觀察自己的動力、積極度與整體的精力，監測自己的能量在各個實驗過程中的高低波動   在一天中，學會善用生理時間段能夠讓你有效的完成重要的任務，這是因為，我們的一天中精力通常都有限。   精力就像是一整天的燃料，用來維持高效的生產力。因此，妥善管理精力 (Energy) 非常重要。如果你的油箱裡缺乏燃料讓你做好工作，或是因為你沒有吃好睡足、培養足夠的精力，而導致體力透支，則生產力就會直線下降，就算你的時間或專注力管理得再好也沒有用。   同時，也有很多方式能夠幫助你保留更多的精力：      如果你貫徹極簡主義，你可以擁有固定的幾套衣服搭配，出門不再花心思選擇穿什麼，把思考的能量留在更重要的事情上   做好明天甚至一週的餐點，不必再煩惱午餐吃什麼   關閉你手機的通知和提醒，不讓其干擾中斷眼前的工作，專注處理重要的任務   將不重要的任務延遲，再批次性的處理瑣碎工作   為了釐清尋常日子裡能量波動的狀況，作者也設計了一個為期三週的實驗，每個一小時便紀錄自己的能量狀態。在為期三週的實驗中，同時還做了以下事情：      飲食中完全戒除咖啡因和酒精   盡量少吃糖   少量多餐，讓一整天都有燃料可用   想睡就睡，想醒來就醒來，不設鬧鐘   從實驗中，作者可以發現自己在每天早上十點至中午，以及下午五點到八點左右，是他精力最旺盛的時間。在能量高峰期間，可以執行最重要的項目；在能量下滑時，採取低效率任務行動，提高體能和心力。   花時間觀察你的精力在一天當中的波動，如此一來，便能在「生理黃金時段」處理對你影響最大的任務（此時你有最充足的精力與專注力可以投入），並且在精力下降時，處理對你影響最小的任務。最有生產力的人不只能有效管理自己的時間，他們同樣也能管理好自身的精力和專注力。   要想更加慎重地工作，覺察是關鍵。你必須覺察自己的精力水平，如此才能聰明善用你一天當中的能量。   現代科技的進步實為一把雙面刃，你可以透過善用科技工具幫助你追蹤時間，也可能因科技偷走你很多時間。現在很多 App 都設計了時間追蹤的工具，不妨也試著善用這些工具，例如，Instagram 也提供了追蹤使用該 App 的時間：                                                                                          Instagram 使用時間紀錄       雖然我熱愛資訊科技，並且樂於享受這些產品所帶來的好處，但我同時也漸漸意識到這些產品背後帶來的潛在問題。在過去至少 12 個月的時間裡，我將 Line 和 Instagram 的通知功能全數關閉、震動提醒全部改靜音，移除了 Facebook、Messager 相關的軟體。我的生活因此有受到嚴重的影響嗎？不，自此以來，這種模式讓我獲得非常大的救贖，我能夠在我真的有空閒之餘「主動」的去查看訊息，而不是「被動」的被餵養訊息並且遭到中斷。   這使我花費在社交軟體的時間逐漸降低，並且排除掉了很多不必要的干擾。但你可能會問：      通知關掉這樣別人怎麼找我？    我只能說，這樣的疑慮可能是多餘的。真正重要的人、事，肯定可以透過你的手機號碼與你電話聯繫到你，並且讓你知悉。而那通常是你人生中，20% 你所重視的人。   真正在乎你的人，如果真的有很重要的事情，是不會介意用打電話的方式與你聯繫的。   通訊和社交軟體改變了眾多人的使用習慣，人機介面專家們無所不用其極的想把你的注意力留在他們的產品上，卻也可能間接偷走了你非常多的時間。但這個世界不應該只侷限於一個像素點屏幕，並且汲汲營營的努力經營自己的虛擬形象，人生大部分的時間還是值得花費在真正更有意義的事物上 (例如：創作、體驗生活)。   試試這項方法降低你對這些產品的注意力和花費的精力，也許你也可以在你的生活中注意到一些變化。   3. 清空腦袋   多數腦科學研究提及，要將短期記憶轉化為長期記憶，實則是一項非常浩大的工程。這意味著也許你我天生本來就不擅長記憶事物，我們的大腦更像是一個強而有力的運算單元，而非因儲存用途被設計。   它用於創意發想、思考以及解決複雜的問題。在本書中，基於腦科學研究的理論，提到了幾項可行性的實務建議：      一次只做一件事：將你的任務拆解為一至兩項的小目標，而非因多件事物同時間影響你的專注力   製作焦慮清單 (Worry List)：將你會煩惱的事項紀錄並將其拋諸於腦後 (讓大腦於背景執行中思考解決方式)   冥想：多數研究證實冥想對於清空大腦和提升專注力有一定的效果   有時候，我們仍無法避免進行一些低回報性質的維護類型任務，例如：清理收件夾、剪指甲、分類郵件、準備午餐等。   但維修保養類型的工作，卻不可不做的主要原因，是因為，它通常用以維持你個人的工作與生活正常運作。你若不烹煮健康的食物，便很難吃得健康；若是沒有隔幾天刮一次鬍子、洗頭髮並吹乾，便很難有清爽的外表；你的房子若是亂成一團，回到家就很難感到舒服。甚至以情緒、煩躁等形式影響你的大腦，剝奪你的專注力。   這種情況，如果有很多瑣碎的事項，不妨安排「維修日」來讓你更好地處理這些事項。   整個星期，逐一記下所有的低回報維護任務：從採買雜貨到修剪指甲，全部寫在表上。在那個星期裡完全不做，而是等到週日 (維修日) 再一次全部處理。清空你的腦袋，並有效率的批次完成工作。   當然，如果你實在無法安排一天的「維修日」，不妨試著逐一記下你整個星期必須做的維護任務，並且建立一張維護清單。這樣一來，當你精力不足、無法專心處理高影響力的任務時，你就可以一次處理維護清單上的好幾個任務，多少減輕一些工作的負擔。   總結   「最有生產力的一年」真的是我目前閱讀許多提高生產力的書籍中，唯一一本書籍，能以非常有系統化的方式，告訴你何謂生產力、反轉觀念，和逐一分享許多提高生產力的方法。在書中同時提到了非常多你可以立即去嘗試建議，例如：      排除會令你在生產黃金時間時可能的干擾，例如：降低使用手機、社交媒體的頻率 (例如關掉手機的新訊息提醒 — 超級有效！)   處理高回報的任務，一次只做一件事   正確飲食、睡眠、培養良好的習慣 (例如我在原子習慣一書提到的幾個方式)，並追蹤自己的任務及時間            多喝水、少喝含酒精、糖分甚至咖啡因的飲料：人體一旦缺水，將會引起疲勞、嗜睡、焦慮及難以集中注意力，這所有症狀都會降低你的生產力           現在的社會充斥了各種善用大腦設計的誘因促使人們黏著 (速食、社交媒體)，也讓人感覺使用某些工具，似乎就能獲得立即生產力提升的效果 (Trello、clickUp)。但是，想要從變得更有生產力的浪漫想法中，跳到每天完成更多的實際狀態裡，你一定得付出努力。   請記得，快沒有用，改變需要長期耕耘。   這本書裡面，還設計了很多很簡單的小挑戰，一步步引導你成為更有生產力的人類。由於細節實在是很多，無法一一列舉。如果你也期待自已能擁有高效的人生，並想學習更多具體的方式，你可以透過下列連結取得相關的電子、實體書籍版本直接收藏至你的書單：                                                                                                                       最有生產力的一年: The Productivity Project (Kindle)                                                    Kindle 數位版售價 $9.50 優惠連結                                                   獲取優惠                                                                                                                                                    最有生產力的一年 (博客來)                                                    博客來 79 折優惠連結                                                   獲取優惠                                        看更多系列文章      沈默並不代表軟弱：內向的你必須看的一本書 - 安靜的力量 Quiet Power: The Secret Strengths of Introverts   3 項原則讓你變得更有生產力 - 最有生產力的一年 The Productivity Project   原子習慣：細微改變帶來巨大成就的實證法則 - 我的心得及實作   刻意練習 - 實踐刻意練習的 3 項原則，往專家的道路邁進，我的心得及實作   ","categories": [],
        "tags": ["book","personal growth","reading","productivity","work","kindle","amazon","自我成長"],
        "url": "https://easoncao.com/the-productivity-project-reading-feedback/",
        "teaser": "https://easoncao.com/assets/images/posts/2021/03/the-productivity-project-reading-feedback/book-cover.jpg"
      },{
        "title": "沈默並不代表軟弱：內向的你必須看的一本書 - 安靜的力量 Quiet Power: The Secret Strengths of Introverts",
        "excerpt":"這本書是我在聽張鈞甯於 Vogue 提供的 night night 真心話節目中聽到的一本書。安靜的力量系列書籍，其內容核心雖相同，卻有不同主題圍繞於不同主軸：      Quiet Power: The Secret Strengths of Introverts (安靜的力量)   Quiet: The Power of Introverts in a World That Can’t Stop Talking (安靜，就是力量：內向者如何發揮積極的力量)             安靜的力量   這是一本寫給年輕人的書，書中內容用非常多的實際案例圍繞著內向者的特質及優勢。      內向者其實比起外向者們，更加有力量。想得很多的內向者們，外表雖然安靜，卻個個是驚人的思想家。    在偶然的機會下讀到這本書，讓我從中更加了解自己，明白自己內向的特質、了解自己與眼中曾經羨慕「很開放、很嗨、很好玩、感覺很活潑」的朋友們有極大的不同。   但這並不代表我不好，相反，其實我擁有很多他們沒有的特質、深思熟慮的個性、天塌下來都無法撼動的專注力，這都是我曾經羨慕那些人不突出的的優勢。讓我意識到，其實我也很棒！   每段文字所體悟的感觸，都促使我願意撰文。只非常希望你可以早點認識這本書。如果你周遭有著內向的朋友，透過本書，你將會更明白如何與他們相處，並且學會觀察及了解內向者們的優點。      這本書就像一冊指南，教的不是如何把自己變成另一種人，而是如何運用你身上早就存在的美妙特質及技巧，在這個世界大放異彩。    以下我將以安靜的力量 (Quiet Power: The Secret Strengths of Introverts) 這本書籍作為主要摘要的內容，並列舉 3 項我從這本書中所學習到的事。      在這篇文章中你將知道      必須透過 Kindle 或是 博客來 收藏本書的理由   如果你因為太害羞而不敢直接說出內心想法，但這並不代表你不好。你在閱讀後將會明白其實有很多人跟你一樣，你並不需要感到無助！   你將會明白這本書會如何引導你找到自己的特質，並善用自己的優勢！    概覽   作者 Susan Cain 是個不著不扣的內向者，花了多年的撰文，於 2012 年完成了 Quiet 一書，為內向者發聲，在全球引起廣大的迴響。   在 2012 年，Susan 在 Ted Talk 上分享了以內向者為主題的內容：The power of introverts，在我撰文之時，更是已經突破 2800 萬次以上的點閱：               內向的我們，有時候我們可能會很怨恨，自己為什麼並不能在眾人或是陌生人面前，自在的展現自己。一旦受到眾人目光投射，早已經恨不得地上鑽個洞躲進去，緊張且不安地要命。   即使努力訓練，在人們面前不這麼膽怯努力的分享想法，還是會感受到一絲絲的不自在，迫不急待的跑回自己的空間充電。   內向有時候可能還帶有貶義的味道：「他很內向」像極在說著「他不善交際、不會與人溝通、性格怪異、有點孤僻」。這麼說來，內向的個性好像並不是一個很令人羨慕的特質，並完全無法在這個急需表達自我想法的社會中生存。   但事實是，內向的你，其實蘊含力量：      慢慢地我了解到，自己面對生活時的沈靜態度，一路走來都賦予我強大的力量。     許多對世界做出重大貢獻的人，無論是創辦 Apple 的賈伯斯 (Steve Jobs)；或是寫出著名童書 - 魔法靈貓 (The cat in the hat) 的蘇斯博士 (Dr. Seuss)，無一不是個性內向的人，但他們把這種安靜的性格變成助力，而非阻力。     內向者沒有一體適用的定義：我們喜歡和人相處，但也喜歡獨處；我們可以輕鬆和人往來，但同時也文靜內斂；我們觀察力敏銳，通常多聽少說；我們有自己的內在世界，而且很看重這個內在世界。     如果說內向者注重內心，外向者就剛好相反，他們在人群中很自在，與人相處特別有活力。    內向者有時候很容易辨認：別人呼朋引伴時，我們會自己一個人縮起腳窩在沙發上，腿上放本書或 iPad；在摩肩擦踵的派對裡，我們可能會和兩三個朋友聊天，但絕對不會爬到桌上跳舞；在課堂上，老師問有沒有人自願回答問題時，我們會把視線移開，但這並不表示我們沒在聽，只是想先安靜地聽聽別人怎麼說，準備好了再回答。   然而有些時候，內向者很會隱藏自己的本性，在教室或學校餐廳可能沒人會發現我們其實生性內向；可能舉手投足都是眾人的焦點，但內心卻只想躲開人群，自己獨處。   當然，沒有人是完全的內向或外向。這種內外向的特質像是共存於同條光譜：一端為極端的外向者，另一端則是極端的內向者。人的個性即使再怎麼接近某一端，仍然會帶有少許另外一端的特性。                     內向 (Introverts) v.s. 外向 (Extrovert)            內向者 10 大守則   身為內向的你，其實很厲害。書中前幾頁就列舉了 10 大內向者守則直接破題。用來告訴你，安靜的你，其實並不是什麼缺點：      文靜的個性具有看不見的神奇力量   「想得很多的人」，稱為「思想家」   傑出的想法大多在獨處時產生   你的個性可以和橡皮筋一樣伸縮，外向者做得到的，你也可以 (成為眾人目光焦點也不例外)。之後，你還是可以做回安靜的自己   雖然偶爾要有彈性，但最後還是要做回原本的自己   有兩三個知心之交，甚比有一百個點頭之交要好   內向和外相就像「陰」和「陽」，彼此相愛、彼此需要   如果看到認識的人但不想閒聊，就過馬路躲開吧   不是只有活潑外向的人才能領導，甘地 (Gandhi) 就是內向領導人的好例子   用溫和的方式，你可以撼動全世界 — 甘地 (Gandhi)   文靜多有力量？書中同時列舉了許多了不起的藝術家、發明家、科學家、運動員及企業老闆，告訴你，其實他們都是內向的人：      甘地 (Gandhi) 小時候個性害羞，幾乎什麼都害怕，他總是下課一打鐘就衝回家，免得與同學來往。長大後，仍忠於自己的天性，以和平、非暴力的方式抗爭引導印度迎向自由。   NBA 運動員賈霸 (Kareem Abdul-Jabbar) 可以在上萬名觀眾前使出招牌天鉤。但他其實不喜歡出鋒頭及受眾人吹捧，並且說自己是個怪胎，只是剛好很會打籃球。喜歡閱讀歷史書籍、寫寫內容，並出版過小說和回憶錄。   碧昂絲 (Beyoncé) 雖然小時候就在眾人前演出，仍坦承小時候很內向。雖然現在演出時充滿自信，但仍安靜穩重，觀察入微的內在依然不變。   艾瑪華森 (Emma Watson) 也是內向害羞的人，坦承自己不擅長社交、不會閒聊、認識新人覺得有壓力、在公眾場合非常不自在。但仍在演藝事業上有著傑出的表現、站上聯合國的舞台發表演說為女權發聲，並且於 2011 參加 Visiting Student Programme 完成在牛津大學 Worcester College, Oxford 的學習，才智兼具。   愛因斯坦 (Albert Einstein) 是一位著名的內向者，卻徹底改寫了物理學的定律，發表了舉世聞名的「相對論」(Theory of relativity)   3 個思維讓你更加喜歡內向的自己   世界上大概有三分之一的內向者，內向的個性並不會在大後就消失；反之，你會逐漸長大，並成為一個內向的大人。你必須接受這項特質，更要珍惜這項特質。      如果你能發現自己內向的特質有多特別，而你喜歡自己的那部分 (有些正來自於你的內向本性)，就更能在生活各方面培養出自信。     不必照別人的話去做，選擇所謂「應該做」的活動、交上「應該交」的朋友；你可以做自己真正有興趣的事情，與真正重視的人當朋友。    從現在開始，我們都可以擁有不一樣的思維來學會如何更喜歡自己。以下我將與你分享我在本書中體悟的 3 個思維，讓你也能更加重視並且喜歡自己的特質：   1. 這個世界對內向者很不公平，但我們都能學會理解，並學會發揮自己的優勢   這個社會往往忽視內向的人，我們把能言善道、喜歡爭取他人注意的人當成偶像。彷彿他們是所有人都該效法的模範，也就是覺得每個人都應該才思敏捷、充滿魅力、勇於冒險，而且行動應該勝過沈思。   這種想法在學校影響特別大：學校裡聲音響亮、能言善道的孩子往往人緣最好，老師也會特別嘉獎那些踴躍舉手回答問題的學生。   但知識的力量不容小覷，內向就是一種個性。我們都可以學會理解外向、內向者的不同，並且了解，這就像是男女不同性別一樣，造成想法差異的有趣之處。   一旦你如此學會理解自己與外向者與眾不同的地方，自然而然就不再為自己的不同而感到失落。   檢視自己的內向特質   以下有幾個簡單的問題，能夠幫助你檢視自己是否偏向於外向或是內向的人格特質。這並不是一個絕對的測驗量表，只用於幫助你檢視自己的特質：      我喜歡一個人獨處   我喜歡深入討論一個主題，不喜歡聊天   朋友說我都會仔細聽別人說話   我喜歡小班級，不喜歡大班級   我不喜歡起爭執   我會把作業做到盡善盡美，才願意給別人看   我自己一個人工作時效率最好   在班上我不喜歡被老師點到   和朋友出去，即使玩得很開心，結束後我還是覺得筋疲力盡   我喜歡和幾個親朋好友過生日，不喜歡開很大的慶生派對   在學校，我不排斥從事個人的大型獨立作業計畫   我常常待在自己的房間裡   我通常不做太冒險的事   寫作業、練習運動或樂器，或進行需要發揮創意的活動時，我一次可以做好幾個小時也不厭倦   我說話前會先思考   聯絡不熟的人，我比較想寫電子郵件或傳簡訊，比較不想打電話   成為眾人目光的焦點會讓我不太自在   我比較喜歡問問題，不喜歡回答問題   常有人說我講話很小聲，或說我很害羞   如果一定要選一個，我寧願整個周末沒事做，也不要塞滿活動   請注意，如同前面提到的，沒有人是完全的內向或外向。這種內外向的特質像是共存於同條光譜：一端為極端的外向者，另一端則是極端的內向者。人的個性即使再怎麼接近某一端，仍然會帶有少許另外一端的特性。   如果上述的問題大部分的回答是 Yes，那僅能說明你傾向於內向者的生活模式，並且因這種模式感到自在。   既然如此，何不學習自己最舒服的模式面對生活中的每一天？從今天開始，你可以告訴大家自己最喜歡的方式與人們相處。一旦你越了解自己，你就越能在對人際關係相處的迷茫中找到你的優勢。   例如：你是一位團隊領導者，但也許你不需要是會積極喊口號、大嗓門有話就說的團隊領導者，但是你可以選擇成為以身作則、全力做好隊員表率的領導者；你可以深入與隊員一對一交流，了解隊員並幫助他們發揮出色的表現。也許不常發言，但內斂沈穩。只要帶領團隊獲得成功，這同樣也是一個優秀的管理者。   其他你也能做的事情還有 ….      做你自己：真正的朋友會欣賞你原本的面目，不必為了讓人留下好印象，就裝出另一種個性。   別怕孤獨：如果身別的人或朋友待人刻薄、不懷好意，就趕緊抽身。寧可沒有朋友，也不要和一群會傷害、霸凌你的人當朋友。你的朋友應讓你覺得放鬆自在，無論開心難過，都可以讓你展現自己真正的一面。   從小處累積：先找一位好朋友就好，一旦感情穩固了，而且也認識另一位可以真心信賴的人，再開始考慮結交更多朋友。   拋出問題：懂得聆聽是內向者的強項，要好好發揮這項優勢。你可以拋出一個問題並仔細聽，聽完再接著問，讓他們了解到你確實有仔細聽他們說話。你不但可以很快了解對方，也可以趁別人在說話時，趁機喘口氣 (不必說話)。   設想別人的感覺：你可以想像一下對方可能有什麼感覺，這樣與其相處時，也許能自在一些。   把話說出來：沒有人會讀心術，如果對方真心與你交朋友，你可以勇敢的把話說出來   2. 沈默並不代表軟弱 — 內向者可以學會沈靜，不沈默   很多時候，課堂發言或是團體討論的情境不可避免。然而，多數時候，內向的我們可能大部分時間都選擇沈默。也許對於發言沒有什麼自信、或是膽怯，似乎讓人感覺自己並沒有參與討論，好像在放空。   然而，事實是，內向者的不開口，不一定是因為害怕，或是全然沒有在進行思考。而是因為，許多內向的人只在有重要事情要講時，才會開口說話。   外向的人剛好相反，喜歡用說話幫助思考。相較之下，我們內向的人喜歡先想清楚再開口。其他類似的原因如下：      怕講錯話   不想說沒意義的話   忙著聽別人說，來不及想   沒有足夠的時間想出答案   擔心一開口舌頭就打結   不喜歡大家盯著我看   不喜歡成為目光焦點   其實，內向者能專心深入思考單一主題的能力，是一種天賦；如果突然被點起來回答問題，我們可能會呆在原地，因為沒有足夠的時間仔細想好答案。   內向的人往往很注意答案是不是有內容、夠不夠清晰。所以寧可不開口，也不願隨便吐出一兩個句子應付。   應對這種狀況，你可以：      找到能自在表達意見的方式：坐在前排，這樣講話時其他人不會注意到其他人都面向著自己，壓力會小一些   早點出擊：搶在所有人面前先發言，盡量早點回答問題   寫小抄：如果擔心會講到一半腦袋打結，可以先在紙上寫上小抄，後續就能參考   後續補充：如果有好的看法，可以在後續透過電子郵件或是其他方式與大家分享，讓大家知道其實你也很認真的在思考這個問題   給自己動力：可以想想，什麼目標對你最重要。你愈是喜歡某個主題，發表意見時就愈有自信   3. 內向不是問題，只是相處模式不同   注意自己在什麼場合中最自信且自在，學到經驗後，就知道什麼樣的活動適合自己。你可以找到自己的「療癒角落」(Restorative niche)，幫助你在面對人群時有可以充電的地方。它可以是臥室、陽台、籃球場、圖書館的隱密角落、洗手間，只要是讓你感覺安全舒適的個人空間都可以   每個人習慣的社交圈大小也不同，從幾個到幾百都有。但都不要緊，只要結交的朋友是自己喜歡的，人數並不重要。      有個內向的朋友，每次有人邀她參加派對都會出席，而且人緣很好，所以邀約不斷。她也很喜歡和大家聚聚，大家也很高興她來參加。     不過一兩小時候，就會感謝主人招待，優雅地道別。沒有人注意到她悄悄離開，大家也不介意先告別，光是看到她來就很高興了。    在安靜的地方獨處一段時間，可以讓內向的人恢復活力，像電池又充飽電一般。所以我們比較喜歡一個人的活動，像是看書、跑步或爬山。如果有人說個性內向就是反社會人格，千萬別信；我們只是和人互動的方式不同而已。      「朋友出去玩還在 Facebook 上貼了一張照片」 ….. 為什麼沒有我？我自己一個人在家好嗎？    社群網站有時會讓我們更強烈地感受到自己被遺漏在外，儘管你想要在家度過寧靜的夜晚，但在網路上看到別人週六晚上都有活動時，可能會因此對自己的生活方式感到懷疑。   不過，如果選擇做自己喜歡的事，即使因此錯過別的事，也不需要後悔。你可以選擇把手機調成勿擾模式 (Do Not Disturb)，這樣在當你沈浸於自己喜愛的事物時，就不會因社群網站的通知而干擾受到影響，而覺得自己應該去做別的事。   要記得，大多數人在網路上呈現的生活都經過美化。滑滑你朋友的 Instagram 上都貼了哪些照片？度假、美食、在派對裡開懷大笑、身邊朋友環繞 ….. 可是沒有人會貼星期天早上穿著睡衣吃穀片這種沒那麼光鮮動人的照片。   所以你無需違背自己的意志，而選擇迎合讓自己看起來好像很受歡迎。選擇自己舒適的方式和空間，並追隨自己所愛熱情的事物，你打從心底會更愛死自己在做的事情。   總結   內向的人擁有神秘能力：深刻思考、專心一志、安於孤獨以及擁有絕佳的聆聽技巧。      雖然這個時代，似乎不太能夠容忍沈默不語；但是請切記，這個世界上像我們內心一樣個性內向的人，仍比你想像中的要多。     全世界有三分之一到一半的人內向者。有不少個性和你一樣的人，都在努力穿越一道道擁擠、混亂的走廊。     身為內向者的你，有能力成就任何事。    內向的人可以靜靜地撼動世界、話不多卻可以一語道破、不善張揚卻蘊含高深的內涵。無論你的個性是內向或外向，安靜的力量這本書依舊能幫助你更加了解自己的人格特質，並學會擁抱自己的特質：      找到你最熱切的理想：凡是追求崇高的理想，就不時會遭受考驗，所以一定要選擇自己有強烈共鳴的理想   發揮自己的長處：記得擁抱你文靜的長處，並盡量學習每一件事   建立有意義的人脈：你不用每個人都認識；認識幾個真誠、深交的朋友，會比一幫泛泛之交更有力量   挑戰自己，延展橡皮筋：你可以每天做一件會讓你害怕的事情，小事也行 (在課堂舉手發言、坐在不認識的人旁邊)。挑戰自己，突破舒適圈可是件會讓人上癮的事情。一旦養成習慣，就會固定去做有挑戰性、也覺得有收穫的事情。   堅持不懈：相信自己的使命，如此才能排除萬難，獲得成功   這本書中，提供了身為內向者的你如何運用自己人格特質，依然能於生活中大放異彩。如果時間能回溯，我很希望自己在國中、高中時就讀到這本書，因為它完全讓我更加了解自己的特質，並且為自己擁有這項內向者的天賦開始感到自信。   (本書也提供了給予老師、家長相應的指南，幫助你協助內向青年找尋挖掘自身的特質，真恨不得每個修教育學程的老師都應該讀一遍。)   如果你也想了解更多內向的自己，並想學習更多與之相處的方法。你可以透過下列連結取得相關的電子、實體書籍版本直接收藏至你的書單：                                                                                                                       安靜的力量，從小就看得見 (Kindle)                                                    Kindle 數位版售價 $5.50 優惠連結                                                   獲取優惠                                                                                                                                                    安靜的力量，從小就看得見 (博客來)                                                    博客來 79 折優惠連結                                                   獲取優惠                                        看更多系列文章      沈默並不代表軟弱：內向的你必須看的一本書 - 安靜的力量 Quiet Power: The Secret Strengths of Introverts   3 項原則讓你變得更有生產力 - 最有生產力的一年 The Productivity Project   原子習慣：細微改變帶來巨大成就的實證法則 - 我的心得及實作   刻意練習 - 實踐刻意練習的 3 項原則，往專家的道路邁進，我的心得及實作   ","categories": [],
        "tags": ["book","personal growth","reading","personality","introversion","kindle","amazon","自我成長"],
        "url": "https://easoncao.com/quiet-power-the-secret-strengths-of-introverts-reading-feedback/",
        "teaser": "https://easoncao.com/assets/images/posts/2021/03/quiet-power-the-secret-strengths-of-introverts-reading-feedback/book-cover.jpg"
      },{
        "title": "台新 Richart 到底能不能轉到 TD Ameritrade (海外轉帳)？答案是 Yes - 3 個步驟開啟 Richart 海外約定轉帳",
        "excerpt":"台新 Richart 目前可以說是台灣數位網路銀行設計數一數二的應用 App，不管是轉帳、分離帳戶或是統計報表都一目瞭然，非常容易上手使用。而且開戶過程全程無需跑銀行，只需要下載手機 App 並且在數個工作天後即可完成。當時推出時，真的可以說是傳統保守的台灣銀行界裡的一大項創新。                     3 個步驟開啟 Richart 海外約定轉帳            目前台新仍在推出開戶優惠計劃，你可以使用我的以下專屬連結註冊，完成開戶後就可以獲得 100 塊台幣：      點擊這裡申請Richart存款帳戶並首次登入Richart APP成功，就能獲得 NT$ 100 用戶禮   由於預設 Richart 提供的外幣帳戶通常並不能很好的支持直接將資金轉入其他帳戶。因此，若你有想要設置轉帳至海外帳戶進行投資 (例如：TD Ameritrade、Firstrade、Interative Broker / IB、Charles Schwab 嘉信 … 等等)，以下內容將幫助你了解在開戶後可以如何開啟該功能：    在這篇文章中你將知道      台新 Richart 設定國外約定轉帳的方式   3 個簡單步驟將資金轉移至海外券商   如果你還沒有 Richart 帳戶，可以點擊這裡申請Richart存款帳戶並首次登入Richart APP成功，就能獲得 NT$ 100 用戶禮    如果我想要轉到海外投資帳戶，能用 Richart App 內建的功能轉嗎？    May 30, 2021 更新     使用 Richart App 轉帳到 TD Ameritrade 的具體步驟   Richart App 注資的部分限制   使用 Richart App 轉帳的交易手續費       不能，期待未來有機會開放 可以，但有部分限制，請參考以下資訊    2021 年 2 月我注意到 Richart App 提供了外幣轉帳的功能，若你正在海外留學或是工作，這項功能十分方便能夠直接將外幣進行轉帳。                                                                                          Richart 提供的外幣轉帳功能       2021 年 2 月之前，若要轉到 TD Ameritrade 將資金轉出，該功能有兩個問題：      無法備註附言   無申報項目 262 - 投資國外股權證券 項目 (未正確申報將資金轉出可能會衍生後續逃漏稅務責任)   但在近期 Richart App 改版後 (2021 年 5 月)，台新銀行已經釋出對應的改版，目前你可以嘗試在你的手機應用中檢視是否存在以下功能，並且遵循以下步驟轉帳：   (需要在台新線上外幣匯出匯款交易時間操作: 營業日 09:00 ~ 15:00)   在 Richart App 使用外幣轉帳注資到 TD Ameritrade 步驟   (Richart App) Step 1. 打開 Richart App，點擊「外匯」並選擇「轉帳」                                                    於 Richart App 外匯頁面中選擇轉帳       (Richart App) Step 2. 填入 TD Ameritrade 或是其他海外券商提供給你的帳戶資訊                                                                                          在 Richart App 中填入對應的轉入對象帳戶資訊       (Richart App) Step 3. 選擇正確的匯款性質並填入附言   這一步是最重要的動作，攸關你的錢是否能正確電匯到海外帳戶中。請確保你的交易正確填寫附言，附上 TD Ameritrade 或是其他海外券商提供給你的個人帳戶號碼：      匯款性質請選擇：投資國外股權證券   附言我使用的格式是：&lt;TD 帳戶號碼&gt; / &lt;姓名&gt;                                                    於 Richart App 外匯頁面中填入附言       (Richart App) Step 4. 確認外匯轉帳交易   完成填寫後，點擊將會轉到確認頁面，請確認轉帳資訊無誤 (特別是附言)：                                                    於 Richart App 外匯頁面中確認轉帳交易       (Richart App) Step 5. 完成轉帳   確認無誤後，如果一切正確操作，將會顯示扣款成功的畫面：                                                    於 Richart App 外匯頁面中確認轉帳交易       一旦你的外匯交易成立，銀行將於交易時間結束後 (15:00 PM)，將發電報並且將款項電匯至對象帳戶。如果你真的不小心寫錯附言，請不要猶豫立即致電銀行，以嘗試了解是否能更改或是取消交易。   使用 Richart App 轉入海外投資帳戶的手續費及注意事項：      每筆外匯轉帳優惠手續費於 2021 年 6 月 30 日前為 $10 USD，費用會從你的外幣帳戶另外扣除 (不包含中間行或清算行扣取之相關費用 — 請參考：Richart外幣轉帳手續費收費標準)   目前單筆最大上限為 $1,500 USD，我已經幫大家試過了，如果超出這個金額，會在轉帳前跳出提示把你擋下來                                                    Richart App 外幣轉帳單筆限制       我在 May 28, 2021 執行這筆交易，款項到 TD Ameritrade 後，中轉行仍然會收走 20 USD 的手續費，我從帳戶轉出了 $ 1, 500 USD，實際到帳金額為 $ 1, 480 USD：                     使用 Richart App 將資金正確轉到 TD Ameritrade 帳戶            因此，你可以試算該功能外幣轉帳費用如下：      10 USD (Richart App 優惠外幣手續費) + 20 USD (中轉行手續費) = 30 USD    由於在我撰文時，使用 Richart App 進行外幣轉帳的單筆交易限制為 $1, 500 USD，這會在當你有大筆資金拆分注入時，產生頻繁的交易手續費。因此，如果你偏好大筆金額定期轉入，用於降低手續費的交易成本。並且仍然想使用 Richart App 提供的換匯功能累積資金轉帳至海外投資帳戶 (比如 FisrtTrade, TD Ameritrade 這些需要備註附言的帳戶)，你仍可以依循以下流程進行設置，開啟更進階的外匯交易功能。   如何開啟台新 Richart 轉帳至 TD Ameritrade 或是 Firstrade？   由於業務性質不同，很常遇到分行辦事人員並不是很清楚 Richart 的業務 (我在分行也是辦事人員現場打電話確認詢問。因此，如果你需要 Richart 的客服提供協助，可以透過 App 或是電話與他們聯繫協助處理)。   以下我將用自身經驗與你分享 3 個必要步驟，以幫助你在跟行員糾葛時，能節省更多時間：   Step 1: 事前準備      TD Ameritrade 或是其他海外券商 (Firstrade, IB, 嘉信等) 提供的約定帳號   印鑑   身分證   手機 (可以先下載台新銀行手機 App)   總花費時間：約 1-2 小時，具體時間取決於該分行效率及排隊等候人潮。   TD Ameritrade 約定帳戶資訊   如果你是屬於台灣電匯的投資者，TD Ameritrade 約定帳戶都是使用以下固定帳戶轉戶，並涵蓋附言將你的資金轉入：   Beneficiary Bank (銀行): First National Bank of Omaha Address (銀行地址): 1620 Dodge Street, Omaha, NE 68102 SWIFT Code/ID: FNBOUS44XXX  Beneficiary (戶名): TD Ameritrade Clearing, Inc. Account Number: 16424641  Remark (匯款附言): 帳號英文姓名 / No. TD 帳號   更多細節可以參考 TD Ameritrade 提供的相關資訊。   Step 2: 開啟台新網路銀行及相關權限   台新一般網路銀行目前分為兩種不同會員權限等級，一種為交易會員，另一種則為查詢會員：                     台新網路銀行會員權限比較            請注意，這個網路銀行的功能與 Richart App 提供的不同，目前該功能仍無整合至 Richart App，因此，如果你需要執行更進階的交易操作，會需要使用台新提供的一般網路銀行。   Richart 的用戶可以先至台新網銀註冊一般網路銀行的查詢權限，如果你沒有像是使用一些同步帳戶資訊的應用 (例如 MoneyBook)，這步驟也可以省略，直接請銀行行員幫你開啟：      台新線上申請網路銀行暨行動銀行查詢會員   一般情況下，開啟這項功能後，你的 Richart 帳戶僅有帳戶資料查詢、檢視的權限。因此，若您正確註冊完畢後，可以透過該系統查到你 Richart 帳戶的相關資料。                     台新網路銀行查詢會員權限            台新一般網銀和 Richart 是不同的兩個 App，但帳戶資料仍可以共享，並且，你可以在兩邊的介面中看到。   但請注意：預設網路銀行查詢會員的權限並不涵蓋國外約定轉帳及相關的交易功能。   (當初行員直接跳過這步直接叫我填 Step 3 的表單，導致我填完回去才發現網路銀行根本不能執行交易。在這個步驟卡了很久，必須得再跑一次銀行填寫一次。)   因此，你需要至分行與行員提及要開啟台新網銀交易的權限。接下來，走到你鄰近的台新銀行 (查詢分行)，你可以抽張 其他業務 的號碼牌，並跟行員說：      我想要為台新 Richart 的帳戶開啟一般台新網銀的設置，及開啟外幣轉帳交易權限，並且要設定國外約定轉帳功能 (投資用)    然後，行員就會請你填寫相關的表單提升相關的權限，並完成該步驟。      備註：就我的研究，若你有拿到 Richart 金融卡並且完成開卡，也能試試使用 ATM 操作開啟交易權限，若有成功開啟，通常能跳過這個步驟。     但 Step 3 - 設定國外約定轉帳帳戶，仍然需要臨櫃填寫表單。    Step 3: 填寫國外約定轉帳表單   接下來的步驟便是設置國外約定轉帳帳戶，以將你的資金轉入海外帳戶。   若在一開始行員正確的領悟到你要申請的業務，他便會拿出一張表單要你填寫。若他還是不太清楚你要做什麼，你可以開啟這篇文章並且與他分享以下的表單：                     外幣約定轉帳約定匯出申請            在這個表單上你就會需要填寫一切必要的訊息，上述表單使用了 TD Ameritrade 作為範例，請記得在匯款附言上 (YANG-XIN CAO / No. 123456) 需要更改為你的相應帳號資訊：      Remark (匯款附言): 帳號英文姓名 / No. TD 帳號    如果你使用了其他帳戶，請根據您的匯款銀行提供相應的資訊。   完成及驗證   一旦設置完成後，在 App 上就可以轉帳 (你可以跟行員請教如何操作)：                                                                                          使用台新網路銀行 App 轉帳功能       在台灣平日銀行開放交易時間 (09:00 - 15:30) 完成約定轉帳後，如果正確設定，一般來說在當天美國交易時間 (台灣時間晚上 23:30 後) 左右，通常就能查到該筆款項：                     資金正確轉到 TD Ameritrade 帳戶            匯款費用   在我的轉帳中，我從帳戶轉出了 $ 2, 408 USD，實際到帳金額為 $ 2, 373 USD。其中外幣轉帳費用如下：      15 USD (台灣台新銀行外幣匯款手續費) + 20 USD (中轉行手續費) = 35 USD    以我目前台幣轉美金匯率 (28 TWD = 1 USD)，費用約為新台幣 $ 980 NTD 左右。可以將資金集中後，再一次轉出，可以減少頻繁轉出相關衍生的手續費用。   總結   在這篇內容中，我與你分享了我個人過去申請海外約定帳戶轉帳的經驗，以及幫助你如何為台新 Richart 申請國外約定帳戶的功能，並將資金正確的轉移到海外證券商 (例如：TD Ameritrade、Firstrade、Interative Broker / IB、Charles Schwab 嘉信 … 等等)。   由於我部分內容可能涉及到台新銀行和相關券商的業務變動，更多資訊，請洽您的相應銀行窗口以幫助你釐清相關的問題。   希望上述的內容同樣也能幫助你成功申請該功能，如果你覺得這樣的內容有幫助，可以在底下按個 Like 讓我知道。   看更多系列文章      學會揭開投資騙局 - 如果你想快速賺大錢，千萬不要去 BOS 巴菲特線上學院   在 25 歲至少擁有 100 萬 - 5 個適合年輕人的理財建議   台新 Richart 到底能不能轉到 TD Ameritrade (海外轉帳)？答案是 Yes - 3 個步驟開啟 Richart 海外約定轉帳   我常用的自動化理財工具及策略 - 適合理財新手的操作手冊   ","categories": [],
        "tags": ["finance","FinTech","TD Ameritrade"],
        "url": "https://easoncao.com/how-to-use-taishin-richart-transfer-to-TD-ameritrade/",
        "teaser": "https://easoncao.com/assets/images/posts/2021/03/how-to-use-taishin-richart-transfer-to-TD-ameritrade/cover.png"
      },{
        "title": "一小時內搭建好 Amazon EMR on EKS 運行 Spark on Kuberentes",
        "excerpt":"自 2020 年 12 月，Amazon EMR 推出支持 Amazon EKS 作為一項部署運行 Apache Spark 的方案。因此，在這篇內容中，我會展示如何整合 AWS EMR 及 Amazon EKS 以幫助你運行 Spark 進行你的 Big Data 大數據 Map Reduce 運算。                     一小時內搭建好 Amazon EMR on EKS 運行 Spark on Kuberentes            簡介   Amazon EMR 是什麼？      如果你慣於運行 Apache Spark, Apache Hive, Apache HBase 等平台。Amazon EMR 主要針對這些開源服務提供了整合的託管式集群，以供你可以輕鬆的運行你的 Map Reduce 運算工作。如果你自己有建置過 Spark 或是 Hadoop Cluster 的經驗，會很清楚知道要維護集群的可用性是一項複雜的工作。     Amazon EMR 就是為了解決這項問題而存在，同時也幫助你自動化像是基於大數據運算所需要的底層硬體擴展、Performance Tunning。你只需要透過 Amazon EMR 提供的介面就能夠輕鬆設定、操作和擴展您的大數據環境，可以處理 PB 規模等級以上的分析工作，同時，通常成本不到傳統內部部署解決方案的一半，速度也比標準 Apache Spark 快 3 倍以上。    Amazon EKS 是什麼？      Amazon Elastic Kubernetes Service (Amazon EKS) 屬於託管式 Kubernetes Cluster 的一種，在過去，如果你要自己搭建 Kubernetes 集群，是一項非常複雜的工作。同時，Kubernetes 社群通常 3-6 個月都會有提供相應的更新，這促使你會需要解決頻繁更新 Kubernetes 集群的問題。     Amazon EKS 就是為了減少你維運複雜性而存在，這項服務幫助你可以輕鬆的擁有高可用的 Kubernetes Cluster、自動化且不中斷的更新流程，專注在部署及擴展你的 Kubernetes 應用程式。    在過去，Amazon EMR 會幫助你執行管理底層運算資源，包含幫助你配置 Cluster Manager、管理 Spark Worker 及 Executor 的資源。即使 Spark 原生就有以 Kubernetes 集群作為一項可支持運算方式，其配置及設定過程仍有一定的複雜性。但在 Amazon EMR 這項支持推出後，你無需做過多的設定，只需專注發出 Submit Job 進行 Map Reduce 運算，意味著你可以更容易的使用 Kubernetes 的運算集群幫助你執行 Spark 運算，並執行 Map Reduce 工作。也可以在單一個 Kubernetes cluster 中運行混合不同的應用，進一步為你的團隊或是組織更有效的運用運算資源，並節省成本。   甚至，在 Amazon EKS，其支持使用 AWS Fargate 幫助你以無服務器的狀態運行你的任務，你更無需煩惱如何有效管理底層所需的運算資源、擴展等工作。   架構概覽 (Architecture Overview)                     架構概覽            Amazon EMR on EKS 主要提供了單一的 API 介面，以供你可以使用過去操作 Amazon EMR 的體驗執行 Submit Job (Spark) 的工作。差別僅在於，Amazon EMR 並不會管理任何底層運算集群，其底層會交付由 Amazon EKS 其管理的 Kubernetes Cluster 執行運算，其提供了跨可用區的高可用運算，以避免單點故障的影響。最終，將交付由運行在 Kubernetes Cluster 的 Spark Worker 及 Executor 將結果及輸出，統一儲存於資料儲存 (Amazon S3)。   如果你已經慣於使用 Amazon EKS 的用戶，要理解並使用這樣的解決方案並不陌生。但如果你是第一次了解 Amazon EKS，看完這樣的架構仍無法理解如何操作。因此，以下我將一一講解怎麼使用，幫助你在一小時內就能夠搭建完成並且運行第一個 Map Reduce 運算！   開始動手做   為了幫助你快速搭建，以下我將一一列舉運行步驟：   預先準備工作   以下環境以 Linux 為基礎範例安裝必要套件：      安裝 AWS CLI   curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\" unzip awscliv2.zip sudo ./aws/install   為 AWS CLI 設定相應的操作用戶資訊   aws --version aws configure   註：你可以在你的 IAM User 中附加相關的 IAM Policy (e.g AdministratorAccess) 以具備執行這項測試相關的權限。並在這個階段你需要指定使用相應的 IAM User 對應的 Access Key &amp; Secure Key。      安裝 eksctl   curl --silent --location \"https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz\" | tar xz -C /tmp sudo mv /tmp/eksctl /usr/local/bin      安裝 kubectl (可選，以下使用 Kubernetes 1.19.6 為範例)   curl -o kubectl https://amazon-eks.s3.us-west-2.amazonaws.com/1.19.6/2021-01-05/bin/linux/amd64/kubectl chmod +x ./kubectl mkdir -p $HOME/bin &amp;&amp; cp ./kubectl $HOME/bin/kubectl &amp;&amp; export PATH=$PATH:$HOME/bin   Step 1. 建立 EKS Cluster   為了方便測試，以下資源都在 N.Virginia (us-east-1) 區域建立。在該區域建立一個 EKS Cluster (名稱為 emr-eks-demo) 並啟用三個節點運行：   eksctl create cluster --name emr-eks-demo --nodes 3 --region us-east-1   註：EKS Cluster 建立過程約 15-20 分鐘   Step 2. 為 Amazonn EMR 賦予操作 Kubernetes Cluster 的權限   為了方便測試及區別，我在 Kubernetes Cluster 中建立一個用於計算 EMR 任務的 namespace (Kubernetes namespace)，並命名為 emr-job   kubectl create ns emr-job   建立後，下一步便是為 Amazon EMR 賦予操作該 namespace 相應的權限 (Amazon EMR 將會使用 Service Linked Role AWSServiceRoleForAmazonEMRContainers 操作集群)，因此，這個動作將會使用 eksctl 建立 Amazon EMR 操作 EKS Cluster 所必須的 RBAC 相關權限，如此一來，使用 Amazon EMR 送出運算任務時，才能正確的在 EKS Cluster 中建立相關的資源 (例如：Job, Pod, Secret … 等等)：   eksctl create iamidentitymapping \\     --cluster emr-eks-demo \\     --namespace emr-job \\     --service-name \"emr-containers\"   註：這個步驟會由 eksctl 工具幫助你配置 RBAC 以及 aws-auth ConfigMap。請使用最新版本的 eksctl 工具以確保選項可以被支持，你可以使用以下命令驗證。   $ kubectl get cm/aws-auth -o yaml -n kube-system apiVersion: v1 data:   mapRoles: |       - rolearn: arn:aws:iam::11122233344:role/AWSServiceRoleForAmazonEMRContainers         username: emr-containers   Step 3. 啟用 OIDC Provider 以利後續配置 IAM Role for Service Account (IRSA)   為了讓 Amazon EMR 啟動的容器 (Pod) 能夠有相應的權限存取、寫入日誌 (輸出至 Amazon S3 等) 以儲存任務運行的資訊，Amazon EMR 同樣使用了 Amazon EKS 所提供的 IAM Role for Service Account (IRSA) 功能為容器賦予這項權限。在 Amazon EMR 中會為運行於 Amazon EKS 的 Pod 指定使用特定的 Job Execution Role (IAM Role)。為了啟用這樣的功能，首先可以使用 eksctl 工具幫助你關聯 EKS 必要關聯的 OIDC Provider：   eksctl utils associate-iam-oidc-provider --cluster emr-eks-demo --approve   Step 4. 建立 EMR 可以操作的角色 (IAM Role) 並更新對應的權限   在成功利用 eksctl 關聯 OIDC Provider 後，下一步的動作便是建立 Job Execution Role 以利啟動的 Pod 擁有操作 Amazon S3、CloudWatch 的權限，這些權限為必要並且用於監控任務狀態和存取日誌的權限。      將以下的 IAM Policy 儲存為 job-execution-role-policy.json：   {     \"Version\": \"2012-10-17\",     \"Statement\": [         {             \"Effect\": \"Allow\",             \"Action\": [                 \"s3:PutObject\",                 \"s3:GetObject\",                 \"s3:ListBucket\"             ],             \"Resource\": \"*\"         },         {             \"Effect\": \"Allow\",             \"Action\": [                 \"logs:PutLogEvents\",                 \"logs:CreateLogStream\",                 \"logs:DescribeLogGroups\",                 \"logs:DescribeLogStreams\"             ],             \"Resource\": [                 \"arn:aws:logs:*:*:*\"             ]         }     ] }   使用 AWS CLI 建立 IAM Role Policy，名稱為 (EMR-EKS-JobExecutionRolePolicy)：   aws iam create-policy --policy-name EMR-EKS-JobExecutionRolePolicy --policy-document file://job-execution-role-policy.json   [output]  {     \"Policy\": {         \"PolicyName\": \"EMR-EKS-JobExecutionRolePolicy\",         \"Arn\": \"arn:aws:iam::111122223333:policy/EMR-EKS-JobExecutionRolePolicy\",         \"Path\": \"/\",         \"DefaultVersionId\": \"v1\",         \"AttachmentCount\": 0,         \"PermissionsBoundaryUsageCount\": 0,         \"IsAttachable\": true,         \"CreateDate\": \"2021-05-09T12:39:39+00:00\",         \"UpdateDate\": \"2021-05-09T12:39:39+00:00\"         ...     } }      使用 eksctl 工具建立 IAM Role / Service Account，名稱為 (emr-on-eks-job-execution-role)，請將前述獲得的 Policy ARN (arn:aws:iam::111122223333:policy/EMR-EKS-JobExecutionRolePolicy) 根據你的環境取代以下命令 --attach-policy-arn 中的設置：   eksctl create iamserviceaccount \\     --name emr-on-eks-job-execution-role \\     --namespace emr-job \\     --cluster emr-eks-demo \\     --attach-policy-arn arn:aws:iam::111122223333:policy/EMR-EKS-JobExecutionRolePolicy \\     --approve \\     --override-existing-serviceaccounts   註：請注意 Service Account 名稱建議使用小寫，以符合 Kubernetes 命名規範 (DNS-1123)，否則將會在建立過程遇到下列錯誤。   2021-05-09 12:41:47 [✖]  failed to create service account emr-job/EMR-on-EKS-job-execution-role: ServiceAccount \"EMR-on-EKS-job-execution-role\" is invalid: metadata.name: Invalid value: \"EMR-on-EKS-job-execution-role\": a DNS-1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')   為了能夠讓 Amazon EMR 具備操作 IAM Roles for Service Accounts (IRSA) 和 Kubernetes Cluster 相關的 Service Account 權限，下一步的動作便是設定相關 Job Execution Role 對應的 Trust Relationship，以賦予 Pod 能夠在運行時，有權限獲得臨時性憑證：      獲取 IAM Role 名稱 (arn:aws:iam::11122233344:role/eksctl-emr-eks-demo-addon-iamserviceaccount-Role1-18HQGD62AI3QM)：   $ kubectl describe sa/emr-on-eks-job-execution-role -n emr-job  Name:                emr-on-eks-job-execution-role Namespace:           emr-job Annotations:         eks.amazonaws.com/role-arn: arn:aws:iam::11122233344:role/eksctl-emr-eks-demo-addon-iamserviceaccount-Role1-18HQGD62AI3QM ...      更新 EMR 操作 Job Execution Role 相應的 Trust Policy：   在取得 IAM Role ARN 後，請再套用命令前，將以下更換為你相應的 IAM Role 名稱 (&lt;eksctl-emr-eks-demo-addon-iamserviceaccount-Role1-18HQGD62AI3QM&gt;)：    aws emr-containers update-role-trust-policy \\     --cluster-name emr-eks-demo \\     --namespace emr-job \\     --role-name &lt;eksctl-emr-eks-demo-addon-iamserviceaccount-Role1-18HQGD62AI3QM&gt;   [output]   Successfully updated trust policy of role eksctl-emr-eks-demo-addon-iamserviceaccount-Role1-18HQGD62AI3QM   Step 5. 將 Amazon EKS 註冊至 Amazon EMR 作為可運算對象 (Virtual Cluster)   使用以下命令於 EMR 建立一個 Virtual Cluster (可以將 virtual_cluster_name 更換為你容易識別的名稱)：   aws emr-containers create-virtual-cluster \\     --name virtual_cluster_name \\     --container-provider '{         \"id\": \"emr-eks-demo\",         \"type\": \"EKS\",         \"info\": {         \"eksInfo\": {                 \"namespace\": \"emr-job\"             }         }     }'   [output]  {     \"id\": \"01h5iv9ihkzwoxslejev29bl1\",     \"name\": \"virtual_cluster_name\",     \"arn\": \"arn:aws:emr-containers:us-east-1:11122233344:/virtualclusters/01h5iv9ihkzwoxslejev29bl1\" }   這裡取得的 01h5iv9ihkzwoxslejev29bl1 便是在 EMR 中相應的 Virtual Cluster ID。你同時也可以在 EMR Console 中檢視 Virtual Cluster：                     在 EMR Console 中檢視 Virtual Cluster            運行你的 Map Reduce Job！   你可以使用 aws emr-containers start-job-run 運行一個 Job。使用以下命令套用前，有部分      -virtual-cluster-id &lt;前面獲取的 Virtual Cluster ID，例如：01h5iv9ihkzwoxslejev29bl1&gt; –name  --execution-role-arn &lt;前面建立的 Job Execution Role，例如：arn:aws:iam::11122233344:role/eksctl-emr-eks-demo-addon-iamserviceaccount-Role1-18HQGD62AI3QM&gt;     “entryPoint”: &lt;啟動應用位置 (可以是 Spark 支持的格式，例如 s3:///.py)&gt; \"entryPointArguments\": []     {“cloudWatchMonitoringConfiguration”: {“logGroupName”: “\", \"logStreamNamePrefix\": \"\"}     {“s3MonitoringConfiguration”: {“logUri”: “s3://\" }    (運行 Spark Job 完整配置)   aws emr-containers start-job-run \\     --virtual-cluster-id 123456 \\     --name myjob \\     --execution-role-arn execution-role-arn \\     --release-label emr-6.2.0-latest \\     --job-driver '{\"sparkSubmitJobDriver\": {\"entryPoint\": \"entryPoint_location\", \"entryPointArguments\": [arguments_list], \"sparkSubmitParameters\": \"--class &lt;main_class&gt; --conf spark.executor.instances=2 --conf spark.executor.memory=2G --conf spark.executor.cores=2 --conf spark.driver.cores=1\"}}' \\     --configuration-overrides '{\"applicationConfiguration\": [{\"classification\": \"spark-defaults\", \"properties\": {\"spark.driver.memory\": \"2G\"}}], \"monitoringConfiguration\": {\"cloudWatchMonitoringConfiguration\": {\"logGroupName\": \"log_group_name\", \"logStreamNamePrefix\": \"log_stream_prefix\"}, \"persistentAppUI\":\"ENABLED\",  \"s3MonitoringConfiguration\": {\"logUri\": \"s3://my_s3_log_location\" }}}'      (套用上述設置運行 Spark Job 的一項使用範例)   aws emr-containers start-job-run \\     --virtual-cluster-id 01h5iv9ihkzwoxslejev29bl1 \\     --name pi-job \\     --execution-role-arn arn:aws:iam::11122233344:role/eksctl-emr-eks-demo-addon-iamserviceaccount-Role1-18HQGD62AI3QM \\     --release-label emr-6.2.0-latest \\     --job-driver '{\"sparkSubmitJobDriver\": {\"entryPoint\": \"local:///usr/lib/spark/examples/src/main/python/pi.py\", \"sparkSubmitParameters\": \"--conf spark.executor.instances=1 --conf spark.executor.memory=2G --conf spark.executor.cores=1 --conf spark.driver.cores=1\"}}' \\     --configuration-overrides '{\"applicationConfiguration\": [{\"classification\": \"spark-defaults\", \"properties\": {\"spark.driver.memory\": \"2G\"}}], \"monitoringConfiguration\": {\"cloudWatchMonitoringConfiguration\": {\"logGroupName\": \"emr-on-eks-log\", \"logStreamNamePrefix\": \"pi\"}, \"persistentAppUI\":\"ENABLED\",  \"s3MonitoringConfiguration\": {\"logUri\": \"s3://My-EMR-Log-Bucket\" }}}'   [output]   {     \"id\": \"00000002uah9c3rkt9v\",     \"name\": \"pi-job\",     \"arn\": \"arn:aws:emr-containers:us-east-1:11122233344:/virtualclusters/01h5iv9ihkzwoxslejev29bl1/jobruns/00000002uah9c3rkt9v\",     \"virtualClusterId\": \"01h5iv9ihkzwoxslejev29bl1\" }   如果成功送出，在返回訊息中可以得知建立的 Job ID，在 EMR Console 中可以檢視 Job 運行的狀態。：                     在 EMR Console 中檢視 Job 運行的狀態            同時，在 EKS Cluster 中也可以注意到由 EMR 啟動的相關 Spark Containers (Driver, Executor, Job)   NAMESPACE     NAME                                   READY   STATUS    RESTARTS   AGE emr-job       pod/00000002uah9c3rkt9v-gbqhl          3/3     Running   0          2m2s emr-job       pod/spark-00000002uah9c3rkt9v-driver   0/2     Pending   0          81s  NAMESPACE     NAME                                                            TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)                      AGE emr-job       service/spark-00000002uah9c3rkt9v-929ad579514b9f34-driver-svc   ClusterIP   None          &lt;none&gt;        7078/TCP,7079/TCP,4040/TCP   82s  NAMESPACE   NAME                            COMPLETIONS   DURATION   AGE emr-job     job.batch/00000002uah9c3rkt9v   0/1           2m5s       2m5s   一旦這些 Spark 的相關元件被正確啟動，在 EMR Console 中檢視 Job 狀態時，點擊 Job 旁邊的 “View logs” 會跳出彈掉視窗顯示 Spark UI 檢視相關的 Job 詳細資訊 (請注意瀏覽器是否有阻擋彈跳視窗)：                     Spark 中顯示的 Job 狀態            當 Job 完成運算，你可以在 EMR Console 中得知該任務完成的變化：                     檢視 Completed Job            清除資源 Clean up   若你要終止並移除所有資源，可以依照下列順序執行清除：   # 清除 EKS Cluster eksctl delete cluster --name emr-eks-demo --region us-east-1  # 清除 EMR Virtual Cluser aws emr-containers delete-virtual-cluster --id &lt;Virtual Cluster ID&gt;  # 清除 IAM Policy aws iam delete-policy --policy-arn arn:aws:iam::11122233344:policy/EMR-EKS-JobExecutionRolePolicy   總結   在這篇內容中，我展示了如何使用 Amazon EMR + Amazon EKS 快速部署一個範例的運行 EMR on EKS 的執行架構，運行大數據運算工作，能夠協助你在配置時具體了解其流程，幫助你在一小時內搭建好 Amazon EMR on EKS 運行 Spark on Kuberentes。   在我實際搭建時，由於涉及不同服務，所以對於剛接觸相關服務的人來說可能十分陌生並且會花費大量時間在閱讀文件，希望上述的內容，同樣也能幫助你成功運行這樣的解決方案，如果你覺得這樣的內容有幫助，可以在底下按個 Like / 留言讓我知道，並且分享給有需要搭建環境的人，幫助他們快速上手這項功能。   看更多系列文章      一小時內搭建好 Amazon EMR on EKS 運行 Spark on Kuberentes   在 Amazon EMR on EKS 使用 AWS Fargate 運行你的 Big Data 大數據 Map Reduce 運算  ","categories": [],
        "tags": ["aws","amazon web services","EMR","EKS","Spark","BigData","Kubernetes","Map Reduce"],
        "url": "https://easoncao.com/run-spark-on-kubernetes-with-amazon-emr-on-eks-in-1-hour/",
        "teaser": "https://easoncao.com/assets/images/posts/2021/05/run-spark-on-kubernetes-with-amazon-emr-on-eks-in-1-hour/cover.png"
      },{
        "title": "在 Amazon EMR on EKS 使用 AWS Fargate 運行你的 Big Data 大數據 Map Reduce 運算",
        "excerpt":"在上一篇內容中，我展示了如何整合 AWS EMR 及 Amazon EKS 以幫助你運行 Spark 進行你的 Big Data 大數據 Map Reduce 運算，如果你想具體了解在一般環境下如何快速建立 Amazon EMR on EKS 的環境，可以參考：一小時內搭建好 Amazon EMR on EKS 運行 Spark on Kuberentes。在這一篇內容，我將基於上篇的執行環境，與你分享如何使用 AWS Fargate 運行你的 Map Reduce 運算。                     在 Amazon EMR on EKS 使用 AWS Fargate 採用無伺服器 Serverless 架構運行你的 Big Data 大數據 Map Reduce 運算            簡介   AWS Fargate 是什麼？      AWS Fargate 是一種無伺服器運算引擎，適用於搭配 Amazon Elastic Container Service (ECS) 與 Amazon Elastic Kubernetes Service (EKS) 使用的容器。在過去，你會需要顧慮為你的容器部署之前相應的可用運算環境 (例如：我需要先部署 1 臺機器以供我啟動容器) 並且煩惱底層運算機器的擴展。然而，一旦選擇 Fargate 作為運行技術，你只需要專注容器的業務運行 (比如：我需要運行 10 個容器，簡簡單單的就能啟動，不需要顧慮要先運行多少底層運算機器)，並可以依照所需資源大小 (CPU / Memory) 以執行時間計費。     Fargate 的執行環境是單獨且隔離的，你的應用資源並不會與其他在雲端上的客戶共享並被存取。使用這種運行模式，你也無需煩惱定期需要更新你底層的作業系統核心、軟體、漏洞修補以確保安全性和合規。                      在 Amazon EKS 使用 AWS Fargate 與一般運行負載的區別 (source)            概覽 (Overview)                     運作概覽 (source)            基本上與上一篇 一小時內搭建好 Amazon EMR on EKS 運行 Spark on Kuberentes 並未有太大的出入，最顯著的差異為將工作負載轉移至 AWS Fargate 上運行。   在這篇內容中，我們將會為 Amazon EKS 設置相應的 Kubernetes namespace 並設置 Fargate Profile，以供任何在特定 Kubernetes namespace 中啟動，在 Amazon EMR 無需進行過多複雜的設置。   Fargate Profile   在 Amazon EKS 中提供了 AWS Fargate Profile。這項配置就像是一個設定檔，如果要將運行於 Amazonn EKS 中的 Pod 採用 Fargate 技術運行，則需要定義一個 Fargate Profile，指定哪些 Pod 應在啟動時使用 Fargate。Fargate Profile 可以宣告哪些 Pod 要在 Fargate 上執行。   在這個配置中，會有一個 Selector，用於指定特定的 Kubernetes namespace 或是特定 Kubernetes Labels 採用 Fargate 技術運行 Pod。如果要 Pod 符合 Fargate Profile 中的任一 Selector，則該 Pod 會用 Fargate 技術運行。   開始動手做   預先準備工作      擁有 EKS Cluster   在上一篇內容中，提到了使用 eksctl 命令建立一個 EKS Cluster：   eksctl create cluster --name emr-eks-demo --nodes 3 --region us-east-1   然而，這樣的設置預設會建立 3 個 EC2 instance 作為 Worker Node，如果你想要將所有的負載及工作完全都使用 AWS Fargate 採無伺服器技術運行，你可以改採使用 --fargate 選項建立 EKS Cluster：   (Option) 完全運行基於 AWS Fargate 為技術的 EKS Cluster   $ eksctl create cluster --name emr-eks-demo --region us-east-1 --fargate  2021-05-13 01:40:28 [ℹ]  eksctl version 0.38.0 2021-05-13 01:40:28 [ℹ]  using region us-east-1 2021-05-13 01:40:28 [ℹ]  setting availability zones to [us-east-1c us-east-1a] 2021-05-13 01:40:28 [ℹ]  subnets for us-east-1c - public:192.168.0.0/19 private:192.168.64.0/19 2021-05-13 01:40:28 [ℹ]  subnets for us-east-1a - public:192.168.32.0/19 private:192.168.96.0/19 2021-05-13 01:40:28 [ℹ]  using Kubernetes version 1.18 2021-05-13 01:40:28 [ℹ]  creating EKS cluster \"emr-eks-demo\" in \"us-east-1\" region with Fargate profile 2021-05-13 01:40:28 [ℹ]  if you encounter any issues, check CloudFormation console or try 'eksctl utils describe-stacks --region=us-east-1 --cluster=emr-eks-demo' 2021-05-13 01:40:28 [ℹ]  CloudWatch logging will not be enabled for cluster \"emr-eks-demo\" in \"us-east-1\" 2021-05-13 01:40:28 [ℹ]  you can enable it with 'eksctl utils update-cluster-logging --enable-types={SPECIFY-YOUR-LOG-TYPES-HERE (e.g. all)} --region=us-east-1 --cluster=emr-eks-demo' 2021-05-13 01:40:28 [ℹ]  Kubernetes API endpoint access will use default of {publicAccess=true, privateAccess=false} for cluster \"emr-eks-demo\" in \"us-east-1\" 2021-05-13 01:40:28 [ℹ]  2 sequential tasks: { create cluster control plane \"emr-eks-demo\", 2 sequential sub-tasks: { 2 sequential sub-tasks: { wait for control plane to become ready, create fargate profiles }, create addons } } 2021-05-13 01:40:28 [ℹ]  building cluster stack \"eksctl-emr-eks-demo-cluster\" 2021-05-13 01:40:30 [ℹ]  deploying stack \"eksctl-emr-eks-demo-cluster\" ...   建立完成後，若正確建立完全運行基於 AWS Fargate 為技術的 EKS Cluster，你可以注意到會有 Fargate Node 自動地被註冊至 EKS Cluster 中：   $ kubectl get nodes  NAME                                      STATUS   ROLES    AGE   VERSION fargate-ip-192-168-124-153.ec2.internal   Ready    &lt;none&gt;   34h   v1.18.9-eks-866667 fargate-ip-192-168-80-190.ec2.internal    Ready    &lt;none&gt;   34h   v1.18.9-eks-866667      部分 Amazon EMR 配置與上一篇內容大同小異，你也可以參考該篇內容，以取得更多細節互相參考。    Step 1. 建立一個新的 Fargate Profile   在 Kubernetes Cluster 中建立一個用於計算 EMR 任務的 namespace (Kubernetes namespace)，為了方便辨識都是採用 AWS Fargate 技術運行，我將其命名為 emr-fargate-job   kubectl create ns emr-fargate-job   Option 1. 使用 AWS Console   你可以參考以下步驟以圖形化介面為你的 EKS Cluster 設置 Fargate Profile：      開啟 EKS Console 並選擇你的 EKS Cluster   在你的 EKS Cluster 中，找到 Compute 頁籤底下的 Fargate Profiles，並選擇 Add Fargate Profile                     建立 Fargate Profile               設定你的 Fargate Profile：            Name: emr-fp (可以設置你容易辨識的名稱)       Pod execution role: AmazonEKSFargatePodExecutionRole (請參考下面有關 AmazonEKSFargatePodExecutionRole 的註解)       Subnets: (選擇你的 subnet。請注意目前使用 Fargate 技術運行的 Pod 僅支持 Private subnet，你的 subnet 會需要採用 NAT Gateway，這個如果你使用 eksctl 建立你的集群會，不用煩惱太多，請選擇使用 Private subnet)                             Step 1 - 設置 Fargate Profile               設定 Selector，如此一來運行在這個 namespace 的 Pod 都可以採用 AWS Fargate 技術運行：            Namespace: emr-fargate-job （指定使用後續運行 Job 的 Kubernetes namespace)                             Step 2 - 設置 Selector               檢視你的設置是否有誤，並且按下 Create：                     Step 3 - 檢視設定並建立 Fargate Profile            開始建立後，你可以在前面的 EKS Console 點擊你的 Fargate Profile，一旦狀態變更為 ACTIVE 即是建立成功：                     檢視 Fargate Profile 詳細資料            Option 2. 使用 AWS CLI   若你慣於使用 AWS CLI，你可以參考以下命令以為你的 EKS Cluster 設置 Fargate Profile：   aws eks create-fargate-profile \\     --fargate-profile-name emr-fp \\     --cluster-name emr-eks-demo \\     --pod-execution-role-arn arn:aws:iam::11122233344:role/AmazonEKSFargatePodExecutionRole \\     --selectors namespace=emr-fargate-job   [output]   {     \"fargateProfile\": {     \"fargateProfileName\": \"emr-fp\",     \"fargateProfileArn\": \"arn:aws:eks:us-east-1:11122233344:fargateprofile/emr-eks-demo/emr-fp/XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\",     \"clusterName\": \"emr-eks-demo\",     \"createdAt\": \"2021-05-14T12:49:42.323000+00:00\",     \"podExecutionRoleArn\": \"arn:aws:iam::11122233344:role/AmazonEKSFargatePodExecutionRole\",     \"subnets\": [         \"subnet-084d1971bb3f2f605\",         \"subnet-0f9ed9f597f259975\"     ],     \"selectors\": [             {                 \"namespace\": \"emr-fargate-job\"             }         ],         \"status\": \"CREATING\",         \"tags\": {}     } }   註：一般來說 AmazonEKSFargatePodExecutionRole 在你過去有建立過 EKS on Fargate 的操作會存在，如果你的帳戶並沒有，可以參考這篇文件建立。   Step 2. 為 Amazonn EMR 賦予操作 Kubernetes Cluster 的權限   建立後，下一步便是為 Amazon EMR 賦予操作該 namespace 相應的權限 (Amazon EMR 將會使用 Service Linked Role AWSServiceRoleForAmazonEMRContainers 操作集群)，因此，這個動作將會使用 eksctl 建立 Amazon EMR 操作 EKS Cluster 所必須的 RBAC 相關權限，如此一來，使用 Amazon EMR 送出運算任務時，才能正確的在 EKS Cluster 中建立相關的資源 (例如：Job, Pod, Secret … 等等)：   eksctl create iamidentitymapping \\     --cluster emr-eks-demo \\     --namespace emr-fargate-job \\     --service-name \"emr-containers\"   在完成設置後，需要更新 EMR 操作 Job Execution Role 相應的 Trust Policy (配置 Job Execution Role 的相關步驟和啟用 OIDC Provider 可以參考前一篇 Step 3 &amp; Step 4. 建立 EMR 可以操作的角色 (IAM Role) 並更新對應的權限)：       eksctl create iamserviceaccount \\         --name emr-on-eks-job-execution-role \\         --namespace emr-fargate-job \\         --cluster emr-eks-demo \\         --attach-policy-arn arn:aws:iam::11122233344:policy/EMR-EKS-JobExecutionRolePolicy \\         --approve \\         --override-existing-serviceaccounts   獲取 IAM Role 名稱 (arn:aws:iam::11122233344:role/eksctl-emr-eks-demo-addon-iamserviceaccount-Role1-1681FO4LQG4QC)。請注意是 emr-fargate-job namespace：   kubectl describe sa/emr-on-eks-job-execution-role -n emr-fargate-job  Name:                emr-on-eks-job-execution-role Namespace:           emr-fargate-job Labels:              &lt;none&gt; Annotations:         eks.amazonaws.com/role-arn: arn:aws:iam::11122233344:role/eksctl-emr-eks-demo-addon-iamserviceaccount-Role1-1681FO4LQG4QC Image pull secrets:  &lt;none&gt; Mountable secrets:   emr-on-eks-job-execution-role-token-jbjxp Tokens:              emr-on-eks-job-execution-role-token-jbjxp Events:              &lt;none&gt;   在取得 IAM Role ARN 後，請再套用命令前，將以下更換為你相應的 IAM Role 名稱 (&lt;eksctl-emr-eks-demo-addon-iamserviceaccount-Role1-1681FO4LQG4QC&gt;)：    aws emr-containers update-role-trust-policy \\     --cluster-name emr-eks-demo \\     --namespace emr-fargate-job \\     --role-name &lt;eksctl-emr-eks-demo-addon-iamserviceaccount-Role1-1681FO4LQG4QC&gt;   Step 3. 將 Amazon EKS 註冊至 Amazon EMR 作為可運算對象 (Virtual Cluster)   使用以下命令於 EMR 建立一個 Virtual Cluster (可以將 my_emr_virtual_cluster 更換為你容易識別的名稱)：   aws emr-containers create-virtual-cluster \\     --name emr_fargate_virtual_cluster \\     --container-provider '{         \"id\": \"emr-eks-demo\",         \"type\": \"EKS\",         \"info\": {         \"eksInfo\": {                 \"namespace\": \"emr-fargate-job\"             }         }     }'   [output]   {     \"id\": \"wuenyscuofnz53vy5m39g2n10\",     \"name\": \"emr_fargate_virtual_cluster\",     \"arn\": \"arn:aws:emr-containers:us-east-1:11122233344:/virtualclusters/wuenyscuofnz53vy5m39g2n10\" }   Step 4. 運行 Spark Job！   (套用上述設置運行 Spark Job 的一項使用範例)   aws emr-containers start-job-run \\     --virtual-cluster-id wuenyscuofnz53vy5m39g2n10 \\     --name pi-job \\     --execution-role-arn arn:aws:iam::11122233344:role/eksctl-emr-eks-demo-addon-iamserviceaccount-Role1-1681FO4LQG4QC \\     --release-label emr-6.2.0-latest \\     --job-driver '{\"sparkSubmitJobDriver\": {\"entryPoint\": \"local:///usr/lib/spark/examples/src/main/python/pi.py\", \"sparkSubmitParameters\": \"--conf spark.executor.instances=1 --conf spark.executor.memory=1G --conf spark.executor.cores=1 --conf spark.driver.cores=1\"}}' \\     --configuration-overrides '{\"applicationConfiguration\": [{\"classification\": \"spark-defaults\", \"properties\": {\"spark.driver.memory\": \"2G\"}}], \"monitoringConfiguration\": {\"cloudWatchMonitoringConfiguration\": {\"logGroupName\": \"emr-on-eks-log\", \"logStreamNamePrefix\": \"pi\"}, \"persistentAppUI\":\"ENABLED\",  \"s3MonitoringConfiguration\": {\"logUri\": \"s3://My-EMR-Log-Bucket\" }}}'   [output]   {     \"id\": \"00000002ubarp3tg0ne\",     \"name\": \"pi-job\",     \"arn\": \"arn:aws:emr-containers:us-east-1:11122233344:/virtualclusters/wuenyscuofnz53vy5m39g2n10/jobruns/00000002ubarp3tg0ne\",     \"virtualClusterId\": \"wuenyscuofnz53vy5m39g2n10\" }   送出任務後，若一切正確配置，你可以在 emr-fargate-job 中找到你的 Pod，並且，稍待幾分鐘，Fargate 將會幫助你調度並部署新的 Fargate Node 供其運算：   $ kubectl get nodes NAME                                      STATUS     ROLES    AGE   VERSION fargate-ip-192-168-118-40.ec2.internal    NotReady   &lt;none&gt;   6s    v1.18.9-eks-866667 ...   $ kubectl get pods -n emr-fargate-job NAME                               READY   STATUS    RESTARTS   AGE 00000002ubatqrom028-87b7k          3/3     Running   0          3m32s spark-00000002ubatqrom028-driver   0/2     Pending   0          44s  Name:               00000002ubatqrom028-87b7k Namespace:          emr-fargate-job Priority:           2000001000 PriorityClassName:  system-node-critical Node:               fargate-ip-192-168-118-40.ec2.internal/192.168.118.40   當 Job 完成運算，你可以在 EMR Console 中得知該任務完成的變化。   總結   在這篇內容中，我展示了如何使用 Amazon EMR + Amazon EKS 並使用 AWS Fargate 與你分享快速部署一個範例的運行無伺服器的執行架構，運行大數據運算工作，能夠協助你在配置時具體了解其流程。   由於很多人對於 AWS Fargate 可能十分陌生，希望上述的內容，能夠幫助你了解並幫助你成功運行這樣的解決方案。如果你覺得這樣的內容有幫助，可以在底下按個 Like / 留言讓我知道，並且分享給有需要搭建環境的人，幫助他們快速了解 AWS Fargate 的神奇威力！   看更多系列文章      一小時內搭建好 Amazon EMR on EKS 運行 Spark on Kuberentes   在 Amazon EMR on EKS 使用 AWS Fargate 運行你的 Big Data 大數據 Map Reduce 運算  ","categories": [],
        "tags": ["aws","amazon web services","EMR","EKS","Spark","BigData","AWS Fargate","Serverless","Kubernetes","Map Reduce"],
        "url": "https://easoncao.com/run-spark-on-kubernetes-with-amazon-emr-on-eks-using-aws-fargate/",
        "teaser": "https://easoncao.com/assets/images/posts/2021/05/run-spark-on-kubernetes-with-amazon-emr-on-eks-using-aws-fargate/cover.png"
      },{
        "title": "寫給第一次遠距工作的你 - 9 個技巧幫助你調適自己並保持高效能 (WFH / Work From Home)",
        "excerpt":"COVID-19 自爆發以來，衝擊了許多人原本的工作模式，也可能隨著在家工作的型態帶來些不習慣，殺得許多人措手不及。畢竟，可能誰也沒有想過有一天所有人都必須足不出戶，並且很認真的關在家裡超過 3 天，甚至數週以上。   由於近期台灣疫情並不太樂觀，再一次掀起遠距工作的需求，也讓很多人感到手足無措，促使我撰文分享一些有關這幾個月來長期在家工作的一些心得和訣竅。   自 2020 年初，Amazon 就不斷更改對於員工在家工作選項指南，強烈建議大家都待在家工作，並且這個時間不斷的延長 (從原本 Oct 2020 [1] 更改至 Jan 2021 [2] 後來再翻轉到 June 2021 [3])。   於是，在經歷 Work From Home (WFH) 一年後，我希望能透過這篇文章總結這幾個月來的心得，並與你分享幾個技巧，希望能幫助你度過這段時間，並同時保持工作上的高效能。                     9 個技巧幫助你調適自己並保持高效能               在這篇文章中你將知道      調適自己以適應長時間待在家中工作的心態、方法   9 項技巧幫助你遠距工作時也能保持高產出   讓你也能在家工作一年以上都保持高效能    概覽                     Working From Home            在 Amazon 很多團隊，Work from Home (WFH) 是很平常的事情，還沒爆發疫情前，我們就有相應的 WFH 政策。只要你的直屬主管同意，你就可以跟你的老闆提出，一週可能有一至多天會在家工作。但這一切前提是，你的 Performance 不能受到任何影響。(當時我 Seattle 的同事們大部分週五都在家工作，只要發個訊息到 team email 告知即可)   當時，COVID-19 還沒有擴散到這麼大規模。但 2020 年 1 月疫情剛開始有爆發跡象時，Amazon 就發佈了相關的 Work from Home 政策要求世界各地的員工長時間在家工作，並且有醫療專業的專家們與我們分享了一些長時間 Working from Home 的健康指南，隨後幾個月，也強烈建議員工都待在家。因此，以下有部分內容也是參考這些來自專業醫療團隊的建議，你可以參考這些內容幫助你改善你現有所遭遇的問題。   在家工作調適自己並保持高效的 9 個技巧   對於最近剛開始在家工作的你，以下綜合我的個人經驗，與你分享可以參考的幾個指南：   1. 調整心態並轉念思考，讓你的大腦保持積極且樂觀   也許你才剛開始執行你在家工作的計畫，但當你持續一步都不出門 2-3 天甚至是一週，以我的自身經驗，當你關在家久了，最明顯的通常會出現以下幾種情況：      生理時鐘會變很差，有時候會分不清是早上晚上   對於今天是星期幾感到混亂，常常無法區分是週休還是工作日   心情十分消極，且感覺常常無法放鬆，有時候難以區分是在工作還是在休息   當時我也常常跟同事們互相吐吐苦水，有時候也會跟其他國家的同事聊聊近況，不外乎就是疫情狀況如何、最近怎麼樣等等 … 但都可以注意到你周遭的同事好像心情、情緒都不太對勁，當時大家對於長期處於在家工作，不免感到疲倦，且不少人都覺得很悶。   如果你跟我一樣在外面一人獨自租屋，更必須要與孤獨學習共處，整天就自己一個人在家感覺沒跟人類社會互動。因為長期處在一個空間中，這種工作型態模式久了，其實多少會感到壓迫，使心態消極。   要調適這種心態，我會建議的第一點，就是要發自內心先感受到遠距上班的好處，你可以想想最近因為遠距工作享受到哪些不錯的優勢，可以寫下來或是與你周遭的人分享，例如：      覺得能在家工作很幸福，與家人相處的時間更多   不用通勤上班，避開擁擠的上班人潮，更可以睡到自然醒   在家想怎麼穿都行，不用穿痛腳的高跟鞋、緊身的正裝，穿著內褲開會也沒人管你   在家有空料理、省了很多伙食費   多了很多時間可以整理房間、打掃   工作累了隨時轉身走幾步就有床可以躺，平常哪裡還有這麼爽的工作環境   並且懷抱感恩的心情看待你現在擁有的這些好處，當你開始這麼做，每天工作的心情自然會好一點。   另外，要使大腦感到興奮或是活躍，你可以試試一些方式 (有些看似很荒謬但其實還蠻有效)：      聽振奮人心的音樂 (Spotify 很多類似的音樂，你可以用像是 Happy, Motivation 等等關鍵字 … 都會推薦不錯且好聽的旋律激發你的大腦)   在家對著牆壁大叫並且隨意舞動你的身體   沒事咬著筷子保持微笑 (順便訓練臉部肌肉)               (YouTube 上也有很多無版權的快節奏音樂，通常是無人聲，這也是我其中常聽的一個播放來源，幫助你激發一天工作的動力)   2. 保持與平常一樣的工作規律以及休息時間   雖然你的生活可能多少都因開始實施遠距工作完全改變，但仍然還是需要保持你的日常行程跟平常工作時無異，以助於你的生理時鐘不會受到太大的影響。      因為你不需要通勤，你可能無需像平常一樣這麼早起，但這並不意味著可以熬夜、晚睡。    不正確睡眠完完全全可以打亂你的生理時鐘，甚至影響你的起床時間，嚴重一點更會影響你日常的工作效率。所以，請試著保持與平常一樣的睡眠規律，你可以設定鬧鈴以提醒自己該上床睡覺了。你可以保持與平常的時間規律、執行相應的行為以喚醒你的大腦，原本通勤的時間你可以取代外出散步 (當疫情緩和時)，亦或是透過其他類型的方式 (訓練、整理家裡、聽 Podcast 做早餐) 等。   當你在家工作時，因為可以無時無刻在餐桌、床上透過手機檢查你的 Email，這容易導致因為這些好處，使得工作完成時間延後、或因為無法切割工作環境的問題，致使你工作時間更久且更長。   因此，很重要的一點，你可以設定自己每天的開始及結束的工作時間，並且嚴格遵守。例如：如果你很難在下午 5 點關閉電腦，則可以選擇計劃在此時散步或進行一些運動、料理等等，以在工作日與晚上之間建立自然的休息時間。   簡而言之，在家工作時，盡可能讓你自己感覺跟平常上下班無異。   3. 喚起工作意識，避免整天穿著睡衣工作並打造可以工作的環境   在家工作因為無需在意穿著，但為了喚起工作意識，請避免整天穿著睡衣工作。穿著睡衣會讓你的大腦誤以為進入現在是要準備睡覺的模式，而無法專注於你眼前的工作任務上，很可能還會隨時感到疲倦。   在每天起床後仍更換正常的服裝，或是至少穿個 T-Shirt、可以出門的衣服以讓你的大腦進入工作的啟動程序，而不是穿著睡衣。   與此同時，請花點時間把家裡的工作區域跟休息區域的區隔開，例如：      盡可能避免在床上工作，你可以體驗個幾天在床上工作的感覺，但請切記不要養成習慣，這會使得你的大腦無法區分你是要準備睡覺還是在工作   規劃一個房間、或是客廳區域是你的工作區域，一旦進入這個地方，你就只專心投入你的工作項目   如果住在小小幾坪的小套房，可用的區域有限，請至少規劃一個桌子或是區域作為你的工作結界，只要一跨過踏入這個地方，你就只專心處理你的工作任務。當想睡覺、感到疲倦就離開這裡休息。即使休息及工作地點距離十分相近，卻仍可以讓你的大腦有足夠的意識知道自己現在的狀態   與家人溝通自己的工作時間及區域，設定好他們可以觸及的邊界。不論是實體 (環境，哪邊可以在工作時間活動、哪邊不行)、或是精神狀態的 (幾點幾分需要保持安靜、禁止打擾)   否則，如果躺在床上工作、餐桌上跟著家人邊吃東西邊打著電腦，很容易被環境干擾，使你的大腦無法區分現在到底是在工作還是在休息，導致任務做得斷斷續續、間接超時加班。以上這些方法將有助於集中精力並幫助你在每天進入工作思路，喚起你的工作意識。   4. 設定工作目標，每天專注處理 1-3 件重要的任務   由於在家工作少了周遭同事、主管的眼睛盯著你看；也撇除了辦公室環境所帶來積極衝刺的磁場，家中的環境又是特別舒適且讓人放鬆的。在這種狀態下，人往往會有處於非警戒狀態下的錯覺，因為沒有老闆看著、關心你現在的進度，使得你的工作模式處於輕鬆且無人看管的狀態；在家工作，你可能還會時不時分心，想著等會再來弄。然而，你的績效要求跟工作目標通常並不會隨著你所在的環境及地點改變。長時間分心、不專注所帶來的影響是往往你會工作比平常更久、更長的時間。   為了解決這種狀況，這裡引用了我在之前提及最有生產力的一年所提到的技巧：      3 項原則讓你變得更有生產力 - 最有生產力的一年 The Productivity Project                                                                                                                       最有生產力的一年: The Productivity Project (Kindle)                                                    Kindle 數位版售價 $9.50 優惠連結                                                   購買                                                                                                                                                    最有生產力的一年 (博客來)                                                    博客來 79 折優惠連結                                                   購買                                        你可以在每週、每天列下你的待辦事項，想像你的 deadline (期限) 就是今天，以此設定你的工作目標，要求自己今天就專心處理這 1-3 件任務。   這項方式其實無論是否在家工作都可以應用，這也是我常用的方式，我平常可能一整天下來只做一件事，但一定是重要的，才不會在家工作整天有一種空虛感。   5. 注意飲食及營養均衡、增強免疫系統並且找到緩解焦慮的方式   這點不論是否在家工作都至關重要，好的食物就像是為你的身體提供好的燃料一樣，好的飲食習慣及營養，更能夠有助於保持血糖平穩，讓你保持清晰的大腦及思緒，並且擁有健康的身體：      多喝水取代咖啡因及含糖飲料   多吃原型食物，少吃加工產品 (醃製、熱狗、火腿、零食、餅乾 … 等)   擁有充足的營養素：Vitamin A, C, D, E, B2, B6, B12、葉酸、鐵、和鋅等   攝取優質蛋白和蔬菜：各式顏色的蔬菜 (broccoli 花椰菜, spinach 菠菜, carrots 蘿菠, sweet potato 地瓜, red pepper 辣椒)、肉類、Salmon (鮭魚)、雞蛋等便宜又容易取得的食物 … 都能充分補足各方面的營養   一些比較不建議常吃的食物：      高碳水且富高油鹽類型的食物，例如：泡麵 (鈉含量通常都很高、麵體都經過油炸)   含糖量過高的汽水、飲料   炸雞、油炸類型的速食   蛋糕   冰淇淋、加工冰棒 (尤其夏天到了，請注意吃這類加工食品幾乎都在吃油。建議可以改用冷凍香蕉、水果取代)   除了平常叫外送交替換換口味外，我常趁假日空閒的時間，一次備料製作約 3-5 天的食物量進行備餐。因為食材容易掌控且都以當季為主，通常排列組合一下就是一道新的料理，除了能滿足基礎營養，也不會佔用太多時間：                                                                                                                                                                      我常做的幾個料理類型       除了生理上的改善，疫情的壞消息可能會讓你每天都充斥著焦慮且不安影響你的心理，你可以：      取消追蹤、靜音那些會分享負面消息的朋友、群組   關閉你的社群軟體通知，只在特定時間去查看他們   練習正念 / 冥想: 正念是將注意力轉移到當前時刻發生的內部或外部體驗的心理過程，或者簡單地說，就是著眼於現在 (而不是已經發生或將要發生的事件的行為)。練習正念的一種好方法，是利用呼吸技巧達成，這項方法簡單且有效：            A. 找個舒服的姿勢，閉上眼睛，放鬆身體、屏住呼吸，吸氣和呼氣時，感受你身體呼吸的律動和感覺。       B. 注意你的想法，如果你不小心分心 (發現思考在想其他事情、思想流到其她地方)，請把自己拉回來，專注在想想自己的呼吸。你只要專注一件事，就是只專心感受你的呼吸！       C. 不要太在意你想的其他事情，也不要帶有任何批判或評斷任何你不小心想到的事情。只要隨時發現自己意識好像飄走，就再拉回呼吸上，持續到你覺得夠了，然後，張開眼睛。       (每天可以執行這個動作 5 分鐘，如果習慣了，可以持續更久)           6. 善用科技和疫情商機下所帶來的便利   疫情衝擊眾多人的生活，卻也帶來另一股商機。外送平台的興起，同時也創造許多就業機會。如果你能善用這些科技，能夠幫助你更有效的執行你的工作。   以我常在用的 UberEats 來說，除了平常用來點外賣，甚至不用出半步門就可以完成很多生鮮採購，更是省下了出門購物猶豫、搬來搬去的時間。你同時也可以使用以下專屬優惠碼幫助你節省更多相關的花銷：      (輸入折扣碼：eats-sb7184vzue) 點擊這裡申請 UberEats 並輸入折扣碼 eats-sb7184vzue 就能獲得 NT$ 200 優惠   這些等待時間我更可以拿來打掃家裡、運動或是做其他事情，善用時間專注在其他任務上，讓 UberEats 的外送夥伴和賣家完成所有事情。   除了使用外送平台，若要補齊日常所需的用品、常備食品及食物，以下也是我常透過的平台購買進行大量採購，方便在家料理：      家樂福線上購物   Pchome 24h 線上購物   一次大量採購不僅通常能夠獲得免運優惠、優惠的價格甚至是折扣，正確結合使用信用卡或是電子支付更可以幫助你省下不少錢。有的平台我也推薦你可以開啟 ShopBack 進行購物，除了信用卡、電子支付本身的回饋，透過 ShopBack 訪問，可以再獲取 1% 甚至隨活動 20% 不等的現金回饋。   如果你還不知道 ShopBack 是什麼，你可以使用我的以下專屬連結註冊，開始在日常的購物中賺取回饋，完成後就可以獲得 100 塊台幣：      點擊這裡申請 ShopBack 帳戶，完成單筆消費 $500，就能獲得 NT$ 100 回饋   7. 運動   規律運動已經證實不僅對於維持身體機能、肌肉、骨骼、心血管等有很好的效果，更是對大腦的運作有非常大的幫助。當進行遠距工作或自我隔離時，很容易忽視平常的運動。在這種情況下，你更需要為自己設定一個固定時間進行，以保持鍛煉水平，並規律地維持。以下有幾個在家也能輕易完成的運動：      深蹲 (Squat)   棒式 (Plank)   伏地挺身 (Push ups)   高強度間歇訓練 (Tabata)   以下我節錄一些來自醫療專家們提供的健康指南，其中提及了幾項運動菜單，你可以根據自己的需求排列組合，讓你的全身都受到充分的訓練：   Upper body      Push ups – max repetitions × 3   Superman – 8 repetitions × 3   Shoulder taps – 8 repetitions × 3   Shoulder press up – 8 repetitions × 3   Door frame single arm row – 12 repetitions × 3   Core      Leg raises – 8 repetitions × 3   Flutter kicks – 8 repetitions × 3   Reverse crunches – 8 repetitions × 3   Bicycle crunches – 8 repetitions × 3   Plank – 30 seconds × 3   Lower body      Squats – max repetitions ×3   Glute bridges – 8 repetitions × 3   Lunge step ups – 8 repetitions × 3   Side leg raises – 8 repetitions × 3   如果你有健身、重訓的習慣，也可以買一條訓練用的彈力帶 (或也有人稱為阻力帶)，幫助你在沒辦法去健身房時，仍可以進行許多不同組合的阻力訓練。如果你覺得要開始培養運動的習慣太難，你可以參考我的一些實務的方法來幫助你養成一個好的習慣：      原子習慣：細微改變帶來巨大成就的實證法則 - 我的心得及實作                                                                                                                       原子習慣: 細微改變帶來巨大成就的實證法則 (Kindle)                                                    數位版優惠連結 - $7.84                                                   購買                                                                                                                                                    原子習慣: 細微改變帶來巨大成就的實證法則 (博客來)                                                    博客來 79折優惠連結                                                   購買                                        8. 重拾你平時的娛樂或是開發一項在家也能做的興趣   長時間在家工作，你無需捨棄娛樂。你必須要適度的安排一些放鬆、休閒的活動以避免自己感到孤獨或是幽閉恐懼。有許多適合在家裡進行的活動你可以參考，整體將對心理健康產生積極影響，並幫助你更容易應對長時間在家的狀況：      少滑手機、閱讀一本書   開始追劇、電視影集   線上學習課程、開發一項新技能   嘗試新食譜並融入你的料理中   聽 Podcast、看 Ted Talk 或是電影   練習樂器   創作 (文字、圖畫、音樂 …. 等等)   製作手工藝 (編織、縫紉、綁花 … 等等)   還有許多方法並沒有辦法一一列舉在這，總之，找出你感興趣的內容及方式，並利用空閒的時間幫助你增強這項興趣。   9. 保持與他人的連結   人類是群體生活的動物，我們天生就熱衷於需要與他人互動，以感受到自己存在於社會之中。無關你是否在家工作、彼此是否存在於相同的時間地點，即使處於遠距，維持你的人際社交仍至關重要。   由於疫情關係，你可能會因為實體面對面接觸的機會下降，感受到與你朋友、家人、同事等人互動之間，產生一種模糊的疏遠及距離感，以下有幾個可以解決這項問題的方法：      使用視訊、電話的方式與你的朋友、家人互動，而非使用 Email   可以與你的同事、團隊安排一個 5 分鐘 Video coffee break 彼此視訊聊天   設置避免基於工作話題聊天的群組 (可以是 Line, WhatsApp, Slack … 等等)   與往常一樣，記得在電話、視訊過程跟你的同事打招呼、再見   透過影音視訊跟你的朋友聊天而不是單純只使用文字傳訊息   總結   在這篇內容中，我與你分享了自己在家工作一年下來，列舉幾項幫助你保持更高效的作法。   希望上述的內容，能夠幫助你在漫漫的在家工作時期度過，並且請讓我們一同努力，讓疫情盡快緩解。      請記得，良好的自律將為你贏得更長遠的自由。    如果你覺得這樣的內容有幫助，可以在底下按個 Like / 留言讓我知道，並且分享給跟你有一樣困擾的人，一同在這個遠距工作時代找到適合自己的方法適應。   Reference      [1] Amazon gives employees option to work from home until “at least” early October under new guidelines   [2] Amazon extends work from home policy to January 2021, opens offices with new safety measures   [3] Amazon will let some employees work from home until mid-2021  ","categories": [],
        "tags": ["remote work","Work from Home","WFH","productivity","work","personal growth","自我成長"],
        "url": "https://easoncao.com/remote-work-tips-for-beginner/",
        "teaser": "https://easoncao.com/assets/images/posts/2021/05/remote-work-tips-for-beginner/cover.png"
      },{
        "title": "在 25 歲至少擁有 100 萬 - 5 個適合年輕人的理財建議",
        "excerpt":"如果你去書店走一遭、YouTube 逛一圈，不乏看到市面上很多各式各樣的「理財」相關書籍、「理財」型 YouTuber、「理財」大師，其實講了很多，很多原則性的東西其實都大同小異，而且也許你過去都聽過，其實要累積財富大家都懂，就是儲蓄 + 開源節流。   但也許是為了吸引大家的眼球，有時候這些內容講的，總讓人感覺好像不「理財」、不遵循「投資」法則就是笨蛋，製造了一個不會理財就是注定成為愚蠢窮人的一種觀感。因為被台灣的市場弄得有些扭曲，讓我一直對「理財」、「投資」這兩個字的定義有一點反感，而且市面上很多各式各樣的流派，讓大家一窩蜂地湧進股市、瘋狂買 ETF、無本當沖、想著賺大錢。   大家都在想著錢放在銀行就是傻瓜、追求高報酬率的操作方法，卻好像鮮少人真正告訴你「規劃」及「風險控管」的重要。(大部分情況下存錢比起投資更重要)   確實有一些不錯的「理財」學習資源，但很多東西缺乏科學的邏輯及實證，認真往下探討，有時候不免參雜炒作市場的動機。比起「理財」兩個字，我更喜歡用「財務管理」來探討對於正確管錢的重要性，小至個人財務規劃，大至企業資本及現金流控管的科學。   我一直相信，在追求人生目標的同時，金錢一直是非常重要的工具之一，是維持這個資本主義社會運作的必要基礎。我一直認為財務管理、財商一直是一門很有趣的學習主題，也通常是學校不會教你的知識。因此，我將在這篇內容中，與你分享我個人認為十分有用的幾個財務規劃建議，也同時是為自己目前所認知的內容做個總結。                     在 25 歲至少擁有 100 萬 - 5 個適合年輕人的理財建議               在這篇文章中你將知道      良好個人財務管理原則   5 項適合年輕人的理財建議   我在 25 歲資產累積到 100 萬的幾項總結    30 秒讓你了解如何變有錢   2021 年，我的人生來到 25 歲。我想告訴你，如果你跟我一樣沒有中樂透彩卷的運氣，那麼累積財富往往靠的不是一夜致富的機會，而是正確的預算分配、擁有正確的財務觀念和努力工作，並且不斷學習優化收入。以下是截至目前為止 (2020 - 2021 年) 在財務管理 App 上面部分所累積擁有的淨資產：                                                    25 歲部分擁有淨資產       其實我能夠累積到這些資產背後的運作邏輯和核心非常簡單，你 30 秒就能了解：                     累積財富的運作邏輯            在這個邏輯背後的幾個重要控制變因如下：      提高收入   隨著收入增加，按比例的提高儲蓄金額   收入增加，仍需要控制支出並有意義的節制，檢視不必要的花費   我寫這篇內容的主要目的，是希望能夠與你分享我一路以來所學習到的心得，如果你是正在開始學習規劃財務目標，我希望能夠從中讓你獲得一些啟發，並且認知到財務管理並不是一件非常困難的事情。   因此，以下我將一一列舉幾個十分有用的財務管理建議：   5 個適合年輕人的財務管理建議   為什麼會這麼強調「財務管理」而不是「理財」來騙點閱率？這是因為，就我的觀點，如果你能夠以管理的角度去學習、思考如何優化你的現金流，你將會有不同角度對待你所擁有的金錢、資源、資產及信用，並且審慎的規劃、管理及執行。   當討論到「財務管理」這個領域，企業家們討論的財務管理範疇通常會是圍繞以下主題：      資本預算規劃   營運資金管理   但相同的原則，其實財務管理這件事情，如果你把自己比喻一個會運作的機器 (企業)，也能夠套用到個人身上：      個人規劃預算的能力   個人使用現有資金 (包含現金、借貸、信用) 操作現金流的能力   很多人對於理財的觀念，可能是總一股腦的聽著哪個股市老師、股神、理財專員跟你說哪個標的好、怎麼操作最賺，但就我的觀察，這些老師們他們擁有了已經累積了多年的資金、操作的起點跟你也不一樣 (他手上損失 100 萬可能只佔他總資產的 1%，但這可能是你存很久、目前所擁有的全部積蓄)；理財專員重視的，可能是他的績效而不是你的報酬，畢竟也不是他的資金。我個人是覺得，如果不思考所吸收的內容而盲目的聽從他人、坊間、新聞給的財務運作建議，不著手研究並想著事情可以如何優化，是最懶惰的。   在任何進行投資決策前，你必須先把基本功具備了、打穩你的資本，有原則的控制風險，才能更有效率的操作資金，審慎的執行你的投資計劃。   我這裡總結了五大建議，也許不見得適用於每個人，但仍是我截至目前為止深深感受到非常重要的幾項原則。可能我的理論及實證，將會隨著過一段時間進行修正而調整這篇內容，但我想這就是學習的有趣之處，人類也正是因為如此，才能持續進步。   1. 認真工作、認真學習   如果你跟我一樣沒有個富爸爸、還是出生於中產階級的家庭、大學北漂畢業得想辦法養活自己的小孩。通常，剛畢業的時候你不可能擁有非常多的資源，讓你足以揮霍下半餘生。畢業後，也許你能夠擁有一份足以養活你生活的一份工作，但生活也許非常痛苦。在這個階段，別一股腦的想著要投資翻身，而是淬煉自己對於「延遲享樂」的能力。並請將 認真工作 及 認真學習 放置在你首要積極努力的目標：   Tips - 充實自己的專業能力   我相信你在畢業後，學校一定給予你了一定程度的基礎專業能力，讓你足以投入職場中貢獻你的能力 (如果沒有，那你真的要好好檢討自己唸大學、研究所是為了什麼，並想辦法積極進修補足落差)。   但通常一畢業的你，都是最菜的，這個時候不是抱怨著自己怎麼領著低薪的工作、覺得老闆不重用自己、工作沒有未來於是上班的時候忙著滑股市刷當沖，這個時候其實你可以：      思考公司、團隊所缺乏的技能、痛點，並且以此為目標充實你的專業能力進行貢獻   考取認證，成為頂尖的專業人才   站在老闆的角度解決公司、團隊所遭遇的問題，學習怎麼跟你老闆爭取升遷的機會   主動向老闆爭取任務、勇敢地問老闆、同事如何做得更好，並且努力完成你的工作   很多人總抱怨自己待錯公司、薪水太少，但你是否曾經想過：      公司憑什麼給你更高的薪水？   如果我是老闆/主管，我會給這個員工怎麼樣的評價？我信賴他的工作能力嗎？他的貢獻足以讓我會願意調整他的薪水嗎？   如果我是團隊的同事，我對自己給怎麼樣的評價？他會在主管前質疑我的能力，還是對我給予肯定？   在還沒累積到足夠的資本前 (這裡指的是資金、人脈、經驗)，「快速致富」的方法，通常是遙不可及且充滿風險，這時候你能做的，就是首先投資你個人的專業能力，將你的唯一收入 (薪資) 努力的提升，這是提高你收入一項十分有效且顯著的方式。   許多領薪水工作的人，總用著「僱員思維」在做事情：總想著我要更好的福利、這家公司就是奴性重、老闆計劃一直改來改去、管理層想法天馬行空，身為員工的你，可以下班就閃人、可以待不下去就換一家公司。卻鮮少人站在資方的立場，想著他們所需要解決的問題，如果你能站在這種角度思考並行動，通常能夠明確知道你每天工作的計畫跟目的。   一旦你的能力及能見度不斷的提升，為公司、團隊整體帶來顯著的貢獻，我相信你的老闆會一定能夠理解你的付出，並且釋出更多責任給你。相對的，這也是你收入成長的機會。如果你發現效果不如預期，我會建議你先好好審視自己是不是自己仍有所不足，並看看你周遭優秀的同事，向他們請益學習。   如果你發現你周遭沒有存在所謂「優秀的同事」，且不幸跟錯老闆 (通常存在於家族企業或是階級制度非常嚴重的組織)。我會建議你可以透過你所擁有的這些能力，在外面接案或是兼職，同時也尋覓跳槽至下一間公司的機會。我相信一旦你擁有一定程度的經驗、背景且扎實的實務成果，當你到達下一間公司時，更會讓薪水有一定幅度的成長及談判空間。   Tips - 思考流程並優化你現有的工作、生活方法   如果你想要跳脫現有的工作及生活模式，你會需要不斷思考以下問題：      原本一個小時的工作我是否能用更短、更有效率的時間完成？   我如何更有效地利用我的時間？   如何戒除不好又花錢的壞習慣 (例如：社交媒體、每天一杯含糖飲料、抽菸、喝酒)   我要如何改變現狀？   思考如何獲得其他收入   當你能更有效率的方式完成你的工作，相對的，你單位時間所能獲取的金錢也隨之提高。當你開始不斷詢問自己這些問題，將會在潛意識中逐漸引導你做出改變。   Tips - 不斷學習   我相信，從學校畢業並不代表學習之路的終點，而是開啟另一階段的學習旅程。我一直認為學習是終生的，畢竟我們人都不完美，唯有不斷學習、刷新自己老舊的觀念及知識，才有能力不斷修正自己的方向，進而更貼近自己理想中的目標。      Read and think A LOT. Buffett spends the majority of his day — 80% — reading and thinking.    就拿人人知曉的股神巴菲特 (Warren Buffett)，他老人家即使已經快 100 歲，但仍每天花大量的時間在閱讀及思考，閱讀各家公司長達數頁的年報對他來說稀鬆平常；比爾蓋茲 (Bill Gates) 平常即使行程再怎麼忙碌，仍每年一定要安排至少一週的 “Think weeks” 閉關，還很熱衷每年跟你分享必讀的書單。   他們難道就不會犯錯嗎？我想，人終究不是完美的，巴菲特也曾經公開承認他錯誤的投資，並選擇清空航空股，仍虛心受教且不斷學習優化自己，並從這些經驗中不斷提高自己所擁有的知識水平。這些 Forbes 排行榜、影響世界的強人都深知學習的重要性，所以我真的不認為，自己有理由可以極度自信的說，自己無需不斷閱讀及學習。      BOS 巴菲特線上學院 - 適合新手的 3 小時投資學習分享會 (線上)   教你用合理的價格買到好公司，並且學會如何用美股每個月賺 2~3% 的現金流   分享會原價 NT $100，透過下方連結報名可免教材費   (每個月還有免費的小課程陪著你繼續學習)   點我免費獲取價值投資課程 課程簡介    Tips - 認知達到目標需要時間及不斷的投入   Jeff Bezos (Amazon 創辦人兼前 CEO) 曾經問過股神巴菲特 (Warren Buffett) 一句話，得到了淺而易見的回答：      Jeff Bezos: “Warren, your investment thesis is so simple, and yet so brilliant. Why doesn’t everyone just copy you?”     Warren Buffett: “Because nobody wants to get rich slow”.    巴菲特的投資理論及概念十分簡單及容易，但這世界上卻仍然有九成的人無法成功複製。如果你縱觀整個市場，總是在教著你如何「快速致富」、「快速賺大錢」，但是，總沒有人願意告訴你慢慢變有錢。   其實很多事情都需要時間的醞釀，才能淬煉出不同凡響的成就。目標的完成也是需要時間及不斷地細心投入，你需要做的，就是設定你的終點，將大目標具體切割成為小目標，設為一個又一個的 Milestone (里程碑)，並用時間堆疊累積成複利效應。                     習慣帶來的複利效應            (延伸閱讀：原子習慣：細微改變帶來巨大成就的實證法則 - 我的心得及實作)   2. 認知知道這個世界並不公平，那有什麼理由讓自己怠惰？   基於 Pareto principle [1] (俗稱 80/20 法則)，這個世界運作及很多自然現象意外的呈現 80/20 的統計分佈 (80% 的資源匯聚集於 20% 中)。   統計上，全球最富有的 20% 的人口控制著世界收入的 82.7%。綜觀台灣，10%-20% 的勞動人口擁有大於全台灣 80% 以上的薪資收入：                     108 年台灣薪資分布 資料來源：行政院主計處薪情平台 [2]            Dcard 上有含著金湯匙出生的台大富家子弟喊著這個世界的百無聊賴 [3]、Johnson ＆ Johnson 家族小孩一生下來只要躺著就有數百年都花不完的祖產。所以這個世界運作本來就不公平，如果為此挑起自端的仇恨及嫉妒心理，其實對於改善自己的現況，一點幫助都沒有。   (也許唯一公平的是：時間、思考、創意發想及學習知識，以及一個人所需要培養擁有的涵養及氣質)   在富爸爸窮爸爸一書作者 Robert T. Kiyosaki (羅勃特‧T‧清崎)，提到許多核心的幾個觀念點，除了現金流的概念外，也涵蓋有關對於金錢使用角色的區別，並以 EBSI 表示，他同時也在多處地方提及了以下著名的 ESBI 象限：                     ESBI 象限 (Cashflow Quardrant)            這個世界仍基於各種不同角色而運轉，存在於 E、S 象限並不意味著你的人生就一直如此，完全取決於個人心態和對於跳耀象限所做出的努力。Robert T. Kiyosaki 也是在年輕時不斷的學習他所討厭的事物 (稅務、債務、保險等) 以實現他想達成的角色目標：      Robert Kiyosaki: When I was young age, I knew I want to get here (B &amp; I), this takes time. So when I was (before of my 20s), I knew I want to go there (B &amp; I), and I wasn’t doing what I love.     I had to learn what I didn’t want to learn. I sometimes had to do what I hated. — I had to learn about taxes, debt. I had to take classes, I had to learn about insurance.     So I was doing a lot of things I hated, so I could come over here (B &amp; I).  So my purpose was to come over here (B &amp; I), so I could serve more people.    (內容出自於 THE BIGGEST MISTAKE YOUNG PEOPLE MAKE - ROBERT KIYOSAKI)               我在國小的時候第一次接觸到這本書，深深改變我對於金錢的認知。有些觀念其實在小時候並無法直接的理解，但隨著實際用錢、工作還有不斷建立且學習的財務知識，逐漸了解到書中所圍繞的幾個重要觀念。   我個人認為仇富是一個最糟糕的心態，通常有這種想法的人往往不去思考為什麼富人之所以變富，而將一切推就於階級和金融騙局。   引用富爸爸，窮爸爸，窮爸爸總想著：「不行、我錢不夠、那個我沒辦法」，然而，富爸爸思維是：「我要如何能夠達成那樣的狀態」。                                                                                                                       富爸爸，窮爸爸（20週年紀念版） (Kindle)                                                    數位版優惠連結 - $5.00                                                   購買                                                                                                                                                    富爸爸，窮爸爸（20週年紀念版）                                                    博客來 85折優惠連結                                                   購買                                        富爸爸，窮爸爸是一本十分經典的財務觀念書籍，暢銷超過二十年，如果你有興趣，可以透過上述專用連結購買並收藏至你的書單。   3. 釐清是慾望還是需求，撇除無意義的娛樂並重視自己的生活 (善用時間)   相信大家或多或少都認知：沒辦法帶來收入的資產可視為負債，但試問自己，你日常有多少花費及開銷是真正遵循這項原則實行的？   人在消費其實都不是很理智的，不然就不會有 StarBucks 買一送一、雙 11、Black Friday 等等的活動。這些商店所設計的消費流程、亦或者是活動的背後，其實都離不開消費心理學的範疇 (屬於行為經濟學的一部分)。其實很多時候人類對於消費的選擇，很常基於情緒、商店氛圍等影響其購物決定。   最典型的案例就是炫耀著買了既時尚又高端的汽車 — 買車除了需要負擔一筆開銷，更需要燃油花費、各類稅務和保養費用。也許你會說：「我買車是為了代步」，但拋開方向盤跟品牌，多問自己：「你是不是有其他更便宜能達到相同目的選擇」，或者，你真的需要這個東西嗎？(例如：我可以選擇共享汽車、搬家到離通勤距離近一點的位置)   你可能為了擁有一部新的 iPhone 感到快樂，但過了一陣子，你會發現似乎那份愉悅十分短暫，擁有 iPhone 似乎往往無法滿足內心深處某種深不見底的需求。相比之下，我們小時候可以為了擁有 100 塊的零用錢感到富足，但長大了，明明賺了更多的錢，卻總覺得還是不夠，似乎在說著我們人類那永無止盡的慾望。   金錢和物質需求往往並不能滿足自我實現的需要，因此，如果你能開始學習重視自己內心真正所需要的並如此思考，也許你將能更有原則的善用你的每一分錢，和有意義的執行每一項決策。      我總想著，如果我的一生可以活到 100 歲，到了 25 歲這個時間點，就代表我的人生已經過了 1/4。基於需求層次理論 [4]，撇除金錢對於安全、社會需求的基本需要，那我死後，代表我這一生所追求的人生意義是什麼？    有時候我會不斷提醒自己以此為執行的原則，一部分也包含對於消費的觀念、識別當下的感受和渴望，究竟是屬於個人慾望還是真正的需求：      這東西我真的需要嗎？還是只是一時之間的慾望或是虛榮心讓我想擁有這個東西？   等我死後我會覺得擁有這個東西是值得的嗎？   擁有這個東西真的能幫助我達到我死後所期待的狀態嗎？   不管你是否年輕，時間一直是你最珍貴的資產，各種貨幣可能會隨著市場行情起起伏伏，但時間也許是地球上最公平的單位。你可能聽過：「時間在哪裡，成就在哪裡」，你把時間花在哪，投注在哪些事情上將為你帶來成就。需要時間成就的目標非黑即白，如果你今天正確的投入時間，將為你帶來成果，反之，就是一無所有。   雖然道理非常簡單，但相信我，仍鮮少有人能夠做到並且堅持，否則成功的故事不會寥寥無幾。在度過生活的每一天時，試著思考幾個問題：      我要如何利用我的時間以達成我的目標 / 改善自己的生活品質   這個娛樂真的是有必要的嗎？還是我能將這些時間以其它方式利用，以貼近我死後所期待的狀態   我要如何有效地利用自己的時間 (例如：戒除社交媒體、過量的遊戲、無意義的社交) 以奪回自己的注意力   4. 學習妥善規劃預算及存錢理財自動化   大學的時候，我曾經很認真的下載記帳 App，努力的在每筆花銷之間、各種空檔，打開應用記下自己又花了多少錢。但我發現，我自己無法保持無時無刻的紀錄每一筆花銷 (我很佩服能堅持記帳的人)，有時候又要注意是不是跟朋友拆帳，持續一個月後就開始感到這種方法要堅持非常困難。   後來，我改變策略，改為設定每天所能花費的金額 (假設大學生生活費是 8 千，每天可花費金額為 — $8, 000 / 31 ~= $250) 並且每天不能超出當日預算，牽制著每天的消費策略，從此生活變得十分輕鬆，自此也很少在月底時發現存款見底。   網路上很多理財專家們強調著：要堅持記帳、支付改用現金而不是信用卡 (因為可能會因為刷卡沒感覺會透支)。然而，如果你跟我一樣不愛記帳，你也許可以試試我反其道而行的做法。這讓我在開始工作後，直接捨棄記帳的習慣。原因是因為：      我的日常消費盡可能使用信用卡   自從我擁有信用卡後，我改用 信用卡帳單 幫助我執行每個月記帳的工作 (這讓我瞭解了每個月的支出項目和比例)   出門很少帶現金，盡可能使用電子支付，電子支付綁定了信用卡執行扣款   正確規劃帳戶，善用對帳單和銀行幫你整理的報表 (這像是銀行每個月幫你記帳，不但免費、省了很多時間而且通常還一目瞭然)   善用科技整合不同帳戶的資訊 (現在各家網銀、應用 App 都能夠實現這樣的功能，善用這些科技將為你帶來事半功倍的效果)   其實在很多國家信用卡的使用十分普遍 (例如美國就是信用卡大國)，如果你正確的使用信用卡，能夠為你帶來十分多好處，例如：      享有信用卡本身的回饋優惠 (折扣、現金回饋等)   培養良好的信用 (這個十分重要，日後不免因為需要大金額而得跟銀行打交道時，例如：買房、創業，銀行會更願意借貸)   我的消費習慣不見得適合每一個人，因為這樣的操作有一個非常大的原則，就是你必須要擁有非常好的財務紀律，包含以下幾點：      有意識的控制每天的消費，每個月絕對不刷超過自己配置預算的額度            例如：伙食開銷有一筆預算並使用對應的信用卡，每個月的帳單都能夠清楚知道自己在伙食上的花費 (現在手機也都可以直接立即查帳)           不支付自己無法負擔的消費，不因為銀行給予較大的額度，就感到自己能夠負擔閉著眼睛刷下去 (這只會為自己帶來短暫的快樂，繳帳單時將會是痛苦萬分)   帳單一定使用自動扣繳並且每月全額繳清 (絕不使用循環利率)   正確使用信用卡和電子支付能夠為你放大許多效益，但同時，這類型支付也將原本使用現金支付的疼痛感降低許多。因此，理財除了聰明消費，我認為更重要的是學會「預算」。在以前，我想著存錢的方式是：      收入 - 生活開銷 = 儲蓄    後來我發現，這種方式很容易因為衝動消費或是一些情緒驅使的消費，讓你花了更多的錢、存不了多少儲蓄。為了翻轉這個問題，我開始學習規劃預算，理解金錢預先分配的重要性，於是每個月拿到薪水的模型變成以下：      收入 - 儲蓄 = 生活開銷                      執行分離帳戶            在實際的應用中，我會在每個月薪資入帳後，自動將金錢按比例轉帳至分離帳戶，並區分為 6 個以上不同用途：      緊急 + 保險備用金   投資 + 夢想基金   教育基金   健身基金   旅遊基金   生活費 (這是薪水拿到後最後才會注資的，平常開銷都只使用這個帳戶的錢)   每個月生活費多少就是多少，帳戶沒錢了就是乖乖吃土 (減少娛樂消費、少吃大餐)。不管收入多寡，也嚴謹遵循這樣的原則，同時，對於每月用錢執行的計畫上更加嚴謹。當你根據 1. 認真工作、認真學習 的建議，讓收入逐漸能夠打平生活槓桿並且控制你的物慾，你會發現存錢其實並不難。財富的累積更不是看你賺錢能力有多少，而是你能夠保留多少資產，並且利用其幫助你賺錢產生更多效益。利用這種方式，讓我默默地在畢業開始工作後，每個月固定存了 50-70% 以上的薪資收入作為投資和儲蓄用途。   我並不建議將帳戶分離過多，除非你的薪資收入非常高，否則，除了難以管理，同時你的金錢也會被切到十分微小，裡面存下的金額會少到讓你懷疑自己儲蓄的計畫，而難以堅持。   如果你什麼都沒有，我會建議請先存下一筆準備好 6-12 個月你失業還能夠養你的緊急預備金 (例如：每月花銷金額 * 12 月)。花點時間寫下你人生中追求並重要的 1-6 件目標 (例如：買房、退休)，根據其規劃思考你未來幾年後所需要的金錢，並切割成每月要儲蓄的金額。   你可以透過建立一個自動化的系統幫助你執行存錢自動化，現在有許多數位網銀和 App 都能夠實現這樣的功能，讓你可以設定每月自動存入，例如：   台新 Richart 提供的「小查罐」功能   台新 Richart App 提供了「小查罐」可以幫助你設定不同的子帳戶 (目前上限最多 10 個)。你可以根據不同用途設置，來幫助你完成不同的儲蓄目標。同時也可以隨時調整選擇單次存入或是每月固定存入：                     Richart 小查罐            台新 Richart 仍是台灣數位網銀數一數二 UX 設計十分友善且易用的，如果你對於這樣的功能有興趣，目前台新仍在推出開戶優惠計劃，你可以使用我的以下專屬連結註冊，不但全程線上完成開戶不需要跑銀行，完成開戶後，還可以獲得 100 塊台幣：      點擊這裡申請Richart存款帳戶並首次登入Richart APP成功，就能獲得 NT$ 100 用戶禮   國泰世華網路銀行子帳戶   除了台新銀行所提供的功能，國泰世華網路銀行 App 也能夠幫助你設置子帳戶：               (點擊這裡下載並申請國泰世華 App 獲得抽獎好禮 - 邀請碼: ETBL9)   如此一來，這將讓你專注於重要的任務 (實現財務管理) 使其帶來效益，能為你的明天贏取更多的時間。                     Focus Tunnel            (延伸閱讀：3 項原則讓你變得更有生產力 - 最有生產力的一年 The Productivity Project)   5. 投資是追求風險控管而不是報酬   你可能會因為某某老師或是誰，最近因為透過 ABC 產品，賺了大錢讓你心癢癢的並且也想要入坑 (例如：想要開始炒比特幣)，但請記得：   所謂的投資(財務投資)，是指透過完善的分析，對於本金、報酬可達一定程度的預估，將資金投入那些預期有所成長的標的上。   然而，當你開始投入股市、或是去 ptt 股版逛一圈，你總能發現報明牌，還有鼓吹哪檔標地看漲的投資人，掛著「投資」的名義做著「投機」的操作。   最顯著的例子是 Bitcoin，2021 年 3-4 月份當加密貨幣價值被炒到天價時，你會發現全世界的人真的是瘋了。新聞、媒體、所有人一股腦的瘋著都搶著討論加密貨幣，似乎不買 Bitcoin 、Tesla 或是加密貨幣跟上這波流行，將錯失翻身的機會。但如果仔細問問他們選擇購買這項資產的原因，我最常獲得的答案是：沒來由的跟你說這是世界趨勢、長期看漲，但一旦問及「趨勢走向」、「為什麼會漲」，相信我，10 個人將會有 100 種不同答案。   如果你仔細觀察，其實加密貨幣市場只是反應長期以來經濟的趨勢和市場行為，這些背後購買的動機，仍無法脫離人性的兩個缺失：「恐懼」及「貪婪」      “Be Fearful When Others Are Greedy and Greedy When Others Are Fearful”    我並不是說買入加密貨幣就是罪惡 (我也有買並且在操作加密貨幣)，而是你必須了解自己的風險承受能力，並理性的規劃資產配置。如果你為這兩個動力所驅使 (恐懼、貪婪) 而選擇大量購買或拋售加密貨幣，那你的投資策略將會十分危險。   其他案例像是：壓身家借貸全部買當紅股票 [5] [6] (台積電、長榮、陽明)，如果你是一般的投資人，這種行為在我看來是十分不理性且非常危險。如果運氣好賺錢了，我非常恭喜你並且很高興你藉機發財，但相對的請記得，如果輸光你必須為自己的負債負責，至少我非常清楚這種操作策略並不適合我 (可能晚上睡不好並且每天都在擔心股票漲跌)。   綜觀市場和歷史事件 (例如：2008 年的經融危機或是 2021 年 5-6 月近期比特幣從 6000 美元一路下滑至 3000 美元，直接蒸發好幾億美金的價值)，事實是，我們都沒有聰明到能夠精準預估市場的走向，甚至連股神巴菲特都會有犯錯的時候。   那如何有效地控制風險？ 除了衡量自己的風險控管能力，正確的執行資產配置外，能夠有效降低風險的方法便是不斷學習， 當你足夠了解你的投資標的，並且擁有充足的知識、判斷能力，就像是你非常清楚你在做的生意一樣，能利用你所具備專業的知識做出合理的策略，將有助於你降低對應的風險。   知識的落差將為你帶來財富上的落差，你能不斷做的，就是努力投資自己並且不斷學習。請記得：「市場上並不缺少賺錢的機會」寧可錯失一次賺錢的機會，也不要因為投機血液作祟而做出不正確的決策，不正確的風險控制，是能夠一夕之間將你前面所累積的獲利全部吐回去。   總結   除了財富，其實你身邊一定也擁有許多珍貴的資產：家人、朋友、你所認識的人及擁有的事物 (健康、你擁有的知識、欣賞及演奏美妙音樂的能力、創意 …. 等)。一昧的追求金錢並不是人生目的，好好思考人生中對你重要的事物，並且保持開放的心態享受人生的每一個階段。   在這篇內容中，我與你分享了我個人對於財務規劃上十分重要的幾點建議。請記得：      “The stock market is a device for transferring money from the impatient to the patient.” – Warren Buffett.    如果你覺得這樣的內容有幫助，可以在底下按個 Like / 留言讓我知道，並且與你週遭的人分享，讓我們一同在學習財務管理這條路上共同努力。   看更多系列文章      學會揭開投資騙局 - 如果你想快速賺大錢，千萬不要去 BOS 巴菲特線上學院   在 25 歲至少擁有 100 萬 - 5 個適合年輕人的理財建議   台新 Richart 到底能不能轉到 TD Ameritrade (海外轉帳)？答案是 Yes - 3 個步驟開啟 Richart 海外約定轉帳   我常用的自動化理財工具及策略 - 適合理財新手的操作手冊   Reference      [1] Pareto principle   [2] 行政院主計總處：薪情平臺   [3] Dcard - 這年頭沒人在靠自己的好嗎？   [4] 需求層次理論   [5] 貸款200萬元！北醫男只買台積電「6個月賺75萬」成功秘訣曝光   [6] 拿房借貸買台積電拼一把                                                                                                                       富爸爸，窮爸爸（20週年紀念版） (Kindle)                                                    數位版優惠連結 - $5.00                                                   購買                                                                                                                                                    富爸爸，窮爸爸（20週年紀念版）                                                    博客來 85折優惠連結                                                   購買                                        ","categories": [],
        "tags": ["finance","investment","money","personal growth","投資理財"],
        "url": "https://easoncao.com/financial-management-tips-for-young-people/",
        "teaser": "https://easoncao.com/assets/images/posts/2021/05/financial-management-tips-for-young-people/cover.png"
      },{
        "title": "學會揭開投資騙局 - 如果你想快速賺大錢，千萬不要去 BOS 巴菲特線上學院",
        "excerpt":"我曾經對自己私底下承諾，只要我的 TD 帳戶從零一步一步累積至少一萬美金的資產，就決定認真跟大家分享我在背後經歷學習的部分心路歷程，沒想到真的寫出來，已經是突破兩萬美金的時候了 (不好意思本人有拖稿的壞習慣)：                     達到累積一萬美金的目標            在有系統性的達成目標的背後，一部分是因為繳了快 4 萬塊的學費報名加入「BOS 巴菲特線上學院」開始努力學習並了解價值投資。我想到這個階段，用一篇文章的時間濃縮一下我個人對於這 1-2 年投入股市的經驗總結。   同時，讓我來告訴你，如果你正在猶豫 BOS 巴菲特線上學院好不好、是不是要報名課程、美股投資 OK 不 OK … etc   以下就讓我這個菜雞學員跟你分享，我成為學員學習一年多以來的心得，讓我用一篇文章的篇幅告訴你，幫助你客觀判斷這個課程是否適合你，也讓你學會分辨投資騙局。                     學會揭開投資騙局 - 如果你想快速賺大錢，千萬不要去 BOS 巴菲特線上學院               在這篇文章中你將知道      BOS 巴菲特線上學院是什麼 (點擊這裡免費獲取 3 小時的價值投資課程)   帶你揭開幾種常見的投資騙局   我在 BOS 巴菲特線上學院學到什麼？以及我學以致用後的投資績效表現    30 秒讓你了解本篇重點   如果你隨便 Google 一下「BOS 巴菲特線上學院」，你絕對可以找到排名前幾的推薦文章和評價。但大部分內容都沒有提及一些事實，因此，今天我的這篇撰文將與你客觀分享我對於 BOS 巴菲特線上學院 (Buffett Online School) 的一些真實面。   本篇的結論是：      如果你希望這個課程學完後，能從投資中快速賺大錢，千萬不要去 BOS 巴菲特線上學院    為什麼會這麼說呢？首先要從「什麼是價值投資」說起，這也是 BOS 巴菲特線上學院所圍繞的投資核心：   什麼是價值投資      價值投資絕對不是短時間賺大錢的方法，如果你偏好短期操作，這門課程絕對不符合你的調性。    其實股市投資的方法非常多，每個人適合的工具也不同，以下是幾種常見的投資方法：                  投資方法       價值投資 (佛系投資派)       技術指標 (當沖、短線操作派)       主力買賣超分析 (人云亦云投資派)                       投資面向       基本面       技術面       籌碼面                 投資週期       長期       短期       不定                 盯盤時間       極少       長       中                 風險性       較低       較高       中                 報酬穩定性       長期穩定       波動較大       中                 持有標的時間       長       短       中                 決策判斷複雜性       要分析財報與護城河       容易入門，但常出現模稜兩可的情形       未必能表達主力真正意圖           價值投資最看重的以及最核心的策略，包含幾個面向：      以老闆思維在挑選標的，重視護城河和財務狀況，勝於追隨趨勢及潮流   在意的是價值，而不是價格   長期持有   如果你今天就是比較喜歡追求刺激並且愛在股市殺進殺出，那跟你說再多價值投資的策略，你也未必接受。   我在當初接觸台灣股市時，也認識過做當沖交易的保全大哥 (不知道為什麼我認識的保全大哥都是已經財富自由來退休交朋友的)。年紀輕輕的他就靠當沖交易致富，錢多到還可以在信義區置產。   當時我跟他聊著我想開始踏入股市，他也跟我大方談吐他過去操作股票的思路，以及技術分析的竅門：我會看這個正方形，怎麼畫線、通常這個時候進場就是要漲、我只要有賺就見好就收 … etc   所以那時候我也認真在買股票後，多少學習研究一下技術分析的知識，但後來覺得這種方法有點看運氣、無法抵擋金融危機，且缺乏評估一檔股票好壞的基本邏輯 (可見真的不太適合我)。   當然，我相信懂得操作的人絕對有他的技術和專業在，能夠透過當沖交易賺錢且擁有高勝率也是一個本事，但說白了這種方法真的不太適合我，尤其是要每天盯盤擔心股票的漲跌，我發現我並沒有這樣的心臟與精力。   我並不是一位全職的操盤手，因此我決定潛心研究更核心及根本的思維，用企業、長遠經營的角度認真思考我的投資標的，影響我的投資方法。   帶你揭開投資騙局   其實在台灣不乏有許多以投資和理財為主題的頻道和名人，例如，你可能聽過以下：      不敗教主 - 陳重銘   樂活大叔 - 施昇輝   華爾街操盤手 - 闕又上   下班經濟學   柴鼠兄弟ZRBros   無本當沖學院   市場先生   Ms. Selena   Yale Chen   蕾咪 Rami   股魚   小資女艾蜜莉   StockFeel 股感   價值投資達人 - 華倫老師   … 等等   各家理論和方法百百種，我不會說哪種好、哪種不好，但大家可以思考一下，有多少人認真的跟你說如何「控制風險」、「資產配置」、「正確存錢」、「評估投資標的」？ (我相信上述列舉的還是有的)   我也看過、聽過很水 (沒什麼內容跟邏輯，只無腦的推崇自己選的標的) 的投資課程或是相關資源，如果你認真看著這些大師分析，也必須思考你可能已經成為他們流量的一部分，這將成為他們最終轉換成為收入的目的、或是最終導向課程購買。   正確投資其實並不難，你可以在選擇學習資源時，特別注意並且避開以下的投資騙局：   投資騙局 1 - 跟隨老師、新聞說買什麼就買什麼   投資最忌諱的事情就是跟著人家說什麼好就決定投什麼，而完全沒有自己的思考和判斷決策：我看 ETF 好像很不錯、比特幣好像很賺、人人都買台積電我也要、最近疫苗類股漲很多要趕著上車 … etc   還有人總說著買某檔基金或是 0050 (ETF) 就穩賺不賠，可以傻傻存，試問：      你真的了解 ETF 是什麼嗎？   你知道 ETF 有公開說明書嗎？你有認真讀過嗎？還是你就人家說什麼就跟著買什麼？   你知道基金或是 ETF，是有機會會下市，並且解散讓你拿不到錢的可能嗎？   你知道要怎麼規劃你投資 ETF 的資金嗎？   ETF 真的就是穩賺？你知道 Michael Burry 一直喊著 ETF 可能會泡沫化嗎？你有思考過背後的邏輯嗎？   你確定 ETF 真的適合你嗎？   當你開始認真思考你所吸收的內容是否具備一定的邏輯和驗證，並且認真研究你所購買的產品，而非這些大師們一人所操作出來的哲學，那你將會具備更加成熟的判斷能力，幫助你降低輸錢的風險。   投資騙局 2 - 過高的報酬   一般來說，合理的報酬率通常介於 3% - 10% 之間。一旦有人告訴你可以賺 20%、50% 甚至 100% 以上的投資策略，通常高於這個數字，你就必須意識到是否有潛在的高風險及危機存在，因為它將有可能是一場投資騙局。   但太多人在操作投資時，眼錢過於注重報酬並總想著要賺錢，總覺得在現在低利率的時代把錢放在銀行十分不划算，還會被通膨吃掉。因此，決定放在高報酬的標的上「賭一把」，但是，卻往往忽略自己理財的目的到底是為了賭一波還是為了累積財富：   將錢放在銀行定存也不失為一個穩定且低風險的策略，正確使用更有助於你可以達到財務目標。   當你注意到一個新興或是熱門的課程遠高於市場平均報酬率，甚至可以躺著賺，那你必須得非常小心了解正在接觸的這項產品和服務 (例如知名炒房名師王派宏吸引學員投資，並且號稱每年會發 20% 的利息返還，最終捲款潛逃)。   市場上也絕對存在高報酬的產品，但選擇這些產品之前務必具備正確的心態，並且在合理範圍內控制風險，以規劃理財策略。   投資騙局 3 - 穩賺不賠的生意   在市場一片看好的時候，隨便操作時人人都是股神，及擁有不錯的報酬。但遺憾的是，投資最忌諱的就是做了錯誤的決策渾然不知，抱持著自己才是真理的想法與其他流派互嘴。(贏錢是自己英明，輸錢都是別人的問題)   在牛市時，一片欣欣向榮，卻很少人認真看待自己現在賺錢背後的邏輯和原因是什麼。當你有任何投資課程或是名人告訴你某些標的穩賺不賠的時候，必須戒慎恐懼。   事實是，「市場上人人都想賺錢」，我還沒聽過有人進入市場是想要「賠錢」的。但遺憾的是，在市場上，通常永遠只有少數人賺錢，那些贏錢的，除了運氣好賺到一波的投資者，剩下的通常是遵守投資紀律，清楚自己的投資決策，並且擁有良好風險管理的人。      在資本市場中，最能妨礙投資者賺錢，最能害投資者虧錢的東西，不是假消息或黑天鵝，而是心理障礙，和自己設下的陷阱和地雷。     表面上資本市場玩的是金錢遊戲，事實上，這個市場玩的是心理戰。尤其是股市，並不是你錢多或人多就能穩賺不賠。     許多散戶看到某支股票大漲時，就急著去搶買那支股票的權證，即使他們知道當時的權證，隱含波動率已經被人家墊高到 90 幾個百分點，甚至飆到 100 個百分點時，他們還是怕買不到，硬是去買了價格早己被墊高太多，價格失真的權證。 [1]    巴菲特都有承認錯誤投資，並且有選擇清空航空股的一天。大盤都有崩盤重整的時候、金融都會發生危機、美股也有會熔斷的機會，而且都真實發生在歷史事件上。你要說市場上有穩賺不賠的生意嘛 … 我真的認真覺得你可以好好想一下。   投資騙局 4 - 快速致富   你可能常聽到以下宣傳：      我用這個方法短短半年已經賺進上百萬   快速讓你每天賺取 (3000 ~ 6000) 的數倍報酬   短短 10 天內賺進 51%   如果真的這麼好賺，那怎麼沒有人人都是大富翁呢？有時候不必太羨慕別人在短時間內獲得財富，先想想自己有沒有在前面付出相應的功夫。並且也要想想這些賺錢、快速致富的方式，是否合乎邏輯、以及長久適用這個瞬息萬變的市場。   如果有一堂課讓你充斥美好的幻想，可以讓你想著上完課就可以馬上賺大錢，我只能說，一個願打，一個願挨；祝你好運，恭喜發財。   投資騙局 5 - 膚淺的課程內容   一般來說投資課程都會附上一些基本的課程簡介，然而，其實你可以在課程內容和簡介上明顯感受到這個與你分享理財知識的人，他的層次和級別在哪，通常能夠分辨出投資人的涵養和所秉持的理念。   通常只顧著談論「績效」、「豐功偉業」和「輕鬆賺大錢」的老師們，通常只會跟你說他成功的案例和過往用一招半式賺大錢的過程。他們的志業不在分享投資和不斷優化，而通常是在開課程斂財或是發展其他副業。   以下都是我真實在網路上可見的一些大師們實際寫的課程內容和文案，大家看過無需過多評論，但可以好好思考一下：      我是如何在 26 歲的年紀，一年的投資被動收入就超過百萬，並且之後的每年我的獲利一直都是源源不絕的越滾越多錢!（PS. 現在帳戶總已滾出超過千萬)   教你二手包包隨便賣達到百萬營收   一檔讓我短短 1 年就賺 218％ 報酬的股票代號   贈品送越多賺越多，一年存入300萬   如何在沒有任何專業金融背景的情況下無須盯盤成功的靠投資創造長期的被動收入？   賭場 12% 定存，一年賺 560 萬   為什麼我的績效，可以打敗美股大盤，並創下美股大盤 2 倍的獲利   數十條書本上沒有的賺錢秘密 (無價，分享會現場直接告訴你)   BOS 巴菲特線上學院      BOS巴菲特線上學院 (Buffett Online School) 由巴菲特家族的瑪麗．巴菲特 (Mary Buffett)所創辦 。瑪麗．巴菲特嫁入巴菲特家族中，跟隨股神巴菲特13年，是真正第一個從股神巴菲特身上學習價值投資方法的人，而她也透過此方法，創造了屬於自己的財富。瑪麗．巴菲特想要讓更多的人認識「巴菲特投資的方法」，於是成立了『BOS巴菲特線上學院』。    這是官方給的文案，但讓我客觀的說一下是不是「真正第一個從股神巴菲特身上學習價值投資方法的人」確實讓我打一個問號。我想行銷性質大於實際內容，我能理解學院為了要招生想辦法打廣告的需要，但我也不是因此全然否定學院誇大不實。   請容我以下一一列舉及分析，與你分享我認為這個學院非常有價值和真實的幾個面向：   為什麼決定報名這門課程   我在畢業後花了很多時間跟學費，投入過學習許多投資方法和產品，像是原物料、基金、ETF、債券、股票、儲蓄型保單等等。我不敢說自己很懂，但至少有一些健全的知識能夠幫助我了解這些不同產品其實際的意義、區別，例如：      如果今天我在台灣要買主動型基金，會選擇使用公有平台而不是選擇在銀行申購   先讀讀公開說明書和基金規模再考慮是不是要買   看一檔 ETF 先了解背後組成、內扣費用是什麼，而不是只顧報酬率跟績效   債券成分以及年限   儲蓄型保單 … 除非真的是很有錢選擇配置，不然通常淪為業務的績效   因為我任職的公司談好的薪資及 Package，本來就有配發美股股票，讓我自然對美股市場有一定的興趣。加上 BOS 巴菲特線上學院廣告其實打很兇 (第一名的是史蒂夫跟戴夫，我也有用)，我是蠻相信這些出來開課的人，還是具有一定的專業和經驗，所以當時也是抱持著開放的心態多來看看一種投資模式，並且擠了下班時間參加了分享會聽聽是什麼，圍繞了幾個價值投資的核心策略：      A. Access 篩選: 利用巴菲特的策略先篩選出優質好公司   B. Buy Price 進場時機: 計算出合理的價格後等待時機進場投資   C. Cash flow 現金流: 搭配美股選擇權可以每月創造2%現金流                     價值投資的核心策略               好吧，我覺得 Make sense，但聽完還是很空泛 ….    當時聽到報名費要快 4 萬塊台幣，真的是覺得怎麼可以這麼敢收，而且覺得自己遇到詐騙。於是我就在會後認真的拋了幾個問題，並且於很認真的問了同樣是培訓師的 Victor 以下內容 (很感謝他當時沒有覺得我很奇怪)：      你們怎麼評估公司好壞？            我們會教你如何看公司的財報，並且課程中會有許多實際的案例和教學教你分析公司的基本面、財務面和護城河           判斷進場時機的策略是什麼？            我們會有一個基於不同策略的估價方法，幫你算出股價相應的「合理價格」           市面上也有很多技術分析、判斷進場的方法，為什麼你們會提這種策略？            市面上教投資的策略很多，我們基於的模型就是屬於估價和分批買進，進行長期持有的策略。你可以去市面上選擇其他合適的方法，不一定要來我們這裡上           你也是培訓師！？你們培訓師過去都是無償志工是真的嗎？那 BOS 學院到底是怎麼組成的？為什麼會想當培訓師？怎麼樣成為培訓師？            我們培訓師過去原本都是學員，後來願意在假日當志工，過來一起跟大家學習。成為 BOS 培訓師我想最大的必要條件就是要有熱情，就是要具備教學的熱情在分享投資這件事情上，並且持續學習。           我當時是這麼想的：所以你還是不具體告訴我策略是什麼，反正你們就是有一套估價方法而且還不是技術分析就對了？   — 「好吧，心一橫就來聽聽到底是什麼，被騙就當繳學費了。」   我還記得，當時開收據的時候，問到不用 TD Ameritrade 作為課堂上主要的操作券商戶，改用其他原本就有的美股證券戶行不行 — etoro 和 FirsTrade，就馬上披頭被某培訓師大聲訓斥：「你知道 etoro 是什麼東西嗎你還敢用？」      這是另一個故事了，因為 etoro 預設是 CFD 差價合約，BOS 學院是不太鼓勵大家使用 etoro 的。     我當然清楚 etoro 預設交易 CFD 的這件事情，因此我能理解培訓師們勸人不要用 etoro 並且盡快上岸的心情。     為了避免交易 CFD，我在使用 etoro 後已經主動更改了監管單位，以交易實體股份而不是合約，也理解其中可能的風險，所以本來在 etoro 帳戶裡面也沒有注入很多資金。     etoro 在金融和 FinTech 領域上足以有一部分的創新，而且在美國跟各個國家也有掛牌和監管：          英國金融行為監管局(FCA)：編號 583263     澳洲證券投資委員會(ASIC)：編號 491139     賽普勒斯聽證會(CySEC)：編號 109/10     美國金融監管局(FINRA ETORO USA SECURITIES INC.)     證券投資者保護公司(SIPC)       在 2021 年 3 月 16 日更與 FinTech Acquisition Corp V 合併 並且在 NASDAQ 上市 (NASDAQ: FTCV)。在 etoro investor relations 更可以看到提交給美國 SEC 的相關文件、財報     etoro 包含可以簡單的交易很多不同的產品，包含虛擬指數、複製倉位和加密比特幣 (合約)。     每個人在開戶後都有專屬的 Account Manager，所以作為一些小額投資的方法，其實是不錯的。     當然，在使用這幾家券商後，我個人並不怎麼推薦，也比較鼓勵新手選擇 TD Ameritrade 作為入門的證券商    其實我十分贊同 Victor 老師曾經說的「你可以去市面上選擇其他合適的方法，不一定要來我們這裡上」，分享會也是很多聽聽就閃人的會眾。我很少聽到有教育機構可以吃了誠實豆沙包，跟你說這樣的策略不見得適合每一個人，而不是慫恿你趕快報名、不報名將錯過財富自由的機會等等，讓你衝動消費。   而且講述能夠獲得報酬的獲利方式，其實符合邏輯且蠻合理的，這當時讓我感受到這個教育機構真金不怕火煉的自信。      BOS 巴菲特線上學院 - 適合新手的 3 小時分享會 (線上)   教你用合理的價格買到好公司，並且學會如何用美股每個月賺 2~3% 的現金流   分享會原價 NT $100，透過下方連結報名可免教材費   (每個月還有免費的小課程陪著你繼續學習)   點我免費獲取價值投資課程    我在這裡學到什麼   我在學院裡學習到非常多有趣的財務知識，光是線上平台的內容就有數小時的內容供你點閱：                     線上課程平台提供的內容 (會不定時更新)            而且 BOS 屬於全球跨國教育的體系，這對於我來說，是十分吸引的，我也有加入 BOS 在全球的 Facebook 社團，除了美股，裡面也討論很多不同國家的市場 (例如：新加坡、中國、日本等等)：                     BOS 學院在全球的分佈據點                              BOS 全球的社團            此外，BOS 巴菲特線上學院同時也具備 ISO 9001 的規範 (台灣到底有多少理財教育機構具備這種公認認證？)：                     SGS 國際 ISO9001 認證「美股價值教育機構」            其實 Dcard 上也是有 [2] [3] 覺得上完課程浪費錢的學生，覺得估價模型跟策略十分地無效。我只能說，如果你一昧的套用計算公式，說一直等不到進場時機點，我只能說有點以偏概全。   你可以說 BOS 學院教的內容不適合你，但這背後肯定是有一套系統及規範的。如果你希望這個課程學完後，能從投資中快速賺大錢，那你千萬不要去 BOS 巴菲特線上學院。因為如果你是短線操作的投資者，你絕對會覺得這種慢慢累積知識和財富的過程是在浪費時間。   我只能說：道不同、不相為謀。但如果你也認知到慢慢累積財富的重要性，以下是我想與你分享我在接觸學院後，有許多改變的幾個項目：   更認真學習財務知識和投資新知   我認為投資是需要做功課的，這個學院大部分的時間，就是在不斷的告訴你要如何研究公司、評估市場、最重要的是擁有正確的心態，並且努力的學習財務知識和投資新知。   BOS 學院其實有很多學習資源和豐富的知識庫，這是我覺得含金量最高的：      BOS 學院就像是一個小型 EMBA，學院裡面學員臥虎藏龍，並且都樂於分享            有各式各樣背景和不同產業類別的學生，每個學生對於自己熟悉的產業都有不同的洞悉，這在了解不同性質的公司的時候可以用更專業的角度評估公司的好壞       有國稅局相關的同學、或是了解法律及稅務的同學，分享報稅、合法節稅的知識       懂房地產的跳出來教你怎麼看房買房       懂音樂的會創作 BOS 之歌           我個人認為 Facebook 社團跟額外的補充才是精華，常常會有直播、小組討論和同學分享自己對於公司財報的分析，還有許多額外的學習資源，並且追隨趨勢了解相關動態   我真的很好奇這些覺得浪費錢的學生是天性喜歡做波段覺得不適合呢？還是學東西都只學一半？   對於這種負面建議，我想也是樂於見到這些聲音以讓我們有更多開放性的討論，但我無法過多評論。我只基於事實與你分享，我認為加入這個學院最有價值的地方絕對不是基礎課程教導最基本的估價方法、跟告訴你有哪幾檔股票，而是其他面向的資源和訓練。   我在這裡充實非常多健全的財務知識，包含「怎麼教你存錢並且自動理財」：      一生要用多少錢   存到 100 萬的方法   自動化理財   很多學院大部分都只是講個一招半式、收完學費就拍拍屁股走人，讓你自生自滅。但有趣的是，這個學院有一堆奇奇怪怪的其他小課程，而且都是「免費」，還不怕你一直重複上：      愛情小課程   如何快速讀一本書   時間管理   52種被動收入來源   超強記憶力課   資產配置交流與強化   創意思考課程，解決人生疑難雜症   自動理財實戰課   ETF實戰課   發揮你的天賦心流   台股一日地獄班   我雖然沒有去上到實體課程，但這些都是我在線上有跟到的幾個課程。老實說除了掛理財標題之類的課程，其他課程 (像是有畫粗體的) 簡直就是莫名其妙。   我在這些資源裡面所認知 BOS 學院最大的核心價值，就是讓你具備「有錢人思維」，讓你在學習「投資」的同時，也正確的經營你的生活和人生。   特別是「時間管理課程」讓我感觸最多，從中提到許多實務的方法，重新審視自己花費的時間和精力。並且認知到，要具備健全的投資知識也是需要花時間學習，並且不斷優化的 (但壓根跟投資就是無關)。   以下是其他的小課程主題：      兒童理財家長訓練班   魯拉帕路薩效應訓練   哥倫比亞大學價值投資課程精華   ETF實戰課   價值投資的金律   個人股票配置課   … 等等   同時每月也都會有 Mary Buffett 和其他 BOS 教練評估市場狀態的一些分析會議影片 (全英文)，前陣子也提了像是 Tesla、中國公司、旅遊業、低利率對銀行股的影響等 … 這些市場上熱門的一些話題。   其實資源豐富且講了很多細節，只是需要花很多額外的時間努力學習。從中學習、看看這些投資多年的教練都是怎麼看市場的，充實自己的知識面。其實都擔心太多東西學不完，說報名浪費錢，我真的是覺得有些以偏概全：                     與 Mary Buffett 相關的會議            學習看財報評估公司體質   價值投資最看重的就是以老闆心態看公司整體營運，以挑選標的。所以認真來看，前期絕對不是一個簡單懶人的投資方法，但通常是最貼近公司營運和市場運作邏輯的一套哲學。   課程上會引導你看上市公司三大財務報表：      資產負債表 (Balance sheet)   損益表 (Income Statement)   現金流量表 (Cash Flow Statement)   並且也會給出實際公司做財務假帳的案例，讓我能用更客觀的角度評估這個企業的財務狀況和賺錢能力，而不是根據一間公司的 Branding 就憑感覺的投資，相對而言，並不會依賴股票價格水漲船高或是新聞怎麼說，就決定買進。   這正是整個價值投資圍繞的重點，我們挑選好的公司或是正確評估這個公司的獲利能力，而不因為某檔股價便宜，就決定買來賭一波飆股。   這是我還在努力學習的重點，現在有時間為了想更加了解一家公司，都會很認真的拿他們的投資人年報和財報慢慢讀，像在讀雜誌一樣，但也是我覺得很有趣的地方。   進場時機點   我在學習許多課程之後，對於股票的「價格」有了更另一層次的理解，更理解投機的投資人他們會買低賣高的邏輯 (賺取波段)，就不會急著想要進場。   因為美股的市場十分大，自然就會更有耐心的轉移自己的金錢，配置不同的部位慢慢等，並且並努力研究公司財報，找好公司。   對我來說，我的策略並不複雜，而且也是課程中不斷強調的：      定期投入穩健的部位   根據估價或歷史價格，在合理且相對低點的價格買進配置   長期持有   在 [2] 裡面對估價根本進不了場的討論，吵得沸沸揚揚。其實 PE 只是一個判斷的一個市場狀態的指標，在現在市場總體被高估的狀況，你理所當然的沒辦法輕易的進場 (我遇到有這麼漂亮價格的時候，大概就是美股熔斷那段時間)。   前期課程與你分享的模型是十分保守的，採用這麼保守的方法是幫助你提高安全邊際，這將有助於你降低輸錢的風險。但這時候看的，就是你是否有耐心了，這也是額外學習不斷強化對於投資學習的重要。   如果是我了解追隨大盤指數的 ETF 標的，基於這種指數型基金背後運作的經濟及市場理論邏輯，我個人仍然會使用定期定額慢慢買，只要正確配置好資產控制風險，了解自己投資什麼東西並且清楚其價值，讓錢和時間複利慢慢幫你工作。只要是有價值的標的，最終時間會證明，只是賺多賺少的問題。   你當然可以隨時進場，只要為自己的投資決策負責就行。   (這裡必須推薦我在國高中看過一部由 Bridgewater Associates / 橋水基金創辦人 Ray Dalio 分享的影片)   [經濟機器是怎樣運行的 — 時長30分鐘]               再次呼應之前撰文提到的：我相信市場上並不缺少賺錢的機會，寧可錯失一次賺錢的機會，也不要因為投機血液作祟而做出不正確的決策。我不會因為錯失進場的時機點而感到可惜，我只會為自己做錯誤的投資決策賠錢而感到後悔。   不再盯盤及煩惱股價漲跌   我還記得我第一次開完台股帳戶買入第一支股票的時候，每天都很煩惱價格，並且不時都會去看看自己的倉位。只要看到賠錢或是起起伏伏，都特別影響自己的心情，覺得怎麼一下子就少了幾千，有時候甚至會影響自己工作的思緒。   但在我上完這些課程後，讓我重新檢視自己的資產配置和持有的部位，並且逐一汰換過去那些聽爸爸媽媽的話買的股票。清楚認知到股票價格就是有漲有跌，然而，一間好的公司其價值將會不變並且會持續成長。   當大家都在看漲哪幾檔股票時，我仍會重新檢視市場是不是過於高估這家公司：      Be Fearful When Others Are Greedy     Be greedy when others are Fearful    現在我通常台灣時間早上掛個單就去睡覺了，大部分 2-3 週才掛單，也很少在看盤，只會看一下最近的報價怎麼樣。其他時間就是努力看看財報，學習並體會更多營運和策略面的洞悉。   有趣的是美國市場非常熱絡，而且沒有漲跌停限制，因此除了直接掛合理價以內的現價單，用歷史價格回推的策略，通常如果差個幾塊美金，總有一天都會掛到 (會有可能是 20-60 天後)。   這是我現在對於市場的狀態和觀感，對我來說，股市崩盤像是週年慶大特價一樣，這時候價值投資者在股價下跌時是會歡呼的。對我來說，在意自己買入的標的是否穩健大於是不是飆股，來的重要許多。   套一句我十分印象深刻的金句：      股票什麼時候漲？ — 你賣出的時候漲     股票什麼時候跌？ — 你買進的時候跌    打造自動化理財   如同我於 在 25 歲至少擁有 100 萬 - 5 個適合年輕人的理財建議 裡面提到 學習妥善規劃預算及存錢理財自動化 的重要性。   有我在學習財務管理之後，便開始認真的打造自動化理財的系統，幫助我有效率的管理財務和預算分配，有興趣可以參考我常用的自動化理財工具及策略。   我的部分投資績效   我是一個不怎麼盯盤的投資者，我的大部分時間仍投注在努力學習和工作、提升能力上，努力學習投資則是我的另一項興趣。我應該不是最認真的學生，但總體來說以目前市場狀態，我目前的配置略勝於大盤總體表現：                                                                                                                                                                      我的部分投資績效       我的不同投資部位仍基於收入的 30% - 50% 持續投入，我想市場價格總會起起伏伏，這些績效只是讓我檢視：我是否足以理性，並且優於大盤表現。其他的，我只在意我的資產是否有持續增長。如果今天發生金融危機，瞬間掉了 10% - 30% 的盈利，我仍然可以很淡定的跟你笑著說：      哦！最近市場表現不太好呢，既然開始下跌了，那我們再多買一些    相信我，你一定會覺得我瘋了。   雞蛋不要放在同一個籃子裡   我記得當時肺炎爆發，導致全球金融市場一片動盪，甚至發生美股熔斷的時候，我手中握有的倉位都是一片慘賠至少 20-30% 以上。那時候真的一度懷疑自己怎麼輸那麼多錢，而覺得有些恐懼。不過慶幸的是，都是拿閒錢去投資，一部分還是一股腦相信標的是好的 (現在想想只是憑感覺)。當時也覺得如果輸掉大不了可以當學費，當個經驗也好，就沒有恐慌性的拋售。 (然後努力的上 BOS 學院的課程決定再買多一點)   我後來非常感激能夠有這次機會真實感受到市場恐慌，體驗 2008 年金融泡沫的那種恐懼，還有大家瘋狂拋售資產的那種速度。更體會到有時候市場確實是瞬息萬變、讓人難以捉摸的。   有時候理論講講大家都信誓旦旦說著：我沒問題！，然後拿著歷史線圖跟你說「我當時 2008 年多買怎麼樣現在就是億萬富翁 … blah blah」，但當你真的遭遇投資部位損失 30%, 40% 甚至是 50% 時，你還能如此的淡定嗎？   這讓我很感激有體驗過這樣的一段時間，當我經歷這些過程，間接幫助於我建立更健全的投資心態，並且認知努力規劃資金和資產配置的重要性。   其他 BOS 巴菲特線上學院的真實面   這是在入教而不是簡單的一門投資課   BOS 學院非常像是一個門派，信仰著「價值投資」這個哲學，裡面很多「學員」(我稱之為教徒) 非常喜歡發表迴響。很常培訓師或是有人分享一些符合理念的內容 (例如：長期持有) 就開始起哄，然後就開始用同樣的文字串洗版。   裡面也有非常多形形色色的人 (包含有投機血液的人) 充斥在裡面，如果被發現還可能會被培訓師、或是其他同學們狠狠地教訓一番 (通常是你一來我一往的互相辯論)，檯面下不免形成一種培訓師箴言的風氣 (不過大部分都很有道理)。   其實這種行為並不會造成什麼問題，只是如果你跟我一樣不是非常喜歡洗腦式傳教的操作，常常需要花一點時間閱讀討論串，並且略過一些芭樂內容，以找到重要的資訊。當然，如果你很喜歡討論的話，裡面也不乏有許多辯論大師可以讓你練練手。   有時候培訓師們比較多話而且會無限重複是真的，而且可能會是既囉唆又充滿長輩關懷的語氣。畢竟這些培訓師們是認認真真有在學習投資，且很努力在製作內容、學習以及分享知識，所以不免會無限的分享他們的見解。從他們身上可以學習到非常多經驗，少了很多摸索的時間和力氣。   在投資的路上，讓有經驗的人分享他們的見解、實際經驗和有他們對於市場的分析，對我來說，這些培訓師就像是個人理財教練一樣，身為學員，也從他們身上學習非常多東西 (但有時候為了讓不同程度的學員理解，內容可能會很淺而且一直重複，有時候上課必須要有耐心)。   我個人是很愛聽這些評論，但如果你不喜歡有像爸爸媽媽角色的人一直給你無限勸告，例如：      我只相信價值投資   長期持有、長期持有、長期持有 (大概是最常聽到的關鍵字…)   不要當沖   好公司過去績效不代表未來是個笑話 (某位培訓師金句)   不要不明白風險操作槓桿   我們是做賣方！你下單下錯借到錢了！   如果你骨子裡還沒準備好接受這套哲學的話，那你可能真的要考慮是不是要花錢一直聽培訓師們無限洗腦老巴哲學，並且當你的理財教練跟他們學習。   讓完全不懂英文的人也投入美股投資   這是我覺得最危險的一個操作，也是我並不非常鼓勵所有人貿然投入的原因。試問身為投資者的你，決定開設證券戶把錢放置在海外，假設今天因為美國當地法規要求讓你必須出席至美國一趟處理資產，雖然機會很低，但你有能力應付嗎？   (但我想 BOS 巴菲特線上學院的培訓師們通常這時候會列出 SOP、或是包機帶大家飛過去 XD)   更別說在開戶階段閱讀所有資料、飄洋過海的文件和報稅表格，其實還蠻多人照著教學、步驟、範例表格填寫就能無腦開戶跟處理這些文件，讓我非常懷疑有多少人認真閱讀條文跟所有原文文件？   事實是，常常就是培訓師說什麼大家就跟著做什麼，當然，大部分情況培訓師們都很認真的幫大家看清楚這些條文並且提醒，但身為學員如果無腦又傻傻閉著眼睛簽下去，其實還蠻危險的。   (你知道你簽署的所有文件都是有法律效益的嗎？)   培訓師卻總是只說著用翻譯工具還是可以多麽容易的了解美股、在台灣也可以輕鬆投資美股等等 … 卻很少提及這些建議的素養和具備的知識，心裡有時候還真的是替他們捏把冷汗。   學院幫助大家縮短投資美股的門檻著實是一件好事，但當你看到有非常多完全不懂英文的學員，真的就是傻傻的簽完所有東西、英文不熟下錯單上社團哭訴，直接變成真實的Case Study。   (這種學員真的還是比較推薦用複委託在台灣券商下單)   總結   此外，就我的觀察，其實有許多知名理財紅人都曾是 BOS 巴菲特線上學院的學生 (e.g. 慢活夫妻, Ms. Selena, 市場先生 … etc)，而且如果你在理財相關圈子逛一圈，會發現好像大家講的投資概念 (尤其是美股) 講得內容好像都跟 BOS 巴菲特線上學院講的一樣 (而且可能少於課程講的內容，卻賣得嚇嚇叫)。如果你熱衷於學習並且想更進一步的充實財務知識，那我非常推薦你可以試試 BOS 巴菲特線上學院。   在這篇內容中，我與你分享了幾種常見的投資騙局並且帶你一一揭開，也與你分享了我在 BOS 巴菲特線上學院學習的一些實際細節和收穫。   切記，投資方法真的無需找最好的，但要找最適合自己的！如果你對於這樣扎實的投資理財課程有興趣，可以使用以下連結免費獲取 3 小時的價值投資課程分享：      BOS 巴菲特線上學院 - 適合新手的 3 小時分享會 (線上)   教你用合理的價格買到好公司，並且學會如何用美股每個月賺 2~3% 的現金流   分享會原價 NT $100，透過下方連結報名可免教材費   (每個月還有免費的小課程陪著你繼續學習)   點我免費獲取價值投資課程    當然，如果你覺得這樣的內容有幫助，並且有助於你更加了解這些內容，可以在底下按個 Like / 留言讓我知道，並且與你週遭的人分享，讓我們一同在學習財務管理這條路上共同努力。   看更多系列文章      學會揭開投資騙局 - 如果你想快速賺大錢，千萬不要去 BOS 巴菲特線上學院   在 25 歲至少擁有 100 萬 - 5 個適合年輕人的理財建議   台新 Richart 到底能不能轉到 TD Ameritrade (海外轉帳)？答案是 Yes - 3 個步驟開啟 Richart 海外約定轉帳   我常用的自動化理財工具及策略 - 適合理財新手的操作手冊   Reference      [1] 為什麼股市永遠只有少數人賺錢？一個40歲交易員的教訓：你的不自律，就是別人的新台幣   [2] 上完BOS價值投資課程的評價，還是不會投資！   [3] BOS巴菲特線上學院   [4] 理財板的十六個門派  ","categories": [],
        "tags": ["finance","investment","money","personal growth","投資理財"],
        "url": "https://easoncao.com/value-investing-and-buffett-online-school/",
        "teaser": "https://easoncao.com/assets/images/posts/2021/06/value-investing-and-buffett-online-school/cover.jpg"
      },{
        "title": "[AWS] 排除 Application Load Balancer 使用 HTTP/2 健康檢查 (Health Check) 失敗",
        "excerpt":"自 2020 年 10 月，AWS Elastic Load Balancer — Application Load Balancer (ALB) [1] 開始支援 End-to-End HTTP/2 協定，這意味著你可以透過 Application Load Balancer 幫助你處理 HTTP/2 版本的請求。   當你在建立 Target Group 時，可以選擇相應的使用版本 (Protocol Version)，並且採用 HTTP/2 轉送：                     於 ELB 建立 Target Group 時選擇使用 HTTP/2            這篇內容我將會與你分享我在工作中處理案例時，使用該功能所遭遇的問題，並提及相關的技術細節。   問題描述   我嘗試在我的環境中建立了一個 Application Load Balancer (ALB)，並且，使用範例應用程式 [2] 為 ALB 轉發提供服務。   我在我的環境中，使用了以下設定：      Protocol Version: HTTP2   為 ALB 設定健康檢查 (Health Check)   但應用程式始終無法通過 ALB 的健康檢查 (一直為 Unhealthy 狀態)：                     選擇使用 HTTP/2 無法通過健康檢查 (Health Check)            然而，使用 HTTP1 時，能夠正確通過健康檢查。同時，使用 --http2 測試也可以返回相應的內容：   $ curl --http2 172.31.18.7 -vvv -s &gt; /dev/null  * Rebuilt URL to: 172.31.18.7/ *   Trying 172.31.18.7... * TCP_NODELAY set * Connected to 172.31.18.7 (172.31.18.7) port 80 (#0) &gt; GET / HTTP/1.1 &gt; Connection: Upgrade, HTTP2-Settings &gt; Upgrade: h2c &gt; HTTP2-Settings: AAMAAABkAARAAAAAAAIAAAAA &gt; &lt; HTTP/1.1 200 OK &lt; Server: gunicorn/19.9.0 &lt; Date: Thu, 08 Jul 2021 21:15:29 GMT &lt; Connection: keep-alive &lt; Content-Type: text/html; charset=utf-8 &lt; Content-Length: 9593 &lt; Access-Control-Allow-Origin: * &lt; Access-Control-Allow-Credentials: true &lt; { [9593 bytes data] * Connection #0 to host 172.31.18.7 left intact   問題研究   Client 端行為 (curl)   問題回到 curl 提供的 --http2 參數，文件 [3] 中提及了該參數可以幫助你啟用 HTTP/2：      curl offers the –http2 command line option to enable use of HTTP/2.    從請求行為中，也可以注意到該行為的請求：   $ curl --http2 172.31.18.7/get -vvv  *   Trying 172.31.18.7... * TCP_NODELAY set * Connected to 172.31.18.7 (172.31.18.7) port 80 (#0) &gt; GET /get HTTP/1.1 &gt; Host: 172.31.18.7 &gt; User-Agent: curl/7.61.1 &gt; Accept: */* &gt; Connection: Upgrade, HTTP2-Settings &gt; Upgrade: h2c &gt; HTTP2-Settings: AAMAAABkAARAAAAAAAIAAAAA &gt; &lt; HTTP/1.1 200 OK &lt; Server: gunicorn/19.9.0 &lt; Date: Wed, 30 Jun 2021 11:00:10 GMT &lt; Connection: keep-alive &lt; Content-Type: application/json &lt; Content-Length: 304 &lt; Access-Control-Allow-Origin: * &lt; Access-Control-Allow-Credentials: true &lt; { \"args\": {}, \"headers\": {   \"Accept\": \"*/*\",   \"Connection\": \"Upgrade, HTTP2-Settings\",   \"Host\": \"172.31.18.7\",   \"Http2-Settings\": \"AAMAAABkAARAAAAAAAIAAAAA\",   \"Upgrade\": \"h2c\",   \"User-Agent\": \"curl/7.61.1\" }, \"origin\": \"172.31.18.7\", \"url\": \"http://172.31.18.7/get\" } * Connection #0 to host 172.31.18.7 left intact   從 curl 的行為中，可以注意到 --http2 其實是採用基於新增 HTTP/1.1 Upgrade Header 的行為，並且由 Client 發起了 Upgrade: h2c 的 HTTP Header。若 Server 端支援 HTTP/2，一般情況下，將預期返回使用 HTTP 101 (Switching Protocols)，告知 Client 可以使用 HTTP/2 協定互動 [4]。   在與熟悉網路的同事和專家們討論後，提及在 RFC 7540 [5] 文件中定義了發起 HTTP/2 協定的行為和限制：      (A) Negotiating HTTP/2 via a secure connection with TLS and ALPN            (在 TLS 交握的過程中，於 TLS extension (TLS-ALPN) 帶入 “h2”)           (B) Upgrading a plaintext connection to HTTP/2 without prior knowledge            (在明文傳輸中以 HTTP/1.1  傳送 Upgrade Header，表明使用 HTTP/2 傳輸)           (C) Initiating a plaintext HTTP/2 connection with prior knowledge            (直接在明文傳輸環境中發起 HTTP/2 連線)           同時，HTTP/2 的設計中，改進了使用單一個 TCP Connection，並且採用 Binary Framing，將過去 HTTP/1.1 相關包含的 Header 以二進位方式編碼，以作為主要 HTTP 請求的機制：                     HTTP2 in one slide - (source)            所以，截至目前為止，可以確定 Client 端的行為 (curl) 採用 --http2 參數所執行的測試方式，在明文傳輸中，會以 HTTP/1.1  傳送 Upgrade Header，表明使用 HTTP/2 傳輸，並不意味著確定應用程式完全支持 HTTP/2。   Application Load Balancer (ALB) 使用 HTTP/2 的請求行為   接下來讓我們來進一步了解為什麼採用 HTTP/2 之後，Health Check (健康檢查) 會失敗，以及探討 ALB 在使用 HTTP/2 相關的請求機制。在我的環境中，請求行為如下：      在收集相關的封包後，可以確認 Application Load Balancer 在主動發起 Health Check 檢查 HTTP 請求時，會主動使用 (C) 的方法，直接在明文傳輸環境中發起 HTTP/2 連線：                     HTTP/2 Connection Preface            同時，從封包中可以注意到 Application Load Balancer 在建立連線時於連線標頭主動提及的協議版本。這如同在在 RFC 7540 [5] - 3.5 中提及的規範，如果用戶端已經知道目標對象將採用 HTTP/2 版本，在建立連線時，每個連線會採用發起 Connection Preface 以作為連線協議版本。用戶端將需要在發起以 HTTP/2 的連線時，發起以下內容：      The client connection preface starts with a sequence of 24 octets, which in hex notation is:    0x505249202a20485454502f322e300d0a0d0a534d0d0a0d0ao      其 16 進制轉換為以下標頭：   PRI * HTTP/2.0\\r\\n\\r\\nSM\\r\\n\\r\\n\"   比對封包中的內容後 (如同圖：HTTP/2 Connection Preface)，可以確認 Application Load Balancer 進行 Health Check 的行為。   至此，目前可以確定，在 Application Load Balancer 已經得知目標採用 HTTP/2 版本的情況下，將採用第三種方式，即發送 Connection Preface 與目標對象 (這個範例為 172.31.8.7) 建立 HTTP/2 連接，以發送 Health Check (健康檢查) 請求。   解決方案   回到 Client (curl) 提供的對應行為，在 curl 提供的方法中，列舉了以下兩種不同的請求方法 [3]：           --http2 command line option to enable use of HTTP/2.     --http2-prior-knowledge command line option to enable use of HTTP/2 without HTTP/1.1 Upgrade.      如同前面提及，在使用參數 --http2 時 (並非 Prior Knowledge 直接採用 HTTP/2 連線)，若服務器不支持 HTTP/2，根據 RFC 7540 [5]，Client 發送 Upgrade: “h2c” 後，應用程式仍然可以使用 HTTP/1.1 回應。   從 Application Load Balancer 所附帶的方法，我們可以確定其包含 Connection Preface (可用於明文傳輸並基於 Prior Knowledge，以 HTTP/2 直接連線)。   因此，從 curl 提供的 --http2-prior-knowledge，可以間接模擬 Application Load Balancer 執行 Health Check (健康檢查) 的行為。   從我的應用程式測試結果中，可以注意到，我的應用程式其實是無法正確支持使用 HTTP/2 協定的行為，這通常涉及應用程式使用不支援對應 HTTP/2 協議相關的網路函式庫：   $ curl --http2-prior-knowledge 172.31.18.7/get -vvv  *   Trying 172.31.18.7... * TCP_NODELAY set * Connected to 172.31.18.7 (172.31.18.7) port 80 (#0) * Using HTTP2, server supports multi-use * Connection state changed (HTTP/2 confirmed) * Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0 * Send failure: Broken pipe * Failed sending HTTP2 data * nghttp2_session_send() failed: The user callback function failed(-902) * Connection #0 to host 172.31.18.7 left intact curl: (16) Send failure: Broken pipe   不過，nginx 在 1.9.5 版本開始，正式支援 HTTP/2 [6]，因此，為了驗證是否與應用程式設計有關，我在我的環境使用了使用了 nginx 1.12.2，並且於設定檔中啟用了 HTTP/2 module：   bash-4.2# nginx -v nginx version: nginx/1.12.2  bash-4.2# cat /etc/nginx/nginx.conf http {     server {         listen 80 http2 default_server;         listen [::]:80 http2 default_server;         ...     } }   在啟用後，可以從 curl 的測試結果中確認 --http2-prior-knowledge 正確被支援：   $ curl --http2-prior-knowledge http://172.31.18.7 -vvv -I ... * * Using HTTP2, server supports multi-use * * Connection state changed (HTTP/2 confirmed) * * Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0 * * Using Stream ID: 1 (easy handle 0x25d0140) * &gt; HEAD / HTTP/2 * &gt; Host: 172.31.18.7:80 * &gt; User-Agent: curl/7.61.1 * &gt; Accept: */* * &gt; * * Connection state changed (MAX_CONCURRENT_STREAMS == 128)! * &lt; HTTP/2 200 * HTTP/2 200 * &lt; server: nginx/1.12.2 * server: nginx/1.12.2 * &lt; date: Sat, 10 Jul 2021 19:33:24 GMT * date: Sat, 10 Jul 2021 19:33:24 GMT * &lt; content-type: text/html * content-type: text/html * &lt; content-length: 3520 * content-length: 3520 * &lt; last-modified: Wed, 28 Aug 2019 19:52:13 GMT * last-modified: Wed, 28 Aug 2019 19:52:13 GMT * &lt; etag: \"5d66db6d-dc0\" * etag: \"5d66db6d-dc0\" * &lt; accept-ranges: bytes * accept-ranges: bytes * * &lt; * * Connection #0 to host 172.31.18.7 left intact   同時也可以確認應用程式能夠正確通過由 Application Load Balancer 發起的 Health Check 請求：   bash-4.2# tail access.log 172.31.0.26 - - [10/Jul/2021:19:31:14 +0000] \"GET / HTTP/2.0\" 200 3520 \"-\" \"ELB-HealthChecker/2.0\" \"-\" 172.31.31.230 - - [10/Jul/2021:19:31:14 +0000] \"GET / HTTP/2.0\" 200 3520 \"-\" \"ELB-HealthChecker/2.0\" \"-\" 172.31.0.26 - - [10/Jul/2021:19:31:19 +0000] \"GET / HTTP/2.0\" 200 3520 \"-\" \"ELB-HealthChecker/2.0\" \"-\" 172.31.31.230 - - [10/Jul/2021:19:31:19 +0000] \"GET / HTTP/2.0\" 200 3520 \"-\" \"ELB-HealthChecker/2.0\" \"-\" 172.31.0.26 - - [10/Jul/2021:19:31:24 +0000] \"GET / HTTP/2.0\" 200 3520 \"-\" \"ELB-HealthChecker/2.0\" \"-\" ...                     Nginx 使用 HTTP/2 通過 Health Check            至此，可以確定 Health Check (健康檢查) 失敗的主要原因，涉及應用程式本身並未正確設計以回應 HTTP/2 協議的支持。並且，可以從數項測試和實際連線數據封包中具體驗證這項細節。   在修正使用支持的應用程式 (Nginx) 後，Application Load Balancer 中的 Health Check (健康檢查) 指標正確檢測其通過。   總結   在這篇內容中，我與你分享了在 Application Load Balancer 中使用 HTTP/2 相關的請求機制。並且進一步分析了用戶端 (curl) 和 Application Load Balancer 本身的行為，同時列舉了使用 nginx 啟用 HTTP/2 Module 修正的範例設定。   如果你覺得這樣的內容有幫助，可以在底下按個 Like / 留言讓我知道。   References      [1] New – Application Load Balancer Support for End-to-End HTTP/2 and gRPC   [2] httpbin.org   [3] Curl - HTTP/2 with curl   [4] Wiki - HTTP/1.1 Upgrade header   [5] RFC 7540   [6] NGINX Open Source 1.9.5 Released with HTTP/2 Support  ","categories": [],
        "tags": ["aws","amazon web services","EC2","Elastic Compute Cloud","amazon","ELB","ALB","Load Balancer","Elastic Load Balancer","HTTP2"],
        "url": "https://easoncao.com/deep-dive-into-http2-and-aws-alb/",
        "teaser": "https://easoncao.com/assets/images/posts/2021/06/deep-dive-into-http2-and-aws-alb/cover.png"
      },{
        "title": "[AWS] 為 CloudWatch Log Group 自動設定日誌保留期限 (Retention)",
        "excerpt":"日誌 (Log) 儲存一直是在資訊稽核中十分重要的一環，在 AWS 中，提供了 CloudWatch Logs 作為監控、存放不同 AWS 資源輸出的日誌檔案 (例如：EC2 等) [1]。   當使用新版本的 AWS Console 建立 CloudWatch Log Group 時，其預設允許選擇對應的保留期間 (Retention)。然而，若涉及部署和配置的自動化，我將在這篇內容與你分享可用的解決方案。                     於 AWS Console 建立 CloudWatch Log Group 時選擇日誌保留時間 (Retention setting)            問題描述   預設情況下，若你使用的 AWS 服務資源存放日誌的行為 (例如：Amazon ECS、Amazon EKS、CodeBuild … 等)、或是採用 CreateLogGroup API [2] 建立 CloudWatch Log 幫助你存放日誌，很有可能建立出來的 CloudWatch Log Group 日誌的存放時間會是「永遠 (Never Expire)」。   然而，一切事情可能都涉及到費用和運算成本的考量，即使 CloudWatch Log Group 每 GB 的「日誌儲存費用」十分便宜 [3]。但也許隨著組織規模的成長，日誌的儲存規模到達 PB 量級似乎也不是特別遙不可及的事情。伴隨著團隊的增加和規模的擴大，使用 AWS 進行產品遞交的成員也逐漸增加、使用了更多服務、開啟了更多的資源，相對的，可能間接增加了數以萬計的 CloudWatch Log Group。   如果這個時候，當你發現 CloudWatch Log Group 已經超過 100, 000 以上，甚至已經多到 100 頁 AWS Console 都塞不下的時候，你還發現每一個 CloudWatch Log Group 都是 “Never Expire”，經年累月下，可能從公司草創到的 Application Log 都還留在 CloudWatch Log Group 裡面。直到帳單上 CloudWatch Log 的費用又成長到超出預期，勢必得在合規的要求下，為這些日誌儲存期限手動一個一個設定到合乎預期的保留範圍。   於是你開始思考：是否能在 CloudWatch Log Group 被建立好的同時也自動設定對應的保留期限？   解決方案   答案是有的，即使在 CreateLogGroup API [2] 不支持更改保留時間 (Retention Period) 的情況下，仍有幾種方式可以在建立過程中達到類似的需求：   A. 使用 AWS CloudFormation      什麼是 AWS CloudFormation?     AWS CloudFormation 是一個管理工具並且能夠使用通用的語法幫助你描述並且部署 AWS 相關的基礎建設和資源。    如果你很習慣使用 CloudFormation 建立和管理 AWS 資源，你可以選擇使用 AWS::Logs::LogGroup，幫助您建立和管理 CloudWatch Log Group 資源。   該類別提供了對應的屬性 (RetentionInDays) 可以設置 CloudWatch Log Group 預設的日誌保留時間：   RetentionInDays  The number of days to retain the log events in the specified log group. Possible values are: 1, 3, 5, 7, 14, 30, 60, 90, 120, 150, 180, 365, 400, 545, 731, 1827, and 3653.   其 CloudFormation template 在編寫過程中，可以描述如下，以設置 CloudWatch Log Group 資源 (myLogGroup) 預設的日誌保留時間為 7 天：   Resources:   myLogGroup:     Type: AWS::Logs::LogGroup     Properties:       RetentionInDays: 7   B. 選擇使用 PutRetentionPolicy API [4] 幫助修改其屬性   AWS CLI   CloudWatch Log 同時提供了 PutRetentionPolicy API [4] 以幫助你修改特定 CloudWatch Log Group 的日誌保留期限 (Retention)。這意味著，您可以採用 AWS CLI 提供的對應以下命令並且設計你的自定義的腳本 (Shell Script) 定期幫助您更新 (例如使用 CronJob)。   AWS CLI 提供了以下命令 (為 CloudWatch Log Group: my-logs 設定日誌保留時間為 5 天) [5]：   aws logs put-retention-policy --log-group-name my-logs --retention-in-days 5   CloudWatch Event Rule + Lambda   亦或者，你可以基於 CloudWatch Log Group 建立事件，採用 Lambda Function 實現該實作。為了監控相關的事件，通常可以採用 CloudWatch Event 規則 (CloudWatch Event Rule) [6] 以捕捉相關的事件，並且透過其觸發定義的 Lambda Function 執行自定義操作，在這樣的架構下，其可能執行流程如下：                     CloudWatch Event Rule + Lambda 執行流程               (1) 建立 CloudWatch Log Group (使用 CreateLogGroup API)   (2) 觸發 CloudWatch Event Rule   (3) 觸發自定義的 Lambda Function   (4) 於 Lambda Function 中使用 PutRetentionPolicy API 幫助您修改 CloudWatch Log Group 對應的 Retention policy   要實作上述的流程，其需要步驟如下：   1. 建立 IAM Role   不管是自行建立對應的 IAM Role 或是採用 AWS Lambda 建立過程中產生的對象，一般來說，其都需要允許操作 logs:PutRetentionPolicy 的權限，以確保 Lambda Function 在呼叫過程具備足夠的權限操作 CloudWatch Log Group 資源更新，例如：   {     \"Version\": \"2012-10-17\",     \"Statement\": [         {             \"Sid\": \"AllowUpdateLogRetentionPolicy\",             \"Effect\": \"Allow\",             \"Action\": \"logs:PutRetentionPolicy\",             \"Resource\": \"*\"         }     ] }   2. 建立 Lambda Function   建立 Lambda [7] 以確保 CloudWatch Event 在觸發時能夠執行更改對應 CloudWatch Log Group 的日誌保留時間，我使用了簡易的 Python 應用程式碼完成這項工作：   import json import boto3  client = boto3.client('logs')  def getCloudWatchLogGroupName(event):     if 'logGroupName' in event:         return event['logGroupName']     else:         return event['detail']['requestParameters']['logGroupName']   def lambda_handler(event, context):     RetentionDays = 7     CloudWatchLogGroupName = getCloudWatchLogGroupName(event)      print('[DEBUG] Updating Log Group {0}, retention: {1}'.format(CloudWatchLogGroupName, RetentionDays))      response = client.put_retention_policy(         logGroupName=CloudWatchLogGroupName,         retentionInDays=RetentionDays     )      return response   3. 設定 CloudWatch Event Rule      至 CloudWatch Console 並選擇對應的區域，例如: https://ap-northeast-1.console.aws.amazon.com/cloudwatch/home?region=ap-northeast-1#rules:   點擊 Create rule   於 Event Source 選擇 Event Pattern            Service Name: CloudWatch Logs       Event Type: AWS API Call via CloudTrail           選擇 Specific operation(s): CreateLogGroup   例如以下的 CloudWatch Event Rule：   {   \"source\": [     \"aws.logs\"   ],   \"detail-type\": [     \"AWS API Call via CloudTrail\"   ],   \"detail\": {     \"eventSource\": [       \"logs.amazonaws.com\"     ],     \"eventName\": [       \"CreateLogGroup\"     ]   } }   於 Targets 點擊 Add Targets 並且選擇前面 2. 建立的 Lambda Function 以確保其正確觸發。   至此，一旦完成建立上述流程，在建立 CloudWatch Log Group 後，便能正確的觸發 Lambda Function 並且修改 CloudWatch Log Group 對應的 Retention Period。   總結   在這篇內容中，我與你分享為 CloudWatch Log Group 自動設定日誌保留期限 (Retention)。並且進一步分享了一項自動化架構的實現流程，同時列舉了具體細節和範例設定。   如果你覺得這樣的內容有幫助，可以在底下按個 Like / 留言讓我知道。   References      [1] What is Amazon CloudWatch Logs?   [2] CreateLogGroup API   [3] Amazon CloudWatch pricing   [4] PutRetentionPolicy   [5] AWS CLI - aws logs ut-retention-policy   [6] 什麼是 Amazon CloudWatch Events   [7] Create a Lambda function with the console  ","categories": [],
        "tags": ["aws","amazon web services","CloudWatch","CloudWatch Log","amazon","Lambda","Lambda Function"],
        "url": "https://easoncao.com/set-up-cloudwatch-log-group-retention-period-automation/",
        "teaser": "https://easoncao.com/assets/images/posts/2021/07/set-up-cloudwatch-log-group-retention-period-automation/create-cw-log-group.png"
      },{
        "title": "(2021 年底最新) 我是如何通過 CKA - 認證考試及準備 Certified Kubernetes Administrator",
        "excerpt":"由於我實在是太懶了，年初嚷嚷買的考試給他一個拖到快年底，決定請了幾天特休閉關唸書準備，並且花了一個下午完成了線上考試。我在 Linkedin 分享考到 Certified Kubernetes Administrator 之後，我就收到許多私人訊息，甚至有的還問有沒有試題的 dump (真的有點太莫名其奇妙了)。因此簡單透過自己的經驗，跟有想要準備這個認證而在閱讀這篇文章的你分享一下自己的考試過程。                     Become a Certified Kubernetes Administrator            Certified Kubernetes Administrator 是屬於上機類型的考試，也就是會有一定數量的情境題需要在時間內完成，並且需要透過操作實際的 Linux server 設定 Kubernetes Cluster 的一些細節。總結來說，我個人覺得比起工作會遇到的問題，Certified Kubernetes Administrator 上機題目不是說很難且複雜，但也不太容易。   我的做題過程真的是令人緊張，做題階段系統還斷了幾次線，不過，所幸還是在時間內完成所有題目，並且提早十分鐘交卷。出來的成績總分是 89 分 (應該是掉了一題 7 分跟一題 4 分的題目)，因此趁現在還有一些記憶，簡短的透過一個篇幅分享有關考試的細節。   什麼是 Certified Kubernetes Administrator (CKA)   Certified Kubernetes Administrator (簡稱 CKA) 是 Cloud Native Computing Foundation (CNCF) 所提供的一項 Kubernetes 技術認證，是唯一 Kubernetes 官方唯一認可的技術能力評鑑認證，CKA 認證旨在針對考核成為業界的 Kubernetes 管理員所需的技能。   如果企業想要申請 Kubernetes Certified Service Provider (KCSP, Kubernetes 認證服務提供商)，條件之一是至少需要三名員工擁有 CKA 認證。   考試屬於線上形式，並且全程會有監考官透過視訊鏡頭和監控螢幕進行監考，過程中需要透過命令行 (Command Line / CLI) 的形式完成。   什麼是 Cloud Native Computing Foundation (CNCF)                     Cloud Native Computing Foundation (CNCF) - cncf.io            Cloud Native Computing Foundation (CNCF, 雲原生基金會) 的誕生與 Kubernetes v1.0 版本的釋出有關 (2015 年 7 月 21 日)。在 Kubernetes 釋出的同時，Google 與 Linux Foundation 合作組建了 Cloud Native Computing Foundation (CNCF)，並將 Kubernetes 作為種子技術的一部分。   創始過程包含 Google, CoreOS, Mesosphere, Red Hat, Twitter, Huawei, Intel, Cisco, IBM, Docker, Univa, 及 VMware 等各個廠商貢獻及草擬，至今已經有超過 450 個企業和會員支持。CNCF 旨在基於各個廠商之間成為中立的存在，協助專案開源及推廣，以打造 Cloud Native (雲原生技術) 的生態鏈。   CNCF 至今仍致力於 Github 上的快速成長的開源技術的推廣，例如 Kubernetes、Prometheus、Envoy 等，幫助開發人員更快更好的構建出色的產品。   考試基本資料   認證有效期   3 年 (CKA and CKAD  Certifications are valid for 3 years [1])   費用   英文考試為 $375.00 USD、中文版本及中文監考官的的考試是 ¥2088 RMB (含税)。價格可能會隨著時間上漲及浮動，最新的資訊可以參考CNCF 的考試公告頁面以掌握最新動態。   考試地點和應試要求   考試採線上形式，可以是任何地點，但對於考試環境有特定的規範。通常掌握以下原則都不會有太大的問題：      通常是安靜且私人的房間，不可以有其他人於房間內走動，因此咖啡廳等公開場所是不允許的   燈光必須明亮能夠清楚提供照明、視訊監考時能看得清應試者的臉和周圍的環境   視訊鏡頭拍攝應試者背後不可以有窗戶或是強烈的光源 (避免反光)   考試桌面保持整潔，不可以有任何紙張、衛生紙、筆等雜物   乾淨的牆面，視訊鏡頭拍攝的四周牆面不可以有紙張或是海報等標記 (一般裝飾通常不是太大的問題，以監考官判定為主)   考試過程可以喝水，但是水杯必須是透明的不包含任何標籤，液體也需要是透明的水   應試過程應試者的臉必須置於鏡頭中央，並且全程可見   (具體的規範可以參考 [1] - What are the Testing Environment requirements to take the exam? )   測驗語文、形式、題數及時間      考試語言：英文、簡體中文和日文 [1]   考試形式：上機測驗   考試題數：約 17 題 (包含 7 分和 4 分等不同級距的問題)   考試時間：120 分鐘 (Candidates are allowed 2 hours to complete the CKA, CKAD and CKS Exams)   及格分數：66% 分通過 (For the CKA Exam, a score of 66% or above must be earned to pass)   考試報名   我是考英文並且安排英文考官，介面直接透過 The Linux Foundation 的頁面完成購買:      The Linux Foundation - Certification / Certified Kubernetes Administrator (CKA)   完成購買不代表預約考試，買完後還需要透過 Training Portal 並且根據指示跳轉到 PSI 安排考試：      Training Portal   如果是中文考官可以透過 The Linux Foundation 官方中文頁面並且根據指示進行購買：      https://training.linuxfoundation.cn/certificates/1   購買後可以在一年內安排考試，可以在不同時區跟地區應考，如果第一次沒通過，包含考試有一次免費重考的機會 (Free re-take)。   考試實際過程及注意事項   在實際過程中會有幾個重要的注意事項：      不可以用手嗚住嘴巴   考試過程會開啟麥克風聆聽現場的環境聲音。因此做題過程不可以把題目唸出來、碎碎念 (避免有複誦題目獲得答案的嫌疑)   過程中只能開啟瀏覽器並且會共享螢幕、不可以使用任何軟體 (包含筆記本程式)，只能用考試系統於瀏覽器中彈出的 Notepad (用 javascript 彈出來) 進行紀錄   為了要控制作答時間，有時候掃過一遍題目覺得太耗時可以加上標記回頭作答，但標記 (Flag) 作答的功能不會保留 (這意味著在斷線之後再回來不會紀錄)。我自己在這邊有點小被雷到，建議紀錄直接透過系統的 Notepad (這個有斷線實測會保存)   考試過程必須關閉所有應用程式及瀏覽器分頁。雖然是 Open Book，但只能保留一個考試介面和一個允許頁籤用以查看手冊，包含：            https://kubernetes.io/docs/       https://github.com/kubernetes/       https://kubernetes.io/blog/       這包含不同語言的頁面，例如：https://kubernetes.io/zh/docs/home/       參考 What resources am I allowed to access during my exam? [1]           考試開始前   建議在開始前至少 1-2 天請根據考試 Checklist 完成每一項檢查，包含：     姓名與英文 ID 文件相符 (護照)   安裝規定的 Chrome 瀏覽器插件 - Innovative Exams Screensharing (這部分根據考試 Checklist 安裝即可，用於分享電腦的所有螢幕)   確保系統合乎考試環境 (穩定的網路)   有視訊鏡頭、麥克風 (用筆電有內建的就沒什麼問題，只要注意可以在展示護照的時候可以正確對焦驗證身份)   要準備的紙本材料有：     與你註冊英文姓名相同的護照 (Passport) 用以核對身份   可以準備有英文姓名的 Secondary ID 以備用查核身份: 信用卡 / Debit Card / 員工識別證 / 學生證 … etc.   (參考 What are the ID requirements to take the exam? [1])   建議 15 分鐘前進入考試介面，這幾十分鐘是用來檢查環境的。監考官全程會透過 Chat 與你對談 (英文)，監考官可以看得見你，但是你看不見他，並且只透過 Chat 對話。   過程中監考官會要求需要緩慢的旋轉鏡頭以環視四周環境，在我的考試中，監考官還特地我要求我拍攝桌子底下的空間，以確定沒有任何雜物和紙張。   以下是一些工作區域的注意事項：      工作區域和工作桌下的所有物品都要清空   可以使用外接螢幕，桌上僅可以有相關的連接線等。這個在監考官透過鏡頭巡視的時候就會一併檢查。以下是一些範例幫助你了解環境的一些注意事項：                                                                                          違反考試規定的考試環境 (考試環境背後有會反光的窗戶, 桌上有雜物)                         允許的考試環境            在考試檢查環境過程考官會要求你分享所有畫面 (包含外接的螢幕)，考試前記得關閉所有應用程式和清空瀏覽器頁面。   如果是 Mac，會要求你按下 Option + Command + Esc (Escape) 以檢視你是不是有開啟其他程式，如果有，會要求你透過該方法關閉額外的應用程式並且只保留 Chrome。      在考試過程需要注意背後是不是有窗戶會影像到鏡頭反光，並且清除桌上和桌下的雜物。我個人在考試過程中把窗簾拉起來，監考官在檢視過程看過確定沒什麼問題。   考試中   考試過程會主要使用 Chrome 瀏覽器完成考試，會是一個線上的 Shell 介面可以輸入命令完成題目。考試的視窗會像是以下：                     CKA - PSI 實際考試介面 (詳細訊息)            如果中途遇到網路問題斷線了，考試介面會凍結，這時候建議嘗試透過介面的重整按鈕刷新，不行再重新整理頁面。我斷了快三次線，斷線的時候考官會保留考試時間跟 Session / VM (tmux session 也還會在)，並且等一切確認 (正確分享畫面、視訊等) 才重新釋放考試介面，所以不用太緊張。   要注意考試的環境在不同系統中 Copy-Paste 的按鍵不太一樣 (我使用的是 Mac，所以沒什麼差異)：      For Linux: select text for copy and middle button for paste (or both left and right simultaneously if you have no middle button).   For Mac: ⌘+C to copy and ⌘+V to paste.   For Windows: Ctrl+Insert to copy and Shift+Insert to paste.   考試過程會完全分享螢幕，因此要記得只能開啟一個瀏覽器視窗檢視 Kubernetes 文件 (要注意 Kubernetes Forum 是不能瀏覽的)。因為時間有限，建議 yaml 能用 kubectl 產生就用命令產生，文件能複製貼上的就複製貼上。考試環境有提供 tmux，所以我在考試過程斷線的時候十分平滑沒什麼影響，以下是一些 VM 環境中有提供的工具：      kubectl with kalias and Bash autocompletion   jq for YAML/JSON processing   tmux for terminal multiplexing   curl and wget for testing web services   要注意考試環境也不允許透過用 vim 等方式在終端介面瀏覽網站 (包含用 wget 獲取一些三方的資源可能也會觸及到考試規範)。   因為全程監考官看得到你但是你看不到他，所有指示和問題都可以透過系統介面的 Chat 視窗對談 (考官不會回答任何跟考試題目相關的疑問)。   過程中可以透過考試介面的 Exam Control &gt; Request Break (我個人是沒用到，但應該沒記錯) 請求休息去上廁所，但要注意時間會繼續計算。   完成考試   考官通常會於剩下 30 分鐘左右透過 Chat 提醒你，不過，如果你跟我一樣遭遇到系統斷線，考官通常會提醒系統中的計時器截止後仍然還會有剩餘的時間。   如果你提早做完，可以透過考試介面的 Exam Control 提早交卷。考試完成後，成績會於 24 小時內通過 Email 通知。因為是上機考試，部分可能會需要人工審核，我自己等候的時間有點長，等到隔天才有成績。這時候就放輕鬆不用傻傻的一直刷了，36 小時後如果還是沒有收到可以透過 PSI 或是發信詢問有關考試的進度。                     CKA - 考試結果和分數            (考試結果如果有通過，會一併核發認證 ID 並且可以在 Exam Checklist 裡面看到總成績。考試結果不會告訴你錯了哪些題目，不過，我們不求 100 分，有求過就好。)   考試重點及準備   1. 掌握考試大綱   如果你正在準備 Certified Kubernetes Administrator (CKA) 考試，那 Exam Curriculum 絕對是不可以錯過的一項環節。在裡面會定義 CKA 考試於不同 Kubernetes 版本考試項目的權重，並且會隨著時間更新。所以千萬別忘記考前花點時間了解一下考試項目的大綱：      CKA Curriculum   我在 Kubernetes v1.22 開始 troubleshooting 問題的佔比達到 30%，不過對於每天都在做 troubleshooting 工作的我來說，這並不是一個太難的項目 (e.g. CoreDNS(kube-dns) resolution truncation issue on Kubernetes (Amazon EKS))。   但如果你不是擅長 troubleshooting 的問題，推薦必須要試著完成一次 etcd backup 及復原的操作、修復 Node 沒辦法加入 Kubernetes cluster 的問題等，因為我在我的考試中還真的遇到了。   2. 熟悉基本命令   考試過程中不會有 Racher 之類的 UI 介面可以讓你懶人操作，所以推薦熟悉 kubectl 的操作以及 cheat sheet 上一些有趣的用法：      kubectl Cheat Sheet   通常也會需要熟悉一些基本的命令：      Create Pod / Service / PV / PVC / ConfigMap / Secret / deployment … etc   Create service account / RBAC (Role-Based Access Control)   知道怎麼設定 Port / 暴露服務   知道 Kubernetes DNS 解析機制   知道怎麼擴展 Pod 數量 (kubectl scale) / Rolling update   知道怎麼替換、升級和更新節點 (kubectl drain)   查看 container / Pod logs   考試的時候你也可以開啟 kubectl cheat sheet 輔助，就不需要全部記憶。但由於考試過程分秒必爭，我個人覺得 kubectl 工具的 help 輸出說明十分詳細，如果可以的話推薦可以習慣使用 -h/--help 直接拉出具體的用例：   kubectl &lt;ACTION&gt; -h   如果你想了解更多，網路上也有 CKA 相關的資源，這是我覺得不錯的文件：      Core Concepts   網路上也有人推薦說要用 kubectl explain 來檢視用法，說實話我個人完全沒有用到，如果你習慣怎麼在 Kubernetes docs 上查文件，我覺得這個不是必須的項目：   kubectl explain &lt;resource&gt;.&lt;key&gt;   在檢查 service account 類型的問題，另一個額外的技巧是用 kubectl auth can-i 檢查權限：   kubectl auth can-i create deployments --namespace dev      Checking API Access   但如果你喜歡硬派一點也覺得時間很多的話，你可以額外學習 Kubernetes API 的操作和用 curl 直接模擬：   # Point to the internal API server hostname APISERVER=https://kubernetes.default.svc  # Path to ServiceAccount token SERVICEACCOUNT=/var/run/secrets/kubernetes.io/serviceaccount  # Read this Pod's namespace NAMESPACE=$(cat ${SERVICEACCOUNT}/namespace)  # Read the ServiceAccount bearer token TOKEN=$(cat ${SERVICEACCOUNT}/token)  # Reference the internal certificate authority (CA) CACERT=${SERVICEACCOUNT}/ca.crt  # Explore the API with TOKEN curl --cacert ${CACERT} --header \"Authorization: Bearer ${TOKEN}\" -X GET ${APISERVER}/api      Accessing the Kubernetes API from a Pod   Access Clusters Using the Kubernetes API   3. 熟悉使用的技術   我在準備階段花了約 2-3 週看完 A cloud guru 的 CKA 課程並且完成所有的練習題目 (有的比較不熟的完成 2-3 次)：      Certified Kubernetes Administrator (CKA)   基本上題目的範圍都不會偏離考試範圍太遠，只需要熟習及練習做題的速度就可以了，避免在考試答題過程花太多時間一直閱讀文件。很多人都說有空的話可以刷 Kubernetes the hard way，但說實話我自己在準備的過程沒有那麼多時間安排真的去一個一個練習、完成這個額外的工作。考下來我也覺得這也不是一個必須的項目，但如果你熟悉的話，會對 Kubernetes 底層的運作有更深層次的理解。   我個人覺得 killer.sh 的題目特別有用，難度特別高，貼近我自己日常工作會遇到的部分問題，做起來特別有感覺。如果你可以熟悉 killer.sh 的問題並且了解、檢討怎麼作答的話，我認為考試不會有太大的問題，因為考試的難度比這個簡單許多：      killer.sh - Kubernetes Exam Simulator   在 Exam Checklist 上會提供兩次免費的 killer.sh (Kubernetes Exam Simulator) 模擬環境的訪問，所以可以不用先購買。我個人考前 3-4 天才打開來做一次，如果你時間充裕，推薦可以在考前 1-2 週左右打開來練習用好用滿。   4. 熟讀文件   我會推薦除了練習命令和做題，剩下的時間就是熟讀 Kubernetes 官方文件 (https://kubernetes.io/docs)。熟悉文件提供的搜尋功能，可以仔細的閱讀常見的問題並且參考相關的 yaml 文件、描述，並且知道可以用哪些關鍵字把文件調閱出來。   我自己的經驗是這是一個很有效的一個準備方式，在考試過程中可以很快速的透過關鍵字搜尋直接找到我要的答案。如果你習慣透過書籤 (Bookmark) 儲存紀錄，也可以在考試前建立對應的書籤資料夾，在考試過程中於另開的一個分頁中直接從書籤中調閱。   一些基本的使用相關的文件我這邊就不贅述，以下是幾個我在考完後認為值得花點時間閱讀跟時間操作的文件：      Configure a Pod to Use a PersistentVolume for Storage   Upgrading kubeadm clusters   Operating etcd clusters for Kubernetes   Ingress   Network Policies   5. 了解 JSON Path &amp; yaml   kubectl 的 selector 通常可以善用 json path 完成許多工作跟篩選，如果你熟悉這個技巧，在考試的時候，遇到要做排序、或是根據題目要求輸出格式，會非常有幫助。如果有時間，我會推薦可以上完在 kodekloud 上約幾十分鐘的免費課程幫助你建立相關的知識：      JSON PATH Quiz- FREE COURSE   6. 其他   基本上以上幾點如果有過一遍我想要及格不會是太大的問題，剩下的就是平常心及多熟悉 CLI 操作了。   以下是一些我在考試過程中的懶人技巧 (我的考試環境是 Kubernetes v1.22，就我的認知下列的技巧於各個版本中不會有太大的差異，但還是可能要注意是否於後續的版本中仍適用)：   在考試過程設定命令快捷 (用 k 取代 kubectl)   alias k='kubectl' alias kn='kubectl -n kube-system'   列出所有 namespaces 底下的所有資源   alias ka='kubectl get all --all-namespaces'  # 或使用 -A 是一樣的效果 k get all -A   善用 kubectl 產生 yaml 文件、建立資源   考試的作答時間非常緊湊，推薦可以在練習過程熟悉用 --dry-run 直接產生許多不同種類物件的 yaml 描述文件，可以節省許多找文件和複製貼上的時間：   kubectl run &lt;POD_NAME&gt; --image=&lt;IMAGE_NAME&gt; --restart=Never -n &lt;NAMESPACE&gt; kubectl expose &lt;deploymentname&gt; --port=&lt;PORT&gt; --name=&lt;SVC_NAME&gt;   kubectl create &lt;....&gt; --dry-run=client -o yaml   產生 DaemonSet 可以用 Deployment 修改即可：   kubectl create deployment --dry-run=client -o yaml   熟悉基本的 shell script 和複製貼上 yaml 的技巧   我個人覺得善用 cat 讀取標準輸入 (stdin) 的方式非常有用，我在考試的時候用這個方式無痛複製貼上許多 yaml 文件，例如：   cat &lt;&lt; EOF &gt; pod.yml apiVersion: v1 kind: Pod metadata:   name: nginx spec:   containers:   - name: nginx     image: nginx:1.14.2     ports:     - containerPort: 80 EOF   如果會一些 shell script 可以在一些設計執行 command 的階段輕鬆的完成任務，但如果會忘記，推薦可以詳細閱讀 Kubernetes 相關的文件並且知道哪裡可以在考試過程中參考，例如：      Init Containers     initContainers:   - name: init-myservice     image: busybox:1.28     command: ['sh', '-c', \"until nslookup myservice.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo waiting for myservice; sleep 2; done\"]   總結   以上就是有關我個人準備 Certified Kubernetes Administrator 考試的簡略分享。在這篇內容中，我與你分享了有關 Certified Kubernetes Administrator 具體的考試注意事項、考試內容和相關的應試細節。並且具體提出幾個考試重點準備相關的 tips，同時列舉了數項實際學習的建議。   希望在閱讀這篇內容的你可以順利完成認證，並且拿到屬於你的電子證書。如果你覺得這樣的內容有幫助，也別忘了在底下按個 Like / 留言讓我知道。                     Certified Kubernetes Administrator            References     [1] Frequently Asked Questions: CKA and CKAD &amp; CKS   [2] Important Instructions: CKA and CKAD  ","categories": [],
        "tags": ["Kubernetes","certificate","cka","cncf","cloud native"],
        "url": "https://easoncao.com/cka-cncf-certified-kubernetes-administrator-study-guide/",
        "teaser": "https://easoncao.com/assets/images/posts/2021/11/cka-cncf-certified-kubernetes-administrator-study-guide/cover.jpeg"
      },{
        "title": "我常用的自動化理財工具及策略 - 適合理財新手的操作手冊",
        "excerpt":"繼 在 25 歲至少擁有 100 萬 - 5 個適合年輕人的理財建議 所提到的內容，為了幫助你了解有哪些可用的工具及方法，這篇內容我將會與你分享幾個我常用的自動化理財工具及策略，內容將圍繞以台灣銀行和台灣股市為主。                     我常用的自動化理財工具及策略               在這篇文章中你將知道      常用的幾種自動化理財工具   幫助你在理財新手階段了解有哪些可用的工具達成財務目標    釐清自己的財務目標   自動化理財工具最大的目標就是幫助你在獲得收入時，能夠幫助你達成自己所設定的財務目標，並且能夠更輕易的檢視自己的金錢收支。但是要注意工具可能存在陷阱，比如：在嘗試套用新的工具後，反而提高了操作負債的慾望 (例如：採用電子支付後因為付款容易，反而消費上並未有節制)。因此，檢視自己對於未來期待的財務水平及健全規劃自己財務狀況是不可少的環節，包含：      檢視自己有多少收入：薪水、穩定投資收益、利息   檢視自己目前有多少負債或是可能成為的負債：信用卡帳單、每個月固定花銷的費用 (房租、水電、娛樂)、貸款   檢視自己所期待的財務水平 (最簡單的設定方式也可以是希望 N 年內存到多少錢)：可以是 1、3、5 … 年內達到的財務水準   自動轉帳   如果你要存下一筆錢，善用銀行提供的自動轉帳功能和市面上的工具能夠幫助你不知不覺達成你的儲蓄目標。目前有許多銀行和相關的功能可以設定自動轉帳，或是達成類似的機制，例如：      開設銀行子帳戶：台新 (小查罐)、國泰世華   使用定存：台新 Richart 能夠提供每月幫助你存下固定的金額                     執行分離帳戶 - 在 25 歲至少擁有 100 萬 - 5 個適合年輕人的理財建議            一旦你擁有分離帳戶後，便可以根據自己每月不同的消費用途規劃並且執行儲蓄。例如存下緊急備用金、一筆海外旅遊的旅費、教育基金等。以下是我常用的幾種工具。   台新 Richart   Richart 小查罐   台新 Richart App 提供了「小查罐」可以幫助你設定不同的子帳戶。你可以根據不同用途設置，來幫助你完成不同的儲蓄目標。同時也可以隨時調整選擇單次存入或是每月固定存入：                     Richart 小查罐            台新 Richart 仍是台灣數位網銀數一數二 UX 設計十分友善且易用的，如果你對於這樣的功能有興趣，目前台新仍在推出開戶優惠計劃，你可以使用我的以下專屬連結註冊，不但全程線上完成開戶不需要跑銀行，完成開戶後，還可以獲得 100 塊台幣：      點擊這裡申請Richart存款帳戶並首次登入Richart APP成功，就能獲得 NT$ 100 用戶禮   設定外幣通知   台新 Richart 也可以在介面中另外一個十分好用的功能就是外幣，我個人覺得 Richart 提供了十分直覺且易用的介面可以幫助你進行外幣轉換、收匯款以及海外收款及轉帳。可以直接在手機 App 上開設外幣帳戶，並且可以在手機上直接解匯。其中包含了外幣到價通知、外幣提領等功能 (部分外幣可以直接在 ATM 上提領)。                     Richart 外幣到價通知                                                                                                 如果你是屬於在台灣收海外收入的工作者，這是一項十分方便的功能，而不需要一直等銀行電話照會解匯。   (延伸閱讀：台新 Richart 到底能不能轉到 TD Ameritrade (海外轉帳)？答案是 Yes - 3 個步驟開啟 Richart 海外約定轉帳)   國泰世華 Cathy Bank   國泰世華網路銀行子帳戶   除了台新銀行所提供的功能，國泰世華網路銀行 App 也能夠幫助你設置子帳戶：               (點擊這裡下載並申請國泰世華 App 獲得抽獎好禮 - 邀請碼: ETBL9)   除了開設子帳戶，國泰世華的網路銀行也提供了非常多實用的功能，包含整合投資、貸款和信用卡資訊，甚至也同 Richart 利用投資學習演算發幫助你選擇基金投資組合，推出了相應的智能投資產品。   MoneyBook 麻布記帳   MoneyBook 也是我個人慣用的一項工具，能夠幫助我概覽同步所有銀行帳戶、證券等，幫助我了解目前的持有資產和負債等資訊。並且如果你持有多家銀行的信用卡，MoneyBook 可以幫助你定期同步各個信用卡的消費資訊，並且提醒你帳單繳費的時間。                                                                                        Money Book 實際上使用了 Google Cloud Platform (GCP) 作為主要的服務提供商，所以如果你透過 Money Book 登入你的銀行帳戶並且取得唯讀的資產資訊，會在銀行端的登入記錄中發現是由 GCP 的 IP 來源存取，並且有關你帳務的資訊，部分可能會存放在 Google 雲端平台中。MoneyBook 背後除了持續積極跟不同銀行合作，會使用銀行開放的 API 存取之外，一部分會像是爬蟲的機制模擬使用者的登入行為來獲取這些資訊。   並且根據 MoneyBook 的隱私權政策，其在背後會收集許多不同層面的資料，包含：      C. 財務資料及交易資料 依據您使用的服務不同，本公司在您的同意及合於法規情況下，可能取得您在金融機構的帳戶餘額、帳戶金融資訊或其他財務資料。 交易資料亦包括您使用繳費功能所需提供之車牌號碼、流水號、存款帳號、信用卡資訊、電信費帳單、水費帳單、燃料費帳單、停車費帳單等各式帳單及帳單上所載之所有個人資料。 依據所選擇服務內容不同，您可能在不同場景進行金融交易，本公司可能需要取得您的交易資訊以提供特定服務。    關於資訊安全的問題，MoneyBook 提供了許多相關的資源可以幫助你了解關於安全性層面的設計。此外，臺灣所有銀行皆需要 IC 金融卡或 OTP 驗證（如簡訊驗證）才能在網路銀行完成非約定轉帳手續，而約定轉帳功能需臨櫃申辦或使用 OTP 驗證申請，即使擁有網銀帳號密碼也無法轉入任意帳戶。但是，這種系統的設計，可能部分會將你的帳號密碼經過轉換存放在 MoneyBook 的資料庫中。雖然有部分的資訊安全稽核機制，但是如果你仍然對於該 App 存有疑慮，可以選擇根據自己的需求使用。   現金回饋   信用卡   以下是我慣用的信用卡，這些大概是台灣數一數二強的現金回饋信用卡，無腦刷都可以幫助你回饋不少的現金或是為你的消費放大許多效益。       滙豐現金回饋御璽卡      新戶不分國內外享 2.22% 現金回饋!   不限保險公司或險種，刷保費分期享 3.88% 起優惠利率   海外 2.22%, 國內 1.22% 現金回饋無上限   4 種現金回饋使用方式：折抵帳單、兌換電商購物金、換成哩程 …. 等等   點我立即申辦        滙豐匯鑽卡      指定通路筆筆 3% 現金回饋 (現金回饋最高可達 6%)   高回饋合作消費通路：Disney+、Netflix、agoda.com, Booking.com、街口支付、Uber Eats … 等   使用電子/行動帳單終身免年費   點我立即申辦    ShopBack   ShopBack 大概是我知道最強的現金回饋服務，支持許多台灣常用的網購商家，包含博客來、Pchome、家樂福線上購物、UberEats、Booking.com 等等。你不需要改變你原本的消費模式，你只需要在購物前使用 ShopBack 的平台導向到對應的購物網站進行購物，就能享有現金回饋，並且在累積到一定金額後就能提領到銀行帳戶。      點擊這裡使用專屬連結註冊 ShopBack 帳戶並首次消費單筆 $500 元，就能獲得 NT$ 100 用戶禮   同時你也可以透過安裝 ShopBack 提供的瀏覽器插件，只要瀏覽支持現金回饋的網站，就能一鍵啟用，自動享有現金回饋：                     ShopBack 在 Chrome 瀏覽器的插件            而且如果你搭配著信用卡消費享有對應的現金回饋的話，會有二次放大消費回饋的效益。   Rakuten   Rakuten (樂天) 也是十分老牌的平台，類似於 ShopBack，上面支持許多知名品牌幫助你累積現金回饋，例如：Walmart、Dyson、Nike、Target 等等，部分為常見的美國品牌、旅遊項目也包含了 Agoda、Booking.com 等等。      點擊這裡使用專屬連結註冊 Rakuten 消費，就能獲得 USD $30 用戶禮                     Rakuten 現金回饋                              Rakuten 旅遊現金回饋            電子支付   街口支付   街口支付是很類似大陸支付寶的服務，目前在大台北和全台有越來越多開始支持街口支付，包含網路電商 (Pchome、家樂福線上購物等)。街口支付最強的地方就是以虛擬代幣方式給予回饋 (街口幣)，並且能夠折抵下次的消費金額，長期使用下來也是一筆可觀的回饋。                     街口支付            Line Pay   現在台灣主流的通訊軟體大概就是 Line 了，因此 Line Pay 也是一個非常大眾的電子支付工具，同時也有越來越多商家支持使用 Line Pay 支付，你只需要手機有安裝 Line 並且綁定信用卡或是銀行帳戶即可。   我選擇使用 Line Pay 的其中一項原因，就是不偏好使用現金 (歸結消費記錄到信用卡帳單上)。同時有些銀行支持使用 Line Pay 支付的相應現金回饋，如果你日常的商家提供了 Line Pay 作為支付的方式，也是一個不錯的工具，幫助你追蹤每月的消費 (例如：轉角那間常喝的手搖飲料店，知道你到底貢獻了多少錢給飲料店)。   投資      BOS 巴菲特線上學院 - 適合新手的 3 小時投資學習分享會 (線上)   教你用合理的價格買到好公司，並且學會如何用美股每個月賺 2~3% 的現金流   分享會原價 NT $100，透過下方連結報名可免教材費   (每個月還有免費的小課程陪著你繼續學習)   點我免費獲取價值投資課程 課程簡介    定期定額 (國泰證券)   如果你偏好定期定額投資，國泰證券提供了定期定額的功能，並且在每次交易固定額度內提供了超優惠的交易手續費 (1 元)。   這個功能是我目前覺得以券商來說做得不錯的一項功能，並且提供了直覺的操作和庫存檢視頁面。   該定期定額的功能會在交易日前先圈存一筆錢，確定你有足夠的金額才會執行購買，也就是你的帳戶中需要有足夠的款項才會觸發交易。這避免了台股 T+2 交易機制不小心掛錯單 (帳戶沒有足夠的金額仍可以掛單成交，直到交割日才扣款)、或是交易自己買不動的股份造成違約交割導致嚴重的信用損害和後果。   總結   在這篇內容中，我與你分享了我個人常用的自動化理財工具和相應工具使用背後的策略，包含使用不同的工具儲蓄、獲得現金回饋、自動化投資，從中放大現金的效益。   如果你覺得這樣的內容有幫助，可以在底下按個 Like / 留言讓我知道，並且與你週遭的人分享，希望能為同樣有想要實現自動化理財的你，提供一些實踐的參考。   看更多系列文章      學會揭開投資騙局 - 如果你想快速賺大錢，千萬不要去 BOS 巴菲特線上學院   在 25 歲至少擁有 100 萬 - 5 個適合年輕人的理財建議   台新 Richart 到底能不能轉到 TD Ameritrade (海外轉帳)？答案是 Yes - 3 個步驟開啟 Richart 海外約定轉帳   我常用的自動化理財工具及策略 - 適合理財新手的操作手冊   ","categories": [],
        "tags": ["finance","investment","money","personal growth","cash back","投資理財","現金回饋"],
        "url": "https://easoncao.com/money-management-automation/",
        "teaser": "https://easoncao.com/assets/images/posts/2021/12/money-management-automation/cover.jpg"
      },{
        "title": "刻意練習 - 實踐刻意練習的 3 項原則，往專家的道路邁進，我的心得及實作",
        "excerpt":"與其他動物不同之處，也就是人類最大的特點，就是能夠自我精進。我們能有意識地依照個人意願自我改變及提升，正是因為如此，使我們從古至今的其他物種有所差異。如何應用正確的練習方式提升自我，正是「刻意練習」所提到的核心概念。             刻意練習   拜科技所賜，現有世界轉變得越來越快。在兩百前，如果能學會一項技能或是專業，大概就能放心運用所學一輩子：拿學位、找個穩定的工作，然後等退休。   然而，在現今的世代，更尤其是因為疫情衝擊，許多四十年前存在的工作已經消失、並且對於職業的特性已經大不相同。現在踏入職場的人必須擁有在退休前可能會換兩、三次工作的心理準備。   刻意練習一書中運用了豐富的研究實例和系統，歸納出如何有效練習成為專家的途徑。以下我將摘要書籍的內容，並列舉 3 項十分受用的方法。      在這篇文章中你將知道      如果你相信萬事皆可成，並且想知道如何透過正確的「練習」成就你的目標，我會與你分享為什麼你該立即透過 Kindle 或是 博客來 收藏本書   刻意練習和一般練習的差異   實踐刻意練習的 3 項原則，往專家的道路邁進    概覽   也許你多少聽過一萬小時法則，但這本書將為你打破練習時數與表現的關係。      一堆人學鋼琴、小提琴、舞蹈、圍棋、各項運動，為什麼有些人可以有高手級表現，大部分人卻只有「可接受」的水準？多數人相信原因出在天賦，但本書作者安德斯‧艾瑞克森根據三十多年的研究發現，所謂天賦其實是人類大腦和身體的適應力，只要透過正確的練習，亦即「刻意練習」，善用大腦和身體的適應力，每個人都能改善技能，甚至創造出你本來以為自己沒有的能力，達到顛峰表現。    作者 Anders Ericsson 和 Robert Pool，可謂是研究世界專家中的專家 (Expert on Expert)。他們致力於「刻意練習」方面的研究，遺憾的是，Anders Ericsson 在 2020 年死於血栓1，但他留下的研究結晶和著作，我相信仍將於未來數年持續帶來重大的影響。   為了追求關於成就專業成功的課題，並探索其中背後的科學。作者匯總多年的研究及精華，寫入至該本書中。   這本書的其中總結了許多有趣的案例表述「刻意練習」與巔峰表現的關係：      透過記憶長串數字的案例顯示刻意練習與之的關聯   倫敦計程車司機與對於複雜路網快速規劃路徑的能力   下盲棋和西洋棋訓練之間的關係成就大師級水平   更重要的是，我認為這本書真正的目的，就是要打破天才沒有「天賦」這項大眾所誤解的觀念，作者並不認為天賦在專長發展歷程中發揮重要作用，而是背後更為重要的「有質量練習」成就天才。      相信天賦而導致的負面影響：許多教練往往讚美那些較有「天分」的球員，更悉心指導並且提供較多上場比賽的機會。這些球員不僅被教練視為較具天分，其他同儕也如此相信，而且因為常聽到自己球技精進的可能性很大、甚至可能成為職業球員，所以往往更勤於練習。    最後的勝利屬於更努力練習的人，而不屬於一開始靠智力或是其他天賦佔上風者。   對於練習的差異   許多人往往對於練習的迷思是只要我投入大量的時間，一定就能夠有所精進。但無論是開車、打網球或烤派，一旦技能達到這種滿意的程度，動作也成自然，就等於不再精進了。   大家經常誤解這一點，以為繼續開車、打網球或烤派就是在練習，只要一直做便能更上一層樓，也許進步緩慢，但還是會做得越來越好。   一般人會認為有二十年開車經驗的人必定勝過只開了五年車的，執業二十年的醫生當然強過僅行醫五年的，教書教了二十年的老師也一定比只有五年教書經歷的更專業。   但在書中用醫生的職業作為範例，提及很可能開業多年的醫生，因為長期套用已知的認知框架在解決問題、甚至不再像醫學院的學生持續參與學術研討，有時候很可能比仍在醫學院的學生更容易陷入「因資歷而更顯專業」的謬誤中。   針對許多專家進行的研究顯示，執業二、三十年之久的醫生在某些客觀表現上還不如剛畢業兩、三年的同行，原因出在醫生每天行醫做的大多數事情都無法改進、甚至維持他們的能力，幾乎沒有挑戰，也沒有將他們推出舒適圈。   之所以會有這樣的差異，書中提及了部分練習方式所帶來的研究以佐證其發現：   天真練習法      老師：你的練習單上寫著每天練習一小時，彈奏測驗的結果卻只有Ｃ。有什麼原因嗎？   學生：我也不知道怎麼會這樣！昨天晚上彈都沒有問題。   老師：彈了幾次呢？   學生：十次或二十次。   老師：有幾次完全沒彈錯？   學生：嗯，不知道耶……一、兩次吧……   老師：這樣啊……你怎麼練習的？   學生：不知道，就彈啊。   目標練習法   目標練習法要求跨出舒適圈。這也許是目標練習法最重要的部分。若不在練習中超越熟悉、應付自如的事，其反而顯出練習上的散漫，只想做那些做起來已經很不費力的事，如此絕對效果不彰。   目標練習法最大的差異就是對於練習有定義明確的具體目標。上述例子中的音樂學生若設定以下這類練習目標，成效會亮眼許多，例如：      「以適當的速度將曲子毫無錯誤地從頭彈到尾，連續彈三次。」   更指出相應的研究發現，創造力其實和下苦功長時間維持專注的能力相輔相成。正是如此，造就專家級能力刻意練習的必備要素。(例如：諾貝爾獎得主往往比大多數同儕更早開始發表學術文章、生涯中發表的文章量也遠多於同行)   更重要的是，目標練習法需要意見回饋。知道自己是否下對功夫很重要，若用錯方法，也得明白錯在哪裡。   實踐刻意練習的 3 項原則   任何練習都有這條基本鐵律：不走出舒適圈，就不可能進步。業餘鋼琴家於青少年時期上過五、六年鋼琴課，若過去三十年來都以同樣的方式重複彈奏同樣那些樂曲，儘管累積了上萬個「練習時數」，卻無法比三十年前彈得更出色，甚至可能表現更差。   但這也意味著，任何的技能應用刻意練習都能夠達到更出色的水平。在 2013 年 Josh Kaufman 在 TED Talk 提出的應用 20 小時學習任何東西 (The first 20 hours – how to learn anything)，同樣也引用了 Anders Ericsson 理論，並且實踐在從新手學習烏克麗麗 (Ukulele) 的技巧中：               順帶一提，演講裡面提到由 The Axis Of Awesome 著作的歌曲 4 Chords song 也是我個人當時聽到覺得很有趣且節奏讓人喜歡的一首歌：               以下總結從書中和前面提及的 Ted Talk 所帶來刻意練習的核心關鍵：   1. 拆解學習的任務 (Deconstruct the skill)   自古以來，具有創造力、不願原地踏步、充滿動力的人對於現況不滿，因而設法尋求進步及創新。但在邁向頂尖的路上，這其中並沒有大耀進。外人之所以覺得進步神速，是因為不瞭解這是由無數個小步所組成。   作者於書中提到，就連所謂的「頓悟」時刻，也必須先有大量努力堆砌，成為高塔，才有可能發現使傑作完美的最後一塊磚頭。因此學習拆解學習的任務將有助於建立起對於技能的學習工作：      從記憶 10 個數字逐漸提高到記憶 100 個數字   漸進式增加彈奏的難度 (例如：從完整彈奏一個小節到以適當的速度將曲子毫無錯誤地從頭彈到尾)   這就像是為每個學習目標設定對應的 Milestone，將每個小的練習工作最終拼揍成為完整的認知模式，如同習慣帶來的複利效應。                     習慣帶來的複利效應            (延伸閱讀：原子習慣：細微改變帶來巨大成就的實證法則 - 我的心得及實作)   2. 建立心智表徵並且自我激勵及校正 (Learn enough to self-correct)   書中大量提到心智表徵一詞，其中部分呼應了腦神經科學的知識 (我個人認為這有部分類似呼應 Learning how to learn2 提到建立腦部的知識區塊 chunking 類似的概念)，也是整本書中提及凸顯刻意練習十分重要的一項關鍵。   心智表徵是什麼   心智表徵是一種心智結構，你可以想像是你對於事物理解的直接認知、直覺，像是你的大腦已經建立對於某種事情的認知迴路。   例如，你可以看到「貓」就能理解這是一隻貓，這意味著你的大腦已經建立對這項生物的認知。   然而，受過訓練的專業人士 (例如獸醫師) 可能更進一步可以區分貓的品種：米克斯、短毛、硬毛、波斯貓等等。由於對於不同品種的認知記憶於大腦中成為了強健且穩固的知識迴路，使得一眼看到時，不需要再重新思考及學習。   一旦建立起基礎的心智表徵後，便能執行自我激勵和校正的工作，例如：棋士能夠透過充分的獨自練習，在每個自我對弈的過程中利用有目標的練習方式，從舊有已知的心智表徵中重新建立更為鞏固的模式，讓棋藝的心智表徵變得更為實用。   另一個例子像是學習樂器，以吉他為例，也許一開始連按下和弦、握琴和記憶不同和弦的能力都有困難，但是經過長久的訓練，各個和弦逐漸組成心智結構，並且於你的大腦迴路中鞏固。使你你不需要再思考每個和弦要按在哪幾條弦。   應用心智表徵的例子充斥在生活周遭，然而，若你是身為某個領域的專業人士，可以總結在專業方面心智表徵的發展更為全面。   在練習初期，由於心智表徵尚未建立完全，往往因為無法進行「有目標的練習」，其質量並不無法有效提升。因此，這時候通常會需要執行「監控式的練習」並且獲得反饋，常見的方式是透過有經驗的導師引導，或是邀請興趣相同的人共組團體、加入現有的社團，將有助於你建立起更為全面的心智表徵。   老師的重要任務之一，是協助學生發展個人的心智表徵，才能針對表現自我監控和修正。好老師也應該具備在該領域的教學能力和經驗。   許多成就非凡的人卻是個糟糕的老師，原因是因為對於教學毫無概念，因為自己做得到，不代表有能力教導他人如何做到。如果你發現有一天自己進步的速度變慢、甚至毫無進步，請放寬心尋找新老師，畢竟，持續向前進才是重點。   一旦掌握基礎的模式後，再自行刻意練習的工作上便能更有效的執行自我激勵和修正。如果是獨自練習，就得靠自身的心智表徵監控表現，判斷是否出錯。尤其在練習了一陣子並且看見成果後，技能本身就可能成為動機的一部分，使你自豪並且激勵自己繼續往下練習。   3. 移除練習的心理障礙 (Remove practice barriesrs) 和保持練習的習慣   往往我們在接觸一項新技能或是在練習階段進入到高原期 (技巧沒有突破)，覺得自己很笨。沒有人會喜歡感受到當笨蛋的感覺，但歸咎這些，其實往往造成學習障礙或是無法突破的並不是外在因素，而是心理因素。   有幾項技巧能夠幫助移除練習的心理障礙，例如：      開始學著專注練習的人往往無法維持數小時的注意力，因此，一開始可以將練習時間設定得比較短，然後逐漸拉長。例如參考前面提到的 Ted Talk，相信自己先學習至少 20 個小時，將會帶來成效   當你不再相信自己能達成目標時，請先不要放棄，先和自己約定好，等到重回先前的水準後再說，到時大概就會繼續下去了   刻意練習的關鍵動機因素是相信自己能成功   告訴自己每天至少只要練一小時全神貫注練習，找到持續的理由   降低及減少干擾訓練的因素 (例如：如果因為手機分心，就關機、放到另一個房間)   書中也提到專家們在進入學習階段時，同時也在自己專攻的技能上得到自我認同，便會開始將在特定的領域中投入大量的專攻，甚至多於社交生活、學校等領域。並且在幾年後將自己視為「鋼琴家」、「游泳選手」、甚至有的相信自己會成為「數學家」，也就是在這個階段開始對專攻的技能認真。   這歸結一個很有趣的現象，雖然這些學習完全源自自我選擇的過程，但往往願意投注數年練習某件事情的人更自然會樂在其中、甚至於練習中逐漸帶來生理上的適應。   但如果你問這些專家他們是否喜歡這些練習，卻反映了違反直覺的答案：許多專家根本不喜歡這些練習，並且不見得感到好玩，做其他事情還比較開心。但是凸顯專家之所以成為專家的，反而是不顧過程的無聊和其他更有趣活動的吸引力，並且仍可以持續投入學習之中的優越能力。   更重要的一點，希望刻意練習能生效，就必須逼迫自己離開舒適圈，並維持專注力。頂尖專家有兩個習慣雖然看似和動機無關，但是卻起到關鍵作用：     照顧身體：睡眠充足、保持身體健康。因為人在疲憊或生病時往往較難維持專注力，並且容易懈怠   將練習時間控制在大約一小時：人無法全神貫注超過一小時太多，訓練初期能集中注意力的時間可能更短   因此，我想刻意練習最為困難移除自己的心理、情緒中的障礙，藉由覺察這些現象，將有助於我們更為認知刻意練習經歷這樣過程其中的必要性。   案例學習：富蘭克林 (Benjamin Franklin) 的練習寫作過程   書中提到了一個我很喜歡刻意練習的例子，以富蘭克林練習寫作的過程為借鏡。   富蘭克林為了提升自己的寫作能力，他以 旁觀者 (The Spectator) 作家們所貢獻的著作作為主要的學習範本。初期他在閱讀部分文章後，嘗試忘掉某篇文章確切的用字遣詞，並請盡可能重現文章中的字句。   在針對自己欣賞的寫作風格挑出文章後，同時透過簡短的筆記紀錄下句子的內容，以提醒自己這些句子的重點。幾天後，他試著根據寫下的提示重現文章，目的不在於精準、一字不漏的複製原文，而是希望自己所寫的文章能像範本那樣具有洞悉且充滿文采。      但透過這些練習讓富蘭克林發現，最大的問題在於自己的字彙量遠遠不及《旁觀者》作家群。雖然認識這些字，下筆時就是寫出不來。為了解決這個問題，他稍加改變第一個練習。他認為寫詩必須根據詩的節奏和韻式用字，會迫使自己運用許多平時不會想到的字，所以將《旁觀者》中的一些文章轉為詩；等到對原文字句的記憶變得模糊之後，又將詩轉回散文。這讓他培養出尋找合適文字的習慣，並增加可以立刻從記憶中喚起的字彙量。    最後，富蘭克林要加強的是他寫作的整體結構和邏輯。他一樣利用《旁觀者》的文章，寫下每個句子的提示，不過這回是將提示寫在不同的紙上，打亂原來的次序隨意排列。等到自己不僅忘了原文的用字遣詞，也忘了句子的順序，便開始仿作。他首先依照自己認為最有邏輯的順序安排那些混亂的提示紙條，接著根據每個提示寫出句子，最後參考原文比較結果。這個練習強迫他在寫作時謹慎組織思緒，一旦發現思緒整理得不及原文作者，便會修改自己的作品，並從錯誤中學習。   這項例子充分的表述了刻意練習的幾個階段：      找出進步停滯的原因   犯了哪些錯、何時做錯的？迫使自己離開舒適圈以觀察哪個問題先顯露出來，並且透過反饋機制校正   以改善那個弱點設計有目標性的練習方法   重複的目的在於發現自己的弱點，並且聚焦於加強弱點，嘗試以不同的方式改善，直到找出最佳策略為止。   其他應用的範例   專注與投入至關重要，即使每回的訓練時間較短，但只要目標較清楚，反而是更快培養出新技能的最佳方法。   學習英文   透過英文電影，反覆觀看有字幕的版本，接著關掉字幕，試著理解台詞。如果想知道自己理解是否正確，則再開啟字幕。   因為再三反覆聽著同樣的對話，有助於提升英文的理解能力，比起單純看好幾部的電影來說，學習上更為有效率。   我的實作心得   最後，我想與在閱讀本篇文章的你分享自己應用刻意練習所提到的理論在我的吉他練習上。   我的吉他並不是那麼突出，而且可以說是一個音癡。過去也只會彈簡單的和弦歌曲 (例如：五月天的擁抱)。在後來認知到學習必須循序漸進後，我在學習一首較為複雜的歌曲分為了以下幾個階段：   1. 練習好節拍和曲目和弦組成   在初期我發現自己的節拍真的是亂七八糟，毫無節奏性可言。我發現這同時影響到我學習任何音樂的過程，因此我花了一些時間開始研究：      重新檢視基礎樂理和爬格子   如何打好節拍   如何正確地打節拍   這首歌的節拍是什麼   在這幾週我的工作就是努力把節拍打好，並且在網路上找相關的資源進行研究。拋棄想著要開始彈歌曲的想法，專注在練習如何把節拍打好，熟悉每一個小節的節奏，讓演奏歌曲時遵循韻律。               2. 學習按好 F 和弦 (封閉和弦)   很快的我發現 F 和弦 (封閉和弦) 是我彈奏上最大的障礙，因此接下來幾天我的任務就是專注在練習 F 和弦      從 G 和弦快速的切換到 F 和弦   從 C 和弦快速的切換到 F 和弦   大約每天彈了半小時，用了至少一週才按得好聽一些。               循序學習每個小節的刷弦方法   在稍微熟悉和弦後，我發現自己的刷弦聽起來非常的生硬且很難聽，因此接下來幾天，即使會練習整首歌曲，我同時開始專注在：      如何正確的刷弦   怎麼樣刷弦才好聽   並且持續的在和弦轉換間重複進行練習，以提高轉換的流暢度：               綜上所述   以上就是我自己應用的過程，經歷了約 4-6 週、1 個月左右的時間。雖然老實說有時候練習過程仍不免因為各種理由斷斷續續的，但希望能給在閱讀的你，看完之後能開始相信任何技能皆可以透過刻意練習來幫助你有效的提升到更進一層次的境界：               總結   刻意練習需要有定義清楚明確的目標，涉及改進想要達到的表現、或是改善某個面向的弱點 (不能設定模糊的整體改善目標)。並且只有在跨出舒適圈後才能奏效，需要不斷嘗試突破現階段的技能水準。這意味著幾乎得傾盡全力，過程往往不會太有樂趣。   因此，也本書提及了許多活生生的案例，以幫助讀者了解長期刻意練習和頂尖高手之間的關聯性。並且提出許多實務上的例子，學習實踐刻意練習的原則，並指出許多實際案例。我個人認為搭配 原子習慣3 中所提及的原則並應用習慣建立系統，持續的實踐刻意練習，將能同時為你累積習慣的複利效應。   由於細節眾多，並且囊括作者多年研究的精華，無法一一列舉。如果你也期待自已能在自己的領域中成為頂尖，並想學習更多具體刻意練習的方法，你可以透過下列連結取得相關的電子、實體書籍版本直接收藏至你的書單：                                                                                                                       刻意練習: 原創者全面解析，比天賦更關鍵的學習法 (Kindle)                                                    Kindle 數位版售價 $7.99 優惠連結                                                   獲取優惠                                                                                                                                                    刻意練習：原創者全面解析，比天賦更關鍵的學習法 (博客來)                                                    博客來 79 折優惠連結                                                   獲取優惠                                        看更多系列文章      沈默並不代表軟弱：內向的你必須看的一本書 - 安靜的力量 Quiet Power: The Secret Strengths of Introverts   3 項原則讓你變得更有生產力 - 最有生產力的一年 The Productivity Project   原子習慣：細微改變帶來巨大成就的實證法則 - 我的心得及實作   刻意練習 - 實踐刻意練習的 3 項原則，往專家的道路邁進，我的心得及實作   References                  The New York Times - Anders Ericsson, Psychologist and ‘Expert on Experts,’ Dies at 72 &#8617;                  Barbara Oakley, Dr. Terrence Sejnowski - Learning How to Learn &#8617;                  原子習慣：細微改變帶來巨大成就的實證法則 - 我的心得及實作 &#8617;           ","categories": [],
        "tags": ["book","personal growth","reading","productivity","work","kindle","amazon","自我成長"],
        "url": "https://easoncao.com/peak-deliberate-practice-reading-feedback/",
        "teaser": "https://easoncao.com/assets/images/posts/2021/12/peak-deliberate-practice-reading-feedback/book-cover.jpeg"
      },{
        "title": "沒有時間跟硬碟容量備份？3 個步驟不用下載檔案從 Google Drive 直接備份到 Dropbox",
        "excerpt":"   Google Drive 教育帳號即將取消無上限儲存空間政策，你還在努力的下載檔案轉移備份嗎？如果你正在尋找非手動檔案搬家的解決方式，這篇內容我將會與你分享簡單的步驟，幫助你不必從 Google Drive 下載檔案，並將檔案轉移備份。                      3 個步驟不用下載檔案從 Google Drive 直接備份到 Dropbox            Google Drive 儲存空間政策異動   Google Workspace for Education 公告了即將採用全新儲存空間政策，並且於 2022 年 7 月生效，全教育機構僅可共用 100TB。邁進 2022 年，免費版的 Google Drive 帳號又只能存放 15 GB 的資料，可能正在閱讀這篇內容的你正在煩惱如何有效率的將資料轉移至其他雲端儲存，畢竟假如直接透過 Google Drive 網頁版下載後上傳，會花非常多時間以及電腦的本機容量。   如果你正在尋找非手動檔案搬家的解決方式，這篇內容我將會與你分享一些簡單的步驟，幫助你不必從 Google Drive 下載檔案，並將檔案轉移備份。    在這篇文章中你將知道      了解不用下載檔案從 Google Drive 直接備份到 Dropbox 的另一個方法 (點擊這裡以新用戶身份註冊 Dropbox 立即取得免費的額外空間)   學習應用 Dropbox SDK for Python 的功能轉移檔案和了解相關範例的演示   了解可能的使用限制    概覽   為了達到不必從 Google Drive 下載檔案，並將檔案轉移備份的目的，這個步驟分為幾個階段：      擁有其他雲端儲存空間的帳戶   設置 Google Colab   無需下載，使用對應支持的 SDK 直接上傳搬移檔案   Google Colaboratory (Google Colab)   Google Colab - Colaboratory 簡稱“Colab”，是 Google Research 團隊開發的一款產品。使用 Colab 可以通過瀏覽器直接編寫和執行任意 Python 代碼。常被用來適合機器學習、數據分析和教育目的。   從技術上說，Colab 是一種託管式 Jupyter 筆記本服務。用戶無需進行設置，就可以直接使用。   簡而言之，Google Colab 提供了可用的運算資源，因此，在這個工作的執行階段，本篇內容將透過 Colab 所提供的功能協助檔案轉移的工作。   使用限制   Colab 的資源使用並沒有保證一定的 CPU、Memory 資源量，但對於這項用應用於遷移的工作上能更簡單地完成這項工作。唯獨要注意的是，一個 Colab 的虛擬執行環境最多執行到 12 小時。   執行步驟   Step 1: 擁有一個 Dropbox 帳號   因為 Dropbox 提供的 Python SDK 相對友善許多，因此這篇內容以 Dropbox 遷移的過程。首先，你會需要一個 Dropbox 帳號。    現在新用戶註冊 Dropbox 立即取得免費的額外空間      點我立即取得額外的儲存空間    Step 2: 在 Dropbox App Console 新增設定 Application 獲取可用的應用程式憑證   為了使用 Dropbox API，你同時會需要設定一個可用的 Application 允許授權存取你 Dropbox 中的資料，並且賦予必要的權限。可以透過以下連結訪問 Dropbox App Console：      Dropbox App Console   點擊 “Create App” 並且輸入必要資訊：                     Dropbox App Console                              建立 Dropbox App               Choose the type of access you need: 可以選擇只允許訪問特定的 App Folder 或是 Full dropbox。因為我們要用來搬家，所以這裡選擇 Full dropbox。   Name: 應用程式的唯一識別名稱，不能與其他使用者重複，如果已經被註冊系統會提示。   如此一來你就可以獲得一個可用的應用了，預設情況下，你可以透過 “Generate Access Token” 的按鈕取得臨時性的憑證，並且可以在 Dropbox Python 程式碼中，使用 SDK 提供的方法帶入產生的 access token 初始化 Dropbox 用戶端：   dbx = dropbox.Dropbox('YOUR_ACCESS_TOKEN')   由於憑證預設是 4 小時到期，到期後會需要重新產生。因此，如果需要的執行時間長一點，可以在 “Access token expiration” 選擇 “No expiration”。   (但請注意不要把這組憑證外流，否則可能其他人都能任意存取甚至修改你 Dropbox 中的資料)                     產生存取憑證 (Access token)            權限設定   由於在設計 Python 上傳檔案的應用中，操作中包含了檔案操作的行為，因此，別忘記到 “Permissions” 頁面中選擇需要的檔案寫入的權限 (files.content.write)：                     設定必要的檔案寫入權限            如果沒有設定，很可能會在執行上傳相關的方法 (files_upload(), upload_session) 可能會遭遇到以下的錯誤訊息：   BadInputError: BadInputError('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'Error in call to API function \"files/upload_session/start\": Your app is not permitted to access this endpoint because it does not have the required scope \\'files.content.write\\'. The owner of the app can enable the scope for the app using the Permissions tab on the App Console.')   Step 3: 建立 Google Colaboratory 並且在 CoLab 執行環境中使用 DropBox Python SDK 轉移資料   下一步就是可以直接在目標的 Google Drive 帳號中運行 Colab 環境。CoLab 支持掛載 Google Drive 在執行環境中當成本地端硬碟直接使用，透過這種方式能夠直接在 CoLab 環境中指定要執行備份的目錄工作。   透過在要轉移的 Google Drive 中新增一個 Google Colaboratory 的應用選項，可以直接啟用一個執行環境：                     新增 Google Colab 應用            如果沒有看到 Colab 選項的話，可以透過連結更多應用的選項安裝 Google Colaboratory：                     在 Google Drive 連結更多應用                              在 Google Drive 安裝 Google Colaboratory            接下來就可以直接透過 Colab 掛載 Google Drive：   from google.colab import drive drive.mount('/gdrive')   同時也能透過 PyPi 安裝 Dropbox SDK：   !pip install dropbox   https://gist.github.com/Keshava11/d14db1e22765e8de2670b8976f3c7efb   點擊運行就能將 Google Drive 掛載 (/gdrive/MyDrive)：                     在 Colab 掛載 Google Drive            掛載後就能透過 Dropbox 提供的 API 直接執行檔案上傳，並且透過 Colaboratory 的執行環境可以跑在雲端的背景中執行，最簡單的方式是使用 [files_upload()]1 方法直接上傳：      files_upload(f, path, mode=WriteMode(u’add’, None), autorename=False, client_modified=None, mute=False, property_groups=None, strict_conflict=False)    如此一來，完全不需要下載檔案並且將檔案從 Google Drive 搬家到 Dropbox。                     執行範例            Dropbox 提供的 Python 操作十分直覺，但唯一要注意的是，如果單檔大於 150 MB，就不太適用 files_upload() 直接上傳。會需要根據檔案大小建立上傳的 session 以解決這項問題。    如果你有興趣想了解實作的內容   你可以透過以下的方法填入自定義的金額 Buy Me A Coffee                  一次性支持 (ECPay)       你會獲得贈送的簡單範例程式並且寄送到你的 Email，了解如何直接上傳整個目錄底下的資源，並幫助你快速的瞭解如何使用     總結   在這篇內容中，我與你分享了非手動檔案搬家的解決方式。在這篇內容中，提幾了幾個簡單的步驟，幫助你不必從 Google Drive 下載檔案，並將檔案轉移備份。並且使用 Google Colaboratory 執行 Dropbox 遷移作為範例。   如果你覺得這樣的內容有幫助，可以在底下按個 Like / 留言讓我知道。   References      Dropbox for Python   Data transport limit                 files_upload() &#8617;           ","categories": [],
        "tags": ["google","dropbox","python"],
        "url": "https://easoncao.com/moving-files-from-google-drive-to-dropbox-hack/",
        "teaser": "https://easoncao.com/assets/images/posts/2022/01/moving-files-from-google-drive-to-dropbox-hack/cover.png"
      },{
        "title": "3 個步驟不用下載檔案從 Google Drive 直接備份到 Amazon S3",
        "excerpt":"繼上篇分享搬家到 Dropbox 的步驟，幫助你不必從 Google Drive 下載檔案，並將檔案轉移備份。這則內容將使用 Amazon S3 作為主要的範例。由於 Google Drive 教育帳號即將取消無上限儲存空間政策，你還在努力的下載檔案轉移備份嗎？如果你正在尋找非手動檔案搬家的解決方式，這篇內容我將會與你分享簡單的步驟，幫助你不必從 Google Drive 下載檔案，並將檔案轉移備份。                     3 個步驟不用下載檔案從 Google Drive 直接備份到 Amazon S3             在這篇文章中你將知道      了解不用下載檔案從 Google Drive 直接備份到 Amazon S3 的另一個方法   學習應用 AWS SDK for Python 的功能轉移檔案和了解相關範例的演示   了解其他的應用    概覽   為了達到不必從 Google Drive 下載檔案，並將檔案轉移備份的目的，這個步驟分為幾個階段：      擁有其他雲端儲存空間的帳戶   設置 Google Colab   無需下載，使用對應支持的 AWS SDK 直接上傳搬移檔案   在上篇內容中，提到了使用 Dropbox 作為主要的範例，如果你在尋找 Dropbox 相關的細節，有興趣可以參考上篇的內容以獲得更多資訊。在這則內容終將圍繞 AWS 作為主要的環境。   Google Colaboratory (Google Colab)   Google Colab - Colaboratory 簡稱“Colab”，是 Google Research 團隊開發的一款產品。使用 Colab 可以通過瀏覽器直接編寫和執行任意 Python 代碼。常被用來適合機器學習、數據分析和教育目的。   從技術上說，Colab 是一種託管式 Jupyter 筆記本服務。用戶無需進行設置，就可以直接使用。   簡而言之，Google Colab 提供了可用的運算資源，因此，在這個工作的執行階段，本篇內容將透過 Colab 所提供的功能協助檔案轉移的工作。   使用限制   Colab 的資源使用並沒有保證一定的 CPU、Memory 資源量，但對於這項用應用於遷移的工作上能更簡單地完成這項工作。唯獨要注意的是，一個 Colab 的虛擬執行環境最多執行到 12 小時。   Amazon S3 (Simple Storage Service)   Amazon Simple Storage Service (Amazon S3) 是 Amazon Web Service 提供的資料儲存服務，基本上你可以把它視為一種雲端儲存的解決方案。最大的特點就是 S3 沒有放置容量的上限，費用則會依照你的儲存容量和儲存的資料選用計費 - 也就是你放多少資料，就收多少錢。如果對於 Amazon S3 的定價想了解更多，可以參考以下頁面及工具試算：      Amazon S3 定價   AWS Pricing Calculator - 費用試算   S3 服務將資料存放在名為 Bucket 的對象中，可以想像就是一個獨立的硬碟，並且可以選擇不同的區域。   用戶可以選擇離自己地理位置區域較近的資料中心建立這個資源，一個 AWS 用戶可以建立多個 S3 Bucket 儲存資料。   執行步驟   Step 1: 擁有一個 AWS 帳號   一切的前提是你要先有一個 AWS 帳戶 能夠操作 AWS 資源。   Step 2: 建立 S3 Bucket 並且設定 IAM User 並且賦予必要的權限   接下來你就可以透過訪問 S3 Console 建立 Amazon S3 bucket，一旦擁有帳號並且開通後，可以透過以下連結訪問 Amazon S3 Console：      S3 Management Console   點擊 Create Bucket 可以進行 S3 Bucket 的建立操作：                     S3 主控台介面            輸入預期的 S3 Bucket 名稱 (命名為唯一識別的名稱，不可與其他使用者重複) 和區域：                     建立 S3 Bucket               根據我的測試，Google Colaboratory 似乎會選擇在執行環境中選擇離你較近的機房作為執行環境的首要選擇。為了提高檔案從 Google Drive 傳輸到 Amazon S3 搬家的效率，建議選擇離自己地理位置近的地方建立 S3 Bucket，也許能降低一部分的傳輸延遲。     如果是亞洲地區的用戶通常是日本東京 (ap-northeast-1)、新加坡 (ap-southeast-1) 或是澳洲 (ap-southeast-2)    一旦建立好 S3 Bucket 之後，基本上你就可以透過網頁介面上傳檔案了。                     在 S3 主控台介面中可以直接上傳檔案            但為了實現我們無需下載檔案搬遷的目標，我們需要透過程式化的方式來運作上傳的邏輯，如此一來，才能在 Google Colab 中運行我們的應用執行相關的操作。   因此，在接下來的步驟中，我們將透過建立一個可供 Python 程式應用的使用者憑證，其中透過 IAM User 的方式設定以賦予必要的權限。   IAM (Identity Access Management) 是一個 AWS 整合的主要服務，可以想像是作業系統的權限控制方法，讓您能夠安全地控制對 AWS 資源的存取，IAM 能夠控制每個用戶存取不同 AWS 資源的各種權限。   建立 IAM User   要建立 IAM User，可以透過在上方搜尋列尋找 IAM 連結到對應的服務主控台頁面：                     IAM Console            點擊 “Add IAM User” 進入建立 IAM User 的步驟並且輸入必要資訊：                     新增 IAM User                              輸入 IAM User 名稱和類型               User name: IAM User 的唯一識別名稱，可以自行命名，不能與其他使用者重複   Select AWS Credential type: 為了要用於 Python 應用程式操作的憑證，這裡選擇 Access Key，用於產生純文字類型的憑證   (但請注意不要把這組憑證外流，比如放到 GitHub，否則可能其他人都能任意存取甚至修改你 AWS 資源的資料)   權限設定   下一步就是選擇這個 IAM Policy，用於限制這個 IAM User 到底只能操作、存取哪些 AWS 資源和類型 (例如：是僅可讀，還是也包含寫入？)。預設情況下，IAM User 不指定任何 IAM Policy 等於沒有任何權限操作資源。   如果要賦予操作 S3 Bucket 的權限，最簡單的方式是使用預先定義好的 AmazonS3FullAccess 策略，這個策略會開放 IAM User 操作整個 AWS 帳號底下的 S3 Bucket 資源 (包含可讀、可寫)：                     附加 AmazonS3FullAccess 策略            若要限制 IAM User 只能操作單一個 S3 Bucket，可以透過近一步進行進階的設定，以下是範例的 JSON 格式的策略：   {     \"Version\": \"2012-10-17\",     \"Statement\": [         {             \"Sid\": \"AllowOperateBucket\",             \"Effect\": \"Allow\",             \"Action\": \"s3:*\",             \"Resource\": \"arn:aws:s3:::google-drive-backup-example/*\"         }     ] }   完成建立並且記錄 IAM   根據建立流程檢視 IAM User 的資訊沒有問題，就可以點擊 Create User 完成建立：                     檢視 IAM User 建立資訊            建立環節中最後會產生一組隨機的憑證 (Access Key ID &amp; Secret Access Key)，由於該憑證只會產生一次，一離開這個頁面無法在取得，請紀錄這組憑證的資訊並妥善留存：                     獲得 IAM User 的憑證資訊 (Access Key ID &amp; Secret Access Key)            建立完成後你就可以在 IAM User 的介面找到剛建立完成的用戶，至此 IAM 相關的設定就告一個段落：                     檢視 IAM User             請注意不要把這組憑證外流，比如放到 GitHub，否則可能其他人都能任意存取甚至修改你 AWS 資源的資料    如果你策略也可以在 IAM User 建立完之後附加 (選擇使用 “Add Permissions” 指定 Managed Policy 或是 Add Inline Policy)：                     附加 IAM 策略                              附加 IAM 策略            如此一來，你就可以在 Python 程式碼中，使用 SDK 提供的方法帶入產生的 access token 初始化 S3 用戶端：   import boto3  # Create an S3 client s3 = boto3.client('s3')   Step 3: 建立 Google Colaboratory 並且在 CoLab 執行環境中使用 AWS SDK for Python 轉移資料   下一步就是可以直接在目標的 Google Drive 帳號中運行 Colab 環境。CoLab 支持掛載 Google Drive 在執行環境中當成本地端硬碟直接使用，透過這種方式能夠直接在 CoLab 環境中指定要執行備份的目錄工作。   透過在要轉移的 Google Drive 中新增一個 Google Colaboratory 的應用選項，可以直接啟用一個執行環境：                     新增 Google Colab 應用            如果沒有看到 Colab 選項的話，可以透過連結更多應用的選項安裝 Google Colaboratory：                     在 Google Drive 連結更多應用                              在 Google Drive 安裝 Google Colaboratory            透過 PyPi，可以直接安裝 AWS SDK for Python (boto3)：   !pip install boto3                     安裝 Boto3            接下來就可以直接透過 Colab 掛載 Google Drive：   from google.colab import drive drive.mount('/gdrive')   點擊運行就能將 Google Drive 掛載 (/gdrive/MyDrive)，並且授與必要的權限：                     授與存取 Google Drive 的權限            掛載後就能透過 AWS SDK 提供的 API 直接執行檔案上傳到 S3，並且透過 Colaboratory 的執行環境可以跑在雲端的背景中執行，完全不需要下載檔案並且將檔案從 Google Drive 搬家到 Amazon S3。   import boto3  s3_client = boto3.client('s3') response = s3_client.upload_file(file_name, bucket, object_name)                     執行範例            如果你熟悉 AWS CLI 的操作，甚至可以直接在 Colab 環境使用 AWS CLI 直接做出更多不同的操作和應用：                     CLI 執行範例            唯獨要注意的是，如果是部分 Google Drive 特定的檔案格式 (e.g. Google doc .gdoc … 等等)，因為在在 Colab 用 Python 的檔案讀取操作會遭遇失敗，部分這類的檔案無法透過 Colab 直接轉移，可以另外透過 Python 應用掃描出來之後，在 Google Drive 搬到一個統一的目錄手動執行壓縮下載的操作 (Google Drive 通常會轉換到在一般環境中讀取的格式)。    如果你有興趣想了解實作的內容   你可以透過以下的方法填入自定義的金額 Buy Me A Coffee                  一次性支持 (ECPay)       你會獲得贈送的簡單範例程式並且寄送到你的 Email，了解如何直接上傳整個目錄底下的資源，並幫助你快速的瞭解如何使用     總結   在這篇內容中，我與你分享了非手動檔案搬家的解決方式。在這篇內容中，提幾了幾個簡單的步驟，幫助你不必從 Google Drive 下載檔案，並將檔案轉移備份。並且使用 Google Colaboratory 執行 Amazon S3 遷移作為範例。   如果你覺得這樣的內容有幫助，可以在底下按個 Like / 留言讓我知道。   References      [1] AWS SDK for Python - S3   ","categories": [],
        "tags": ["google","aws","s3","python"],
        "url": "https://easoncao.com/moving-files-from-google-drive-to-s3-hack/",
        "teaser": "https://easoncao.com/assets/images/posts/2022/01/moving-files-from-google-drive-to-s3-hack/cover.png"
      },{
        "title": "關於 Cloud Support Engineer 職位的常見問題 - AWS Cloud Support Engineer FAQs (Amazon Web Services) ",
        "excerpt":"有鑒於我實在收到太多有關於職位的詢問，我已經開始懷疑自己到底是公司的 HR 還是 Engineer。但基於這項原因，我注意到許多常見的問題，因此，希望透過簡短的篇幅列舉可能你會想知道的資訊。                     AWS Support FAQs (source)            概覽   在分享 Amazon 的 Cloud Support Engineer 到底是在做什麼 (Amazon Web Services / AWS) 一文後，我開始陸陸續續收到許多私訊，並且收到許多人對於對於內容的反饋，也因為這樣間接也讓更多人更加深入明白對於我們職位的認知。   很多進來我們團隊的新同事都私底下跟透露說他們曾經看過我的內容，讓我著實有點害羞。但能夠幫助到許多當時對於我們團隊職位有興趣的候選人，心裡還是十分感激且開心的。   不過，由於我能從每個詢問中感受到每個人在準備面試的疑問，在不違反 NDA 的情況下，只希望給每個想要加入 AWS Cloud Support 團隊的你能夠有更多的方向，幫助你了解有關職位的內容，甚至能夠了解這份工作是否符合你的期待。   因此，以下內容均屬於個人自身經驗，不代表官方建議，請參考就好。   常見問題   Q: 團隊面向的客戶、在做什麼   請參考 Amazon 的 Cloud Support Engineer 到底是在做什麼 (Amazon Web Services / AWS)   Q: 需要會英文嗎？面試需要具備英文能力嗎？程度需要多好？      要、會、True、Yes    Amazon / AWS 是一家跨國的公司，在內部主要書信和溝通語言以英文為主。所以英文能力是必備的，但工程職位的英文能力可以不用說到一定要語言檢定都滿分非常強的程度。   但至少，要有能力不畏懼能跟英文母語者溝通和互動、聽說讀寫，因為除了無時無刻與其他國家的同事互動，也會有接觸英文客戶的機會需要使用全英文溝通 (或是為客戶充當翻譯)。   但如果你在中文團隊，使用英文這樣的佔比可能會是 50/50，工作中不乏還是會有使用中文與團隊成員、客戶進行溝通的機會。   (不過，我個人覺得這不是一個投遞職缺上很大的阻礙，畢竟語言這種東西也是可以練習跟訓練的嘛！)   Q: 我發現你們的招聘職位有 Cloud Support Engineer 跟 Cloud Support Associate，但要求好像一樣，差別是什麼？   在我們團隊工作內容相同，也會接觸相同的客戶，技術跟軟實力培訓跟資源都是一樣的。   差別在於 Cloud Support Engineer 是定義技術水平在業界比較有工作經驗的工程師，因此會有大量的機會接觸困難且複雜的案例、工作面向的對象也比較多是有規模的企業或是團隊為主，Performance 要求通常比較高 (簡單來說就是比較操，但相對的，協助複雜案例或是與客戶接觸的外部機會也通常比較多)。   Cloud Support Associate 在進入團隊後，同樣會有豐富的訓練資源幫助你累積足夠的實際客戶案例和經驗。再經過一定的技術考核後，可以經過內部 Promotion (升遷流程) 成為 Cloud Support Engineer。   Q: 以 Big Data/Networking/Database … XYZ ，請問面試過程中會問到 Linux (OS) 或是 Networking 相關的問題嗎 (還是偏向 AWS 產品 ABC 呢)？會問到多深入呢？   因為我們面對的客戶包含維運、開發者等不同角色，並且 AWS 的基礎建設離不開這些技術，使得 Linux 及 Networking 在我們團隊許多職缺算是基本的必備能力，但通常不會比專精 Linux 和 Networking 的專家還深入。   基於這項原因，就如同招聘說明和簡介裡面寫的，通常對於基本的作業系統知識、了解 Linux 系統的運作原理、檔案系統、維運相關等知識通常免不了。並且會需要有對基本網路除錯和 L1-L7 網路的理解 (例如：了解 TCP/IP、HTTP/TLS/HTTPS/DNS 及一般網路協定的運作)，每個不同的專業 (i.e. Database, Networking, BigData, Linux, Networking, DevOps … etc) 基於客戶需求和技術相關性對於這個領域的標準不太一樣。換句話說，專注 Database 專業的工程師跟專注 Linux 領域專業的工程師對於 Linux 知識的要求定義可能有所不同。可能 Database 專業的工程師具體了解 Linux 的基本原理、知道一些基本的指令和明白檔案系統、檔案權限管理、basic troubleshooting skill；但 Linux 專業的工程師可能就要非常了解 Linux process 運作、知道如何使用 Linux 的工具更加了解系統效能、知道 kernel dump 怎麼解讀、troubleshooting 等等知識。   每個專業領域會有基礎需要知道的基本知識，但團隊的技能樹也都是隨著客戶需求在變化，解決的問題也是日益更新。   面試可能會基於你的工作經歷及背景會有所調整，不過，因為我們就是主要在處理 AWS 產品的問題，因此，你在 AWS 上面可以看到的服務，可以預期都是你未來有機會能碰到的。具備 AWS 產品使用經驗是好的，但如果僅僅只會使用，回到問題排查的角度可能不見得有所幫助 (因為 troubleshooting 和問題排查正是我們團隊每天在做的事情)。   相信我，我們團隊的每個人也都在不斷的學習、拓展不同領域的知識。基於這項理由，沒有所謂固定的「面試問題」；但對於作業系統、網路知識的了解通常仍是需要一定的掌握和深入，因為這是 AWS 基礎建設中，基本中的基本。   AWS 的面試會是實際的理論和實務問題，沒有什麼腦經急轉彎的機智問答，並且，技術面試通常十分重視對於知識的理解。不管是誰來問我，我的建議一直都是你可以先從自己擅長的部分開始準備。由於面試的人通常會是領域專家，所以可以預期有時候問題不會是你可能過去所接觸的，這就取決於你如何分析和解決問題的能力。   具體來說，就我的觀點，如果連基本的作業系統、網路概論跟網路排查都不太熟，建議把基礎功打好再試試。   通常「只會使用和操作」的級別距離這個職缺所需要的能力還有一段差距，如果你想知道為什麼這個職位對於很多技術需由上至下到底層的通透理解，只需要設想你會每天會遇到類似以下各式各樣東西壞掉的情境：      “網站掛點, 救命!”   “資料庫連不上”   “好像有東西不太對勁並且無法正確運行”   “為什麼我的應用程式跑了一陣子就會自己 Crash?”   “為什麼我的生產環境 / 應用無法解析 DNS?”   “救命, 我的應用程式 / 服務在遭遇大流量的時候會崩潰”   如果是你，會怎麼排查呢？   Q: 面試怎麼準備 XYZ, tips …   面試不是考試，而是讓面試者更加了解你的過程。我會推薦根據你選擇的技術領域，準備實際你過去的案例，並且分享相應的實務經驗。另外，有興趣可以根據相關領域找找相應的 AWS 服務和實際案例。不管是否在準備面試，或即使你並沒有要加入我們團隊，我認為這都有助於你更深入了解感興趣的領域，對你的工作、目前在解決的問題可能也會有一定程度的幫助。   AWS 也提供了很多免費的學習資源可以參考 (e.g. AWS Training)，你會更加了解這份工作實際會接觸的內容和產品，和未來要學習幫助客戶解決的問題有哪些。   除了技術面向，Amazon 也十分重視 Culture fit，以了解你是否符合公司所想要的人格特質加入我們團隊。上上下下所有的團隊都留著 Leadership Principles 血液，所有的決策、文化和流程都是基於這些準則實行，某種程度上也影響團隊成員更加負責和不斷推動進步。   因此，我相信你也一定聽過很多傳聞跟分享提到 Amazon 有多重視 Leadership Principles 並且會在面試過程中不斷的一而再、再而三問問你過去處理問題的相關情境。我可以確定這不是都市傳說，面試一定會有 Behavior question，建議可以閱讀 Amazon Leadership Principles 了解公司的文化特質。但這種東西建議根據自身經驗回答就可以了，如果你的做事風格都遵循這樣的準則，很容易在回答中呈現出來。   Q: 我如果是非資工本科系學生，適合這項職位嗎？   我們團隊很強的成員並非全然都是資工 / CS背景，有化學工程、經濟、物理、甚至是商管背景的同事。   就我的觀點，領域背景在 Amazon / AWS 不會是太大的阻礙影響到你的職涯發展，全然取決於你自己如何定義，希望這能增加你一點信心。   Q: BigData 實際工作內容有與外面資料科學家的相關工作內容相同嗎？(數據分析、資料科學家)   就我所知，BigData Team 日常處理的問題都是大規模集群客戶使用上遭遇的問題 (Hadoop, hive … etc)。也許可能會在團隊專案上用到數據分析相關的專業解決一些團隊的需求，但不會是單純做資料分析的工作。   有部分原因由於我們團隊面向的對象有部分都是系統維運人員、開發者，所以更多的是維運、Troubleshooting 相關的知識和技能，存在一定的佔比。這通常會需要對於底層運作存在一定程度的了解，才知道怎麼解決這種連客戶也覺得棘手 (東西壞掉) 的狀況。   Q: 未來職涯發展   由於這個角色會面向許多不同的對象：產品開發人員、客戶、Technical Account Manager、Trainer、銷售或是其他團隊，這造就這個職位的職涯路徑變得非常多元。   我們有持續深化技術能力成為資深工程師的同事，為客戶帶來更深遠的影響、或是往管理職發展；也同時有轉到其他團隊擔任不同職位的同事 (Solution Architect, Trainer ., Developer … etc)。在 Amazon 內部，只要有能力並且存在職缺，都能申請其他團隊的機會。   在 Amazon 有趣的事情是，你可以自己定義自己的職涯藍圖，我也看過非 CS 背景的同事從帳務團隊轉到工程師職位的例子 — 一個非技術職缺轉到技術職缺的案例。因此這題，我想我並沒有標準答案。   如果你問我，我個人則是選擇 Relocate 到國外的團隊繼續發展並貢獻己力，因此，這取決於每個人的發展和職涯取向，但你絕對能挖掘自己的不同可能性。   總結和工商   希望這篇內容能夠對你有所幫助，並且有助於你解答可能對於職缺的相關疑問。   若你對於這樣的工作環境及內容有所興趣並躍躍欲試，我們仍在持續招聘優秀的人才加入我們。我同時也在 NEX Foundation 為串連台灣人才於國際舞台上的職涯發展貢獻己力，你可以透過 NEX Work 附上 CV 提交內推申請 (需註冊登入) 以引薦更多像你這樣的優秀人才，或是透過我的 LinkedIn 與我聯繫。      NEX Work：申請內推 (需登入)   如果你覺得這樣的內容有幫助，可以在底下按個 Like / 留言讓我知道。   看更多系列文章      我在 Amazon 學到的 10 件事   我是如何在還沒畢業就錄取並進入到 Amazon 工作   我是如何在一年內通過 AWS 五大核心認證   Amazon Cloud Support Engineer 到底是在做什麼 (Amazon Web Services / AWS)   關於 Cloud Support Engineer 職位的常見問題 (Amazon Web Services / AWS) - AWS Cloud Support Engineer FAQs   在 AWS Cloud Support Engineer 面試中脫穎而出：必備的技術能力和重要特質   身處 Amazon 工作 5 年學到的事：在 AWS 擔任 Cloud Support Engineer 是什麼樣的體驗   ","categories": [],
        "tags": ["amazon","aws","amazon web services","work","Cloud Support","Cloud Support Engineer"],
        "url": "https://easoncao.com/aws-cloud-support-engineer-faq/",
        "teaser": "https://easoncao.com/assets/images/posts/2022/02/aws-cloud-support-engineer-faq/cover.png"
      },{
        "title": "擁有高效生活：手機、社交應用軟體對於我們的影響以及應對 - 退出社交軟體 30 天 (Dopamine Fast for 30 Days)",
        "excerpt":"「無時無刻不自覺的拿起手機按下 Facebook/Instagram 的軟體圖示」、「新的通知訊息」、「忍不住點擊的小紅點數字提示」、「新通知！忍不住看ㄧ眼震動的手機」 — 你是否曾想過自己對於社交應用已經嚴重影響你的生活，甚至正在左右你的情緒、壓力和思想。                     擁有高效生活：手機、社交應用軟體對於我們的影響以及應對 (source: Unsplash)             在這篇文章中你將知道      了解有關社交軟體成癮和相關的理論   了解幾個社交應用軟體成癮現象   幾項初期可行的解決方式，包含我自己退出社交軟體 30 天的一些心得，幫助你改善生活質量    2020 年，Social Dilemma (智能社會：進退兩難) 在 Netflix 上映。剛看完這部片時，即使是一個在科技業從業的工作者，仍是充滿難以形容的震驚，且有如當頭棒喝。   我們熟捻算法的迷人之處、了解機器學習在透過監督學習訓練下所學會的強大辨識能力。但卻無法想像簡單的分群 (Clustering) 這種在基本不過的演算法邏輯，應用在我們所常見的社交應用和推薦機制上，帶來卻是更多對於強化不同立場同溫層的最壞情況：挑起仇恨、誤導，甚至，我們仍會天真地以為這些都是客觀且可靠的資訊。   我們往往忽略了這些內容的背後，也許正是某部分人為操作所產生：因為，這終究都是 Google 搜尋、Facebook 貼文演算法餵食給你的結果。   設計演算法時都不排除存在所謂的「目標」(Goal, Objective)，也許一個適合於這種商業模型的演算法，都為了「提高使用者在平台的停留時間」這項指標不斷的餵食、推薦你所愛看的任何內容。   有人說，免費的最貴，因為，你就是商品的一部分。透過提高你在社群軟體應用的黏著度，你的注意力就是販售給廣告商的商品。畢竟，這些內容平台目前仍依賴於廣告的收益為他們的公司帶來盈利。   短影音平台的盛行 (Tiktok, YouTube short) 就是個顯著利用人性與演算法的例子；也許你想著每則看似即時且短小的影音看著不會佔用太多時間，殊不知，隨著不斷推送感興趣的內容一直滑下去，就是一個小時以上。明明都是相同的時間，相較之下，要認真的運動一個小時，對多數人來說卻是極度的痛苦。   如果你也有同樣的困擾，並且希望改善這樣的問題，你可以透過這篇內容更加了解其背後的科學和行為，明白自己是否存在成癮。同時，我希望透過我自己的總結幾項研究，與你分享自己的心得和幾項具體解決方法，以更好擁有高效生活、提高專注力和降低對於成癮行為的依賴。   社交軟體帶來了許多人際互動上的革新，但同時，也越來越多的研究和討論，顯示社交軟體應用上導致的健康問題和成癮之間的關聯性。   如果傳統上對於吸毒者成癮我們有嚴謹的道德和社會規範，但往往我們都忽略了社交軟體應用的成癮，也如同另一種形式的飲酒、用藥上癮反應，卻從未因此而受到束縛或是譴責，甚至並不認為這樣的成癮不是什麼大問題。   完成所有社交軟體設計的「任務」(消除小紅點、滑完未讀訊息和動態… 等等)，與這些我們所熟悉那些認為所不好的習慣 (例如：吸菸、飲酒、吸毒) 的成癮反應一樣，這些獎勵機制都會分泌大量的多巴胺 (Dopamine)，同樣能帶來一種暫時性的愉悅和滿足感。1      Smartphones have provided us with a virtually unlimited supply of social stimuli, both positive and negative. Every notification, whether it’s a text message, a “like” on Instagram, or a Facebook notification, has the potential to be a positive social stimulus and dopamine influx.    什麼是多巴胺 (Dopamine) 和其成癮行為   多巴胺 (Dopamine) 屬於人體中重要的神經傳遞物，在眾多研究中指出這項物質可以影響一個人的情緒和獎勵機制反應，主導興奮、開心、情慾等。可以影響許多行為和生理，例如 2：      學習 (Learning)   驅動慾望和動機 (Motivation)   心跳 (Heart Rate)   血壓功能 (Blood vessel function)   睡眠 (Sleep)   行動能力 (Movement)   情緒 (Mood)   注意力 (Attention)   由於吸菸和吸毒都可以增加多巴胺的分泌，使上癮者感到開心及興奮，致使在成癮研究中少不了關於這項物質的探討。   當我們積極做某件事情時，腦中會非常活躍的大量分泌。但當不足或失調時，則會令人失去控制肌肉的能力、導致注意力無法集中，在嚴重時能導致手腳不自主地顫動 (學名為也許你常聽見的帕金森氏症, Parkinson’s disease, PD)。   有趣的是，多巴胺 (Dopamine) 似乎存在學習機制。針對獎勵機制和成癮行為學習的研究中，常使用賭博成癮者作為研究範例；從研究中，當對象在拉下 Slot Machine (俗稱吃角子老虎) 拉桿初期獲得非預期的賭注獎勵時，多巴胺 (Dopamine) 的活性會隨著獎勵的當下增加。此時可能伴隨著興奮、快樂的情緒。   但也因此，多巴胺 (Dopamine) 在之後每次拉下拉桿的「這項提示」中，出現了預期下次操作行為，將獲得相同結果的渴望。使得多巴胺 (Dopamine) 活性在尚未獲得獎勵時，卻在於該提示階段中分泌活躍。然而，當未獲得預期的獎勵時，將降低其活性，並且向大腦發送負面的訊號。便感到失落、情緒上受到影響。                     多巴胺 (Dopamine) 的活動機制 (source: Trevor, H.(2018) Harvard University)            因此，基於這項預期獎勵機制通常上癮行為伴隨著特定的行為模式。並且，隨著我們所獲得的預期獎勵無法獲得滿足，很可能間接降低多巴胺 (Dopamine) 的活性，使得行為產生黏著。   如果想要了解自己是不是有存在社交軟體成癮，可以透過以下幾個常見的規律了解自己是不是存在可能的手機、社交應用軟體成癮現象。   幾個社交應用軟體成癮現象 (常見於 Instagram、Facebook)   A. 起床、半夜睡不著的第一件事就是查看手機社交媒體   每天一早睜開眼睛、或是徹夜難眠的夜晚，你會很自然地拿起手機查看 Twitter、Tiktok、Facebook、Instagram …. 等等。   這樣的過程開啟 App 應用點擊的速度之快，這樣的長久獎勵行為變成一項習慣，你甚至不會去思考自己做的行為。   當你回過神來，你的所有小紅點、通知和未讀的訊息已經在你的一陣操作中全部消除、甚至不自覺的回覆了數串留言，獎勵機制啟動，你感到一陣舒暢。   B. 發出貼文使你感到焦慮或是壓力   身為重度社交軟體應用使用者的你，可能不時在意別人沒有對你的貼文按讚、追蹤你或是留言。   為了獲得認同和點讚的獎勵，每則貼文前你都會一而再、再而三的修改內容，套上美好的濾鏡、不斷的修圖，不知不覺花了半小時甚至一小時以上在編輯內容。   也許讓你獲得了許多來自朋友圈的讚和關注，但也許，你終究明白這不是真正的你；一方面你想滿足呈現自己最美好的一面，但另一方面又不自覺的在朋友圈中進行比較、美化自己在社交軟體上的樣子。   這樣的循環使你感到焦慮，亦或是感到沮喪。   C. 刪除、隱藏不是那麼多讚 (Like) 或是受歡迎的貼文   你會希望在你所有的社交軟體帳號上呈現的事物都非常美好，因此，你會很在意你每一則貼文的迴響。   當你發現自己的貼文也許不是那麼受到歡迎，你會感到失落、懷疑，甚至最終選擇隱藏、刪除你的貼文。   D. 做任何事情不忘滑著社交媒體、持續地查看其他人的貼文，甚至無聊的時候會不自禁的一直滑   你會在做任何事的時候不自覺得滑著社交媒體 (可以是跟你家人聊天、等車、看著 Netflix 等等)；也可能是睡覺前的習慣讓你覺得應該需要滑一下手機以完成某種程度的滿足。   但往往等你回過神來可能已經錯過重要的片段、望著剛駛去的公車、沒有捕捉到的對話或是失去與他人的相處時間。甚至，當你在滑著滑著回過神來，已經是深夜 1-2 點之後，想起明天要早起頓時感到一陣壓力，間接失眠。   當你想起來總是念茲在茲的告訴自己下次要改進，卻仍舊在無聊時，不自覺地掏出手機持續相同的循環，因為你期待點開的時候能夠獲得相對應的獎勵 (小紅點、新的貼文、朋友圈的更新)。   你會選擇解決重要的任務還是滑社交媒體？了解多巴胺 (Dopamine) 和社交媒體成癮的關係   如果上述有幾個項目你感同身受，請先不要一股腦的譴責自己。   因為滑社交媒體是一件非常輕鬆容易的事情，並且滿足了獎勵機制，誘使多巴胺 (Dopamine) 分泌使你感到興奮、快樂、滿足、愉悅。   人機界面的研究者和各個科技公司更是掌握了這項特性，促使你在他們的平台上有更高的黏著度，加上機器學習和推薦系統的演算法不斷放送我們愛看的東西，更讓人沒有理由不沈迷於這些美好和我們所喜歡的資訊。   我們的大腦天生設計傾向於選擇最簡單的任務，也許你只要稍微留意，都能注意到這些軟體花在介面設計上所下的功夫，例如：      比起要點擊按鈕載入更多內容，無限地往下捲更加直覺且容易，促使你不斷的往下滑觀看更多內容   在 Instagram 輕鬆點擊兩下就可以直接對貼文按讚 (Like)，並且這些訊息均即時的推播到對方的通知中。誘發了對方注意並且回到平台上觀看並且互動的可能性，提高平台的黏著度。   限時動態 (Instagram) 和閱後即焚 (Snapchat) 的設計，促使用戶主動發送時效性甚至存在私密級別的內容，甚至設計已讀和紅色小圈圈機制，以推送給關注者。同理，關注者擔心無法在時效性獲得私密性第一手消息，而不斷的要消除未讀的訊息以獲得滿足感。這些設計，都在不斷地誘使你回到平台上查看是否有最新訊息。   不斷的提示你是不是把貼文看完了 (You’re All Caught Up)。基於擔心無法跟上即時訊息，使得用戶有空時不斷的反覆回到平台，透過捲動更新確保訊息即時。   如果拉下 Slot Machine 的拉桿是一種沈迷的行為，存在負面的成癮認知。那捲動內容型社交軟體 (Instagram、Twitter、Facebook)，不斷的透過我們的指尖拉下貼文牆的行為，似乎也相去不遠，都存在成癮機制，並且對我們身心產生劇烈影響。   也許你在社交軟體上不知不覺就度過了一個小時；但要你解決更為重要的任務 (完成手邊的工作、出門運動 30 分鐘、花 15 分鐘讀一篇文章)，可能都會覺得如坐針毯。   閱讀到這邊我相信你很想知道如何改善這樣的問題，因此，接下來讓我們看看幾項可行的解決方式。   幾項初期可行的解決方式   1. 關閉所有通知   每當你的手機震動、響起提示鈴聲、或是出現一閃而過的通知，即使你並不直接反應，往往都令人十分在意。這無疑在某種程度上增加了壓力和焦慮，並且提高你對於手機的依賴程度。   因此，當你關閉所有通知時，你可能頓時會感到空虛、像是某種東西失去。但相信我，當你嘗試幾天後，這件事將會變得很容易，並且將不再為任何一點小事情而收到通知，將注意力專注放在眼前的事物上。                     關閉所有通知 (Line)            有關於常見社交應用軟體 (Facebook, Instagram) 的關閉方式可以參考以下文件：      How do I turn push notifications on or off on Instagram?   How do I turn my Facebook app or game notifications on or off?   2. 改變你對 Instagram、Facebook 形象的想法，延遲、排程使用社交軟體的時間   既然前面提到關閉所有通知的策略，為了最大化這項效益，你更可以進一步設定排程，延遲使用社交軟體的時機。   你可以安排自己每天只能在特定時間 (例如：晚上 8:00 PM)、一切工作完成時打開軟體查看你感興趣的資訊。   更精準的是限制使用的時間上限，但就我的試驗，我覺得設定上限往往很容易打破自己設下的限制。因為，我們常因為各種例外 (回覆留言、處理許久未見朋友的訊息、感興趣的內容、影片) 而產生滯留。      我認為娛樂並不是一件壞事，重點應該著重在這項娛樂應該低於你其他事情的重要性。    這是一種需要不斷練習和自我要求的行為，但透過這樣的覺察，不斷地減少在社交軟體上的耗時，並且找到更多有意思的事情做，你將會逐漸擺脫使用社交軟體的依賴。   請記得生活並不是一場比賽，並且在社交軟體上 (Instagram, Facebook) 並不應該是關於 “Who is the best” (誰是最好的) 這種比較想法，而汲汲營營在上面投入許多不必要的時間。   3. 停止手機不離身   當你專注於某件事物時，可以將你的手機放在你會遺忘的地方 (但仍可以記得找得到)，例如：另一個房間、你的床底下 (我自己是會放到書桌底下看不見的地方)、衣櫃 …. 等等。   這樣你有事沒事的時候，你就不會一直因為手機的震動、亮起的螢幕不斷的查看你的手機而導致注意力下降。   也許一開始會非常不習慣，像是前面提到的，因為某種程度的依賴感失去，存在一種不安全感。但當你開始習慣後，將會逐漸明白這只是一種練習的過程。   如同我於過去內容中提到 - 真正在乎你的人，如果真的有很重要的事情，是不會介意用打電話的方式與你聯繫，比起通知和不斷的文字來回，電話通常是直接並且最有效率的對話方式。同時，現在手機都提供勿擾模式 (Do Not Disturb)，你可以將其設定為這個選項，或是直接使用飛航模式。   你也可以設定僅重要電話響起鈴聲，這樣也許你某種程度上知道自己並不會錯過重要電話而感到焦慮。   (延伸閱讀：3 項原則讓你變得更有生產力 - 最有生產力的一年 The Productivity Project)   4. 限制使用的社交軟體時間   現在的手機作業系統通常都支援限制軟體的螢幕時間 (Screen Time)，這有助於你為自己設定每天軟體使用限制。   千萬不要太相信人性，除非你真的高度自律。否則，人性就是會情不自禁、在誘惑下將用一切作弊的方式選擇點開。透過工具，將某種程度上能夠約束你的行為，並且增加開啟 App 的困難度。   我個人過去會使用 Android 提供的 Screen Time 限制選項設定 (在 Digital Wellbeing 裡面)，除了可以檢視自己到底花多少時間在 App 上，更可以設定每天能使用該 App 的最大時間：      Manage how you spend time on your Android phone with Digital Wellbeing   我目前也在 Chrome 瀏覽器安裝 BlockSite 插件，它可以選擇開啟阻擋模式、特定關鍵字或是設定 Focus Time (專注時間) 而進行過濾，避免你在自己設定的限制時訪問會讓你留連忘返的網站。雖然免費版有阻擋數量上限 (6 個)，但對於我來說已經十分足夠。   當開啟應用是一件「很麻煩」的行為時，你已經成功的說服大腦，通常你也會更加容易告訴自己堅持設下的要求。                     BlockSite 瀏覽器插件 (Chrome)            5. 登出你所有的社交軟體帳號、移除社交軟體 App   你可以根據自己的情況選擇合適的方法，但如果你跟我一樣可能禁不起誘惑，那麼，登出帳號、刪除 App，當你無法輕鬆獲取到這些內容時，便被迫習慣沒有被 App 內容餵養的生活。這大概是最好作法，沒有之一。                     從今天開始一起成為只剩網頁版可以使用的 Instagram 用戶 (記得登出帳號)            實施 Dopamine Detox (Dopamine Fasting)   Dopamine Fast (多巴胺禁食 / 多巴胺禁斷) 由 Dr. Cameron Sepah 提出，並且於臨床中應用於科技工作者或是風險資本家，目標是讓他們擺脫對某些刺激的依賴，例如電話提醒、短信和社交媒體通知。   在 Sepah 的理論和臨床研究中，提出並且辨別了六種主要的強迫性行為作為主要戒斷的目標 3：      因情緒主導的飲食 (Emotional eating)：例如心情不好的暴飲暴食、嘴饞非飢餓性想吃零食的衝動   過量的網路使用和遊戲沈迷 (Excessive internet usage and gaming)   賭博和購物 (Gambling and shopping)   沈迷色情內容和自慰 (Porn and masturbation)   尋求刺激和新奇事物 (Thrill and novelty seeking)   藥物成癮 (Recreational drugs)：包含吸菸、飲酒等等               基於臨床上的研究，Dopamine Detox (多巴胺排毒) 逐漸成為近期很熱門的議題，意味著透過排除部分會產生大量多巴胺 (Dopamine) 的行為，將大腦分泌多巴胺的活動程度降低，減少上癮和達到某種程度「延遲滿足」的效益。   初期最簡單的實踐方式，就是你可以安排每一週的一天遠離使用手機、中斷網路，並且將精力專注在其他無聊的事情上，例如：看書、做筆記、走路、冥想等等。               但要注意的是，許多人往往誤解這種禁斷的行為，並且做出許多強烈且偏激的限制：不吃東西、不運動、拒絕社交、排斥聽音樂 (甚至是上面的影音中所提到的部分，可能是為了凸顯某種程度的「與眾不同的自律」而存在激進)。但這樣的禁斷使得你拒絕再回到生活中既有的部分模式時，將更容易存在上癮行為。      However, people are adopting ever more extreme, ascetic, and unhealthy versions of this fasting, based on misconceptions about how dopamine works in our brains. They are not eating, exercising, listening to music, socializing, talking more than necessary, and not allowing themselves to be photographed if there’s a flash (not sure if this applies to selfies).    根據 Harvard Medical School 提出的內容指出，基於 Sepah 建議這種禁斷方式應該從生活方式影響最小的方法開始，並且逐漸擺脫對於相關成癮媒介的依賴。例如：可以從一天結束最多練習不要使用手機 1-4 個小時 (取決於工作和家庭需求)。4   再來你可以逐步的移除你的社交軟體 App，從一天、到一週、甚至一個月，你將逐漸擺脫對於使用社交軟體的依賴。   實施 30 天不使用 Instagram   我認知到自己是一個非常重度的 Instagram 使用者，並且無時無刻地會關注他人的貼文。因此，自從在認識到自己的上癮習慣後，我在去年開始嘗試上面所提到的方式，並分為幾個階段：      Phase 1：移除 Facebook App (因為鮮少使用，並且都轉移到網頁版)   Phase 2：關閉所有通知，包含 Line、Instagram、Twitter 等等，開始變成想到才去看一看訊息   Phase 3：設定 Screen Time，有意識的告訴自己花了很多時間在幾個 App 上 (但不可避免會手動取消，有時候還是會關掉限制打開 App)   Phase 4：取消遊戲和幾個會耗費大量時間但是沒什麼在用的訂閱 (例如：設定提醒取消 Amazon Prime、取消 Deliveroo 的外送會員計劃，減少花費大量時間選擇外送食物的行為)   Phase 5：設定 Email filter，退訂懶得看或是沒有質量的廣告、News Letter，不能退訂的就直接轉到垃圾信箱   並且，逐漸將社交軟體平台登出，甚至將 Instagram 移除。但仍不可避免仍克制不住想發動態的慾望，有時想要使用的時候，就會回到 App Store 上抓回來使用，但相對變得麻煩許多。   在這個時候開始，我嘗試了兩週後才回去使用 Instagram。在一開始確實充滿無聊，但在這個階段，我也不斷嘗試將注意力轉移到吉他的練習和其他事物上 (延伸閱讀：刻意練習 - 實踐刻意練習的 3 項原則，往專家的道路邁進，我的心得及實作)。   我也允許自己發呆，不得不說當時還是會下意識的打開 instagram.com，然後就盯著這個畫面：                     對著 Instagram 的登入畫面發呆            但看到這個畫面，就是告訴自己再無聊都不可以登進去。上述的行為重複幾次後，我才發現原來自己會不自覺一天開啟這個頁面不下 5-10 次，可見大腦對於一旦養成的習慣變成為「自動模式」，其影響有多深遠。但也因為每次打開頁面什麼也不能做，於是開始感到無聊，且覺得沒意義，無意識開啟的頻率開始逐漸降低。   雖然 2 週的實驗結束後，還是會跑回 Instagram 手機或是網頁版看看東西，但在實際體驗這樣的過程後，卻也發現好像對生活不會有太大的影響。並且，對於生活某種程度上獲得一些不錯的改善。於是，在今年開始，我真正的將 Instagram App 徹底從我的手機移除，並且嘗試實施了 30 天禁用 Instagram App。   同時，應用部分習慣養成的理論，我在腦中設計了類似日曆鏈 (Calendar Chain)：做法就是想著這樣的行為最終可以讓我獲得一個打叉，這類似於原子習慣中提到的迴紋針策略。(延伸閱讀：原子習慣：細微改變帶來巨大成就的實證法則 - 我的心得及實作)   因為不想讓這中間的鏈結斷開，因此你便有了更多堅持的想法：                     日曆鏈 (Calendar Chain)            當你過了 30 天回到平台上，你會發現，大家仍持續的過他們自己的生活、發佈他們在意的內容，並不會因為你的消失而有所變化。   你可能也會發現，即使錯過一部分的資訊、不再進行比較，其實，這些資訊也並不是那麼重要，並不需要時時刻刻的刷著社交軟體打轉。因為你清楚知道這 30 天內你不斷的提升自己、利用原本拿來刷社交軟體應用的時間專注自己所在意的目標。   可能失去了無聊時習慣打發時間的渠道，但相比之下，你改掉睡前滑 Instagram 的習慣、睡眠質量提升、不再一直隨時拿著手機滑滑滑。你也許會明白，人們並不會因為你不使用社交軟體應用就討厭你，而是在意總是輸出他們不是那麼喜歡、或是不需要的內容，選擇討厭。   明白你自己的價值並不依賴於社交軟體 (Instagram、Facebook) 上的數字、獲得的讚數或粉絲追蹤，更不應該與他人比較，因為只要一登出，便毫無意義。   相信我，你會開始認知你的價值並不會由 Instagram、Facebook 上的數字而定義，並且探索更多值得你花費時間在上面的其他事情。   總結   即使寫完這篇內容，說了這麼多方法，讓你覺得我是一個非常自律的人，但我必須直白的說這某種程度上存在誤解：我也會怠惰、某些事情並不是做得這麼好。但我想我們都有能力學習在意識到這些問題時，是否願意讓自己更持續進步。如同我當時定義網站標題稱為 Continuous Improvement 的核心理念，因為我相信所有人都有能力能夠持續進步，有能力選擇想過的生活。   事實是我仍然會對這些社交軟體應用的使用習慣上癮，這必須多虧科技公司和各領域專家的致力研究。但我想，改變最大的一步就是覺察，我們都可以學習如何更好的與這些科技所帶來的便利共處。   因此，在這篇內容中，我與你分享了幾個有關社交軟體成癮和相關的理論。同時，也與你分享了數個社交應用軟體成癮現象。並且在這篇內容中，分享了幾項初期可行的解決方式。最後提及了實施 Dopamine Detox / Dopamine Fasting，包含我自己 30 天不使用 Instagram 我自己的一些心得。   我希望在閱讀這篇內容的你，在看完這篇內容的同時，除了可以理解到認知自己對於成癮行為的沮喪並不是一件壞事，並且從中透過可行性的方法逐漸獲得改善。此外，也更可以理解到社交軟體平台上的數字、別人的評價並不能夠足以定義你和你的價值。   你更無需與社交軟體上的名人、其他模範進行比較。你並不需要覺得自己輸人一點，請記得，社交軟體上大家呈現的都是理想化的自己，其實真實世界的你，遠不止這些。   如果你覺得這樣的內容有幫助，可以在底下按個 Like / 留言讓我知道。   Reference                  Trevor, H.(2018) Harvard University - The Graduate School of Arts and Sciences. Dopamine, Smartphones &amp; You: A battle for your time &#8617;                  Smitha, B. (2021) WebMD. What Is Dopamine? &#8617;                  Lindsey, T. (2021) Medical News Today. What to know about a dopamine detox &#8617;                  Peter, G.(2020) Harvard Medical School. Dopamine fasting: Misunderstanding science spawns a maladaptive fad &#8617;           ","categories": [],
        "tags": ["personal growth","reading","productivity","work","psychology","自我成長"],
        "url": "https://easoncao.com/dopamine-detox-and-have-high-productivity/",
        "teaser": "https://easoncao.com/assets/images/posts/2022/02/dopamine-detox-and-have-high-productivity/cover.jpg"
      },{
        "title": "AWS Firecracker 論文導讀：一個小孩才做選擇，我兩個全部都要的 VMM",
        "excerpt":"AWS 公開 Firecracker 專案已經至少 1-2 年的時間，也許你多少都聽過這項技術。然而，究竟 Firecracker 是什麼，我想可能你也仍然一知半解。有鑒於我認為學術類型的內容有時不容易讓人明白，因此，我希望可以透過以下的篇幅，分享我自己對於閱讀 Firecracker 設計論文的一些理解。   由於我個人沒有受過正式的學術訓練，因此，如果有專家願意提供任何見解，也請不吝給予指正及建議。                     Firecracker 概覽 (source)            概覽   在閱讀完 Firecracker 的相關論文後，我對於這個專案的結論，簡直可以說是一個小孩才做選擇，我兩個全部都要的設計。   在論文中提到，設計 AWS Firecracker 由於在權衡 Hypervisor-based 和 Linux container 虛擬化技術之間產生的相容性、安全性的優缺點，兩者取其一似乎都無法滿足 AWS 基礎建設所需滿足的工程目標。因此，Firecracker 決定打破這樣的抉擇，擔任起 VMM (Virtual Machine Monitor) 的角色，並且引入相關的各種現有功能機制的優點，以滿足運算虛擬化的設計需要。      Implementors of serverless and container services can choose between hypervisor-based virtualization (and the potentially unacceptable overhead related to it), and Linux containers (and the related compatibility vs. security tradeoffs). We built Firecracker because we didn’t want to choose.    目前 AWS 已經將 Firecracker 導入至兩個公開的無伺服器 (Serverless) 服務：AWS Lambda 及 AWS Fargate，並且支援數百萬的用戶和單月萬億級別 (trillions) 的請求，以下將具體描述更多 Firecracker 相關的細節。   (相關的 Paper 原文和我自己畫的重點請參考1)   基本名詞釋義 (Terminology)   由於 Firecracker 屬於一種作業系統虛擬化技術的延伸，其中涉及 Linux 作業系統虛擬化的諸多細節。因此，首先在閱讀這篇內容之前，必須先了解基本的一些概念和名詞釋義：   Hypervisor   Hypervisor 可以視為用於管理虛擬機器 (Virtual Machine) 的軟體、系統或是韌體。使用虛擬化技術允許我們在單一個電腦上運行多個不同的系統、甚至是可能不同的作業系統 Kernel，並且將其放置於一個虛擬的運行環境中 (Virtual Machine)。因此，Hypervisor 的目的就是用來管理這些虛擬機器，通常，用來執行一個或多個虛擬機器的電腦稱為宿主機 (Host)，這些虛擬機器則稱為客戶機 (Guest)。   Gerald J. Popek 及 Robert P. Goldberg 在 1974 提出了兩種類型的 Hypervisor 2，分別為 Type 1 和 Type 2：                     Hypervisor 類型 (source)            因為在虛擬機器中，安裝了一個 Guest OS 並不意味著就能直接使用 Host OS 的所有資源 (例如：磁碟寫入、CPU 時間、I/O 等操作)。通常，Hypervisor 會實作「模擬」這些裝置讓 Guest OS 以為能夠使用，但實際上仍交由虛擬化技術實際將這些操作轉譯、排程交給 Host OS 處理。      Type 1 的 Hypervisor 通常需要硬體和 Kernel 支援，因為通常能充分交付使用硬體操作，而無需透過 Hypervisor 為 Guest OS 執行作業系統各種操作的 (syscall) 轉譯。這也通常意味著，執行的效能也比較高。常見的實作如：Xen 和 Linux KVM。   Type 2 軟體會運行於主要的 (Host OS) 並且可能會以一般的軟體應用形式運行，通常執行效率比 Type 1 來得低。常見作業系統層級的軟體類似於 VMWare、Vritual Box Hypervisor 軟體。   VMM (Virtual Machine Monitor)   基本上與 Hypervisor 相同，如同他的名字一樣 (Virtual Machine Monitor)，VMM 設計的目的就是用於建立、監控、管理和捕捉跑在虛擬機器中的 I/O 操作 (磁碟寫入、網路吞吐等)。   QEMU   QEMU 是一個開源的 VMM，由於 QEMU 的架構由純軟體實現，並且處於 Guest machine 與 Host machine 擔任中間者角色，以處理 Guest machine 的相關硬體請求，並由其轉譯給真正的硬體，使得其存在一些效能問題。   KVM   KVM (Kernel-based Virtual Machine) 是一種 Linux Kernel 支持的虛擬化技術，可以將 Linux Kernel 轉換成一個可用的 VMM 並將系統轉換為 Type 1 (bare-metal) 類型的 Hypervisor，使得你可以在 Linux 系統上運行多個隔離的虛擬環境 (VM)。KVM 一直是 Linux Kernel 設計的一部分，並且存在於主流的 Linux Kernel 版本中。因此，由於屬於 Linux Kernel 支持功能的一部分，通常可以使用接近原生系統的相應執行效能處理對應的 I/O 操作。   crosvm   crosvm 為 Google 的一項開源專案 (Chrome OS Virtual Machine Monitor)，用於 Chrome OS 執行虛擬化機制的操作，基於 Linux KVM Hypervisor 實現虛擬化技術，並且用於 Android、Chrome OS 為基礎的系統中。與 QEMU 相比，它並不直接模擬實際的硬體裝置，反之，它採用了 Linux 支持的半虛擬化的裝置標準 (virtio) 來模擬虛擬機中相關的裝置。Firecracker paper 中具體提到了實作中採用了以 crosvm 作為基礎核心背景修改。   Cgroup (Control Group)   cgroup 是 Linux Kernel 一項支持的功能，主要可以用來限制運行在容器執行環境中的資源使用 (例如：CPU、Memory 和磁碟讀取寫入等)。cgroup 同時也被大量運用在 Linux container 的技術中，例如：Kubernetes、Docker 等。   在 Firecracker 中，提及了基於不信任 Guest OS 對於資源控制的行為。這是由於 Guest OS 屬於客戶控制的一部分，並無法預期其是否能依照合理的使用行為運行，因此，Firecracker 也採用了 Linux 本身支持的功能及 cgroup 等機制，限制了 VMM 和各個虛擬機器總體可用的資源。   Seccomp   seccomp 是 Linux Kernel 支持的一項功能，用來限制在容器中運行的 process 可以呼叫的系統方法 (syscall)。可以想像就像是允許使用特定 Linux function 的白名單，在 process 的直接階段僅允許特定系統呼叫操作。   同樣的機制也被實踐在一些容器虛擬化技術中，例如 Docker 定義的預設 seccomp profile。   AWS Firecracker 是什麼   在過去，AWS 主流的 Serverless 服務提供了 AWS 客戶另一項託管運行應用的選擇 - 用戶不需要再自行管理底層運作機器和安全性修補的工作。   最著代表性的 AWS 服務便是 AWS Lambda，如果你不知道 AWS Lambda 是什麼，AWS Lambda 是一種無伺服器 (Severless) 運算服務，使用者可以直接上傳你的程式碼並且選擇對應的規格運行，你無須在煩惱需要使用什麼樣的硬體規格以及為維護工作煩惱。   同時，也提供在大規模的應用情境中隨著用量可以動態擴展的優勢。然而，在 AWS Lambda 服務剛釋出時，其採用了 Linux Container 用以隔離不同客戶的執行環境 (類似於 Docker 相應的技術)，然而，這樣的機制除了可能在客戶使用運行執行環境存在限制 (需使用依賴 Host OS 支持的 Kernel 版本指令集)，也因為同時共用相同的 Kernel，也可能存在部分安全性風險。      When we first built AWS Lambda, we chose to use Linux containers to isolate functions, and virtualization to isolate between customer accounts.                      AWS Lambda 虛擬化架構 (左) 為之前的設計 (右) 為採用 KVM &amp; VMM 技術的設計            因此，在這篇 Paper 中，主要提到了 firecracker 評估使用虛擬化技術設計時存在六項重點考量：      Isolation: 需要具備安全的隔離環境使用戶在運行應用時，能避免資料洩漏、非法提權等安全性問題   Overhead and Density: 為了盡可能使單一機器的硬體資源應用最大化，該技術需要能夠提供運行至少數千個 microVM 執行環境 (Lambda function)   Performance: 執行效能要能貼近使用原生實體機器 (Bare-metal) 的執行效能，換句話說能降低因為硬體指令轉譯的執行時間   Compatibility: 需要能夠讓用戶執行應用時運行 Linux 支持的函式庫和執行檔，以客戶無需進行程式碼修改或是重新編譯   Fast Switching: 能夠盡可能快速的啟動執行環境 (microVM) 和清除執行環境   Soft Allocation: 存在資源動態調整機制，能夠允許虛擬執行環境分配額外的 CPU、Memory 等資源。讓每個應用僅可使用消耗他所需要的資源，而不是有權使用的系統資源   在這樣的條件下，論文 2.1 中的細節便是在具體討論和評估數項現有的虛擬化技術，包含：      Linux container: Linux Kernel 本身支持的容器化技術，使 Linux process 存在於獨立的執行環境 (namespaces)，並達到 process-level 的隔離，包含 user IDs (uids), process IDs (pids) 及 network interface，並且能夠利用 chroot 機制隔離執行的檔案系統。同時，利用 seccomp-bpf 更可以達到 process 執行系統呼叫的限制 (syscall)。在相關的研究中，一般啟動 Ubuntu Linux (15.04) 版本的安裝需要 224 syscalls 及 52 個獨立的 ioctl 操作。   Language-Specific Isolation：例如 JVM 透過劃分 Heap size 和虛擬執行環境，於記憶體空間分配支持的虛擬執行環境   硬體和 Kernel 支持的主流虛擬化技術：Intel VT-x、KVM、QEMU。在論文中提到常見的 KVM 和 QEMU 組合通常增加了執行虛擬化上的複雜度，由於 QEMU 專案本身包含了大於 140 萬 (1.4 million) 的程式碼，並且至少需要 270 個系統呼叫操作 (syscall)，若使用這項基礎再疊加使用 KVM，則會再另外增加了 120,000 行程式碼。   因此，在評估和主流虛擬化技術比較這樣的背景下，AWS Firecracker 借鑒了許多解決方案而在眾多項目中選擇一個適當的平和。同時，基於 AWS 內部許多團隊，維運基礎架構都採用 Linux 系統，促使 Firecracker 在設計的哲學上的這項決定。更重要的是，Firecracker 更之所以遵循沿用 Linux Kernel 本身就支持的技術，而不是重新實作替代它，正是因為這些功能行之有年，並且具備高質量、成熟的設計 (例如：scheduler、TUN/TAP network interface)，也能讓 AWS 原本的團隊使用熟悉的 Linux 工具和維運流程執行除錯。例如：採用 ps 即可列舉機器上運行的 microVM，其他 Linux 本身支持的工具 (top、vmstat 甚至是 kill) 均可以在預期的操作下管理 Firecracker。   基於這項原因，Firecracker 使用了 KVM 作為主要的虛擬化執行基礎，並且實作 VMM (Virtual Machine Monitor) 元件以滿足管理 KVM 執行環境的需要。      Our other philosophy in implementing Firecracker was to rely on components built into Linux rather than re-implementing our own, where the Linux components offer the right features, performance, and design    KVM 在這樣的基礎下做了哪些事？   執行硬體層級的虛擬化 (HVM) 及資源分配，例如：CPU、處理記憶體管理、分頁 (Paging) 等。   AWS Firecracker 實作   在 Firecracker 的實作中，以 Google crosvm 作為基礎，移除了大量不必要的裝置，例如：USB、GPU 以及 9p 檔案系統協議 (Plan 9 Filesystem Protocol)。在這樣的基礎下，Firecracker 以 Rust 語言為主增加了額外約 2 萬行的程式碼；同時修改了約 3 萬行的程式碼並且開源公開。                     Firecracker 架構            Firecracker 同時模擬了有限的一些 I/O 裝置，例如：網路卡、磁碟、序列端口 (serial ports)、i8042 支持 (PS/2 鍵盤的控制器)；與 QEMU 相比，QEMU 相對複雜許多，其支持多餘 40 種不同的裝置，包含 USB、影像和音訊裝置。   更細部的設計架構如下：                     Firecracker 細部設計架構 (source)            在 Firecracker 中採用了 virtio 作為網路和磁碟裝置的模擬，其中大約佔 Firecracker 1, 400 行 Rust 程式碼。同時 Firecracker 也提供了 REST API 設計，使其能夠使用 HTTP 的用戶端直接與其互動 (例如：curl)。   總結來說，Firecracker 旨在提供以下機制 3 4:      設定 KVM   提供裝置模擬，包含模擬 SSD、NIC (網卡) 等，即使沒有那麼多裝置在實際的硬體 (AWS Lambda Host) 上，使用 virtio 使得其可以虛擬化這些裝置   執行環境效能的隔離 (採用 cgroup)   為 Serverless 提供優化的效能 (5-8 Mb 的 Linux 啟動時間可以縮短為 100ms 以內、更微小的 Kernel 更可以縮短為 5ms)   資源限制 (Rate Limiter)   在 Firecracker 中的硬體裝置涵括了限制配額的機制，包含可以限制 Disk IOPS (I/O Per Second)、PPS (Packets Per Second for network)。在 Firecracker 提供了使用 API 設定 microVM 可用的資源請求，包含 CPU、磁碟 I/O、網路吞吐等。   其資源限制機制採用 virtio 本身支持的資源限制功能，以網路裝置來說，可以是以下的配置機制 (rx_rate_limiter)：   PATCH /network-interfaces/iface_1 HTTP/1.1 Host: localhost Content-Type: application/json Accept: application/json  {     \"iface_id\": \"iface_1\",     \"rx_rate_limiter\": {         \"bandwidth\": {             \"size\": 1048576,             \"refill_time\": 1000         },         \"ops\": {             \"size\": 2000,             \"refill_time\": 1000         }     } }   安全性 (Security)   為了實踐安全性的最佳化，Firecracker 在部署階段需要充分避免一些因為 Linux kernel 或虛擬化技術可能帶來潛在的安全性問題，例如：Intel Meltdown、Spectre、Zombieload 等安全性漏洞。因此，在生產環境中，為了解決這項顧慮，Firecracker 實踐了幾項部署重點：      關閉 Symmetric MultiThreading (SMT, aka HyperThreading)   Kernel Page-Table Isolation, Indirect Branch Prediction Barriers, Indirect Branch Restricted Speculation and cache flush mitigations against L1 Terminal Fault   啟動部分 Kernel 參數包含 Speculative Store Bypass mitigations   關閉 swap 和 samepage merging   避免共享檔案 (解決 timing attacks like Flush+Reload and Prime+Probe)   以及使用建議的硬體設備以解決 RowHammer 攻擊技術   相關的 Firecracker 生產環境部署建議同時列舉於以下文件中：      Production Host Setup Recommendations   同時為了避免 Firecracker VMM 執行操作的過程出現任何非預期行為 (例如：安全性漏洞允許植入惡意代碼)，在 Firecracker 中實現了使用另一層沙箱 (Sandbox) 提供額外隔離的保護。在 Firecracker 的設計稱之為 Jailer。   雖然是這樣說，但在 Paper 中提到的具體實作，仍為使用 Linux container 提供的技術執行，包含：      以 chroot 機制隔離執行的檔案系統   以 namepsace 隔離執行環境、pid、network namespaces   移除 System privilege (基於 Linux Capabilities 功能 5)   以 seccomp-bpf profile 設定允許呼叫的 syscall                     Firecracker Jailer            在 jailer sandbox 配置的 chroot 目錄中，裡面僅包含 Firecracker 編譯的執行檔、/dev/net/tun、cgroup 控制檔案和 microVM 所需的資源。並且，預設情況下 seccomp-bpf profile 設定了 24 個系統呼叫操作 (syscalls) 和 30 個 ioctls 操作為白名單。   不過就我的研究，如果我理解正確，似乎 Firecracker 在 seccomp filter 上面在最近的版本多了不少 syscalls 支援:      Firecracker default seccomp filters (x86_64)   Firecracker seccomp integration test case   Firecracker 與 AWS Lambda 架構之間的關係 (High-level architecture)   在 Firecracker 設計出來後，AWS 便逐漸於 AWS Lambda 的底層架構中導入使用。使用 AWS Firecracker 允許 Lambda 的架構在每個執行的節點 (Lambda worker) 運行數千個 microVM。   Lambda High-level to low-level architecture   AWS Lambda 從上層到下層的架構可以由遠至近如下：   (1) 用戶透過事件經由 Frondend service 觸發 Lambda function (可以是 API Gateway, 其他來源等)，會由 Worker Manager 定義配置部署可用的執行機器 (Lambda Worker)                     AWS Lambda 觸發的架構流程            (2) 一旦觸發後，Frondend service 交付由 Worker Manager 會遵循調度演算法 (sticky routing) 盡可能將觸發對象黏著在特定的 Lambda Worker 機器上，並且建議觸發的對象 (invoke service) 直接將請求的內容 (payload) 直接轉送到目標的 Lambda worker 機器上，減少觸發上的延遲和來回交互請求 (round-trip)。                     AWS Lambda 事件觸發的流程            (3) 在每個 Lambda worker 提供了 slot 這個抽象物件，該抽象物件即客戶預先載入的 Lambda function 應用程式碼 (Lambda function code)，並且在後面每次觸發的行為上盡可能的重複使用這個執行環境 (slot)   重點在於 Firecracker 於 Lambda Worker 中部署的機制，每個 Lambda Worker 可以視為一個 Bare-metal 的機器，上面運行著 Firecracker VMM 用於管理多個 MicroVM (Lambda function, slot)；每個 microVM 包含了客戶的執行環境 (sandbox) 和客戶的應用程式碼，以及一個 shim control process 用於採用 TCP/IP socket 和 Micro Manager 互動的元件。   (MicroManager 可以視為 Lambda data plane 和 control plane 互動的元件)      MicroManager provides slot management and locking APIs to placement, and an event invoke API to the Frontend                      Lambda Worker 中的細部架構            同時 MicroManager 部分也確保存在小量預先啟動的 MicroVMs，以確保有放置請求的即時需要。這是因為即使 Firecracker 能縮短在 125ms 內啟動，這樣的啟動時間可能仍不足以滿足 AWS Lambda 客戶快速啟動擴展的需要，並且可能會部分阻塞用戶的執行請求，因此在實務中，存在類似這樣 pre-warm 的機制。   Firecracker I/O Path   當 AWS Lambda 中的應用執行寫入操作時 (假設 Guest OS 中的應用希望寫入檔案到磁碟)，此時會交付由 virtio driver 處理該操作，並且由 virtio driver 將其放置到共享記憶體 (shared memory) 中，並且於系統 Ring Buffer 進行緩衝。然後，Firecracker 將被喚醒執行 I/O 操作，並且將該寫入操作真實的寫進實體磁碟當中。6   實際遷移到 AWS Firecracker 的執行   論文中提到 AWS 從 2018 年開始將 AWS Lambda 的客戶從 EC2 運行容器 (per function per container) 的基礎平台轉移到 Firecracker。在遷移過程中，並無可用性中斷、延遲或其他指標層面問題。   不過，在 AWS 內部團隊在遷移過程中，一些小問題也因為這樣的遷移暴露出來，例如前面提到為了安全性考量關閉了 Symmetric MultiThreading (SMT) 機制 (過去的部署中是開啟的)，使得使用 Apache HttpClient 應用執行的行為因為一些執行緒 (Thread) 相關的 bug 也因此暴露，並且存在於過去的 AWS SDK 版本中，需透過修補依賴函式庫解決這項問題。   但在 AWS 內部團隊完成遷移後，便開始實際將外部客戶的相關基礎建設逐步遷移至 AWS Firecracker 為基礎的設施，並且獲得巨大的成功。   同時，有鑒於涉及未來安全性補丁的修復和系統更新，由於傳統使用 rpm、yum 等套件管理工具進行管理的變因太多，可能導致軟體一致性問題產生，AWS 團隊採用了 immutable infrastructure 的策略來完成這項工作，即透過使用新版本的 AMI (Amazon Machine Image, 用於 EC2 的啟動鏡像) 直接啟動新的 EC2 instances，並且替換舊的 EC2 instances 來完成這項工作。   Evaluation (性能評估)   在該篇論文中，Firecracker 提供了數項不同測試數據的表現，同時，在 NSDI 2020 會議上也公開了對應的測試數據7。   下列的測試採用 EC2 m5d.metal instance type，其擁有 Intel Xeon Platinum 8175M 處理器 (48 cores, hyper-threading disabled)、384GB RAM 和 4 個 840GB 的 NVMe 磁碟。   在這項測試中 Host OS 使用 Ubuntu 18.04.2 以及 Linux kernel 4.15.0-1044-aws 版本。   這項測試與幾個主要的虛擬化技術執行比較，包含：Firecracker v0.20.0、Pre-configured Firecracker、Intel Cloud Hypervisor、QEMU v4.2.0                     Firecracker 啟動時間表現            在啟動時間的定義中，啟動時間為 VMM process 執行建立 process 操作 (fork) 並且 Guest Kernel 發起第一個 init process 的時間。   從數據顯示預先配置好 IO Port 的 Firecracker 和 Intel Cloud Hypervisor，兩者環境啟動時間皆優於 QEMU。然而，要注意的是，上述的測試結果中不包含設置網路裝置，一旦加入網路裝置的設置，Firecracker 和 Cloud Hypervisor 皆會在啟動時間中增加約 20ms，然而，QEMU 則是 35ms。                     Firecracker 記憶體消耗使用表現            在記憶體的消耗表現上 (Figure 7)，可以觀察到 QEMU 本身需要 128MB 的記憶體、Cloud Hypervisor 則約為 13 MB，然而，Firecracker 僅需約為 3MB 的記憶體消耗。                     Firecracker 磁碟 I/O 操作效能評估 (使用 fio)            值得一提的是，在檔案 I/O 操作的表現上 (Figure 8 &amp; Figure 9)，該研究使用 fio 執行測試，明顯可以關注到在硬體資源能夠負荷超過 340,000 read IOPS (1GB/s at 4kB) 的情況下，Firecracker 以及 Cloud Hypervisor  僅可以被限縮使用約 13,000 IOPS (52MB/s at 4kB) 的吞吐效能。                     Firecracker 網路吞吐效能評估 (使用 iperf3)            該研究同時也採用了 iperf3 執行網路效能的測試 (針對虛擬的 tap 網路介面, MTU 為 1500 byte)。在機器能夠達到單一網路流 44Gb/s 及 46Gb/s (10 個並行傳輸) 的狀況下，Firecracker 僅可達到約 15Gb/s 的吞吐。然而，QEMU 獲得接近於 Cloud Hypervisor 的測試結果，均能擁有較好的網路吞吐性能，這裡部分歸納結論是由於 virtio 的裝置設計實作而產生的限制。   研究改進和結論   如同前面性能評估所提及的，基於 virtio 的實作因素，這使得 Firecracker 並無法取得以直接存取 PCI 裝置以接近實體機器的 I/O 吞吐性能。使得網路和磁碟 I/O 的效能存在部分限制。   然而，就論該研究的總結，與前面提及的六項主要問題呼應，AWS Firecracker 的技術著實達到其工程上的設計目標，包含：      Isolation: 以 Rust 為基礎的 VMM 允許多個用戶 (multi-tenant) 於單一機器上運行並達到執行環境隔離   Overhead and Density: Firecracker 允許單一硬體資源運行數千個 MicroVMs，以達到節省硬體資源的目的，同時帶來更低的 CPU 和 Memory 資源消耗   Performance: Block IO 以及網路吞吐效能著實存在改善空間，但著實已經滿足 AWS Lambda 及 AWS Fargate 兩者產品所需   Compatibility: Firecracker MicroVMs 運行為修改的 Linux kernel，允許客戶運行相關的應用程式碼，目前尚未發現不允許於 MicroVM 中運行的應用程式   Fast Switching: Firecracker MicroVMs 有較短的啟動時間 (150ms)，並且在多個 MicroVMs 並行啟動的狀況下保持一致的效能   Soft Allocation: Firecracker 測試允許超出 20 倍的資源配置比例，在 AWS 生環境中為允許超出實際 CPU 和 Memory 10 倍的配置比例並未存在問題   總結   Firecracker 除了於部分開源專案為虛擬化提供解決方案外 (例如：Kata container)，目前 AWS Firecracker 更是已經導入使用於 AWS 的基礎產品建設中，包含 AWS Fargate 和 AWS Lambda。   這樣的基礎設施改進同時也為客戶帶來更大的優勢，借助 Firecracker 的設計，使得 AWS Fargate 將運算定價折扣甚至達到 50% 的成本優化 (AWS Fargate Price Reduction – Up to 50%)。   基於對於這樣的技術感興趣，我著實閱讀了有關 Firecracker 整篇論文和參考部分 Firecracker 專案，歸納出上述的內容，並且花了一些時間整理這項導讀，更多訊息可以參考：      Firecracker: Lightweight virtualization for serverless applications   Firecracker project page   Firecracker source code   希望透過這樣的導讀，能夠有助於你更加了解 AWS Firecracker 這項技術。   如果你覺得這樣的內容有幫助，可以在底下按個 Like / 留言讓我知道。   延伸資源      AWS re:Invent 2018: REPEAT 1 A Serverless Journey: AWS Lambda Under the Hood (SRV409-R1)   AWS re:Invent 2019: REPEAT 1 A serverless journey: AWS Lambda under the hood (SVS405-R1)   Firecracker: A Secure and Fast microVM for Serverless Computing (Orelly)   Firecracker: Lightweight Virtualization - Opportunities and Challenges (2020)   Deep Dive into firecracker-containerd (2019)   Extending containerd - Samuel Karp &amp; Maksym Pavlenko, Amazon (2019)   Deep Dive into firecracker-containerd - Mitch Beaumont (AWS)   References                  Alexandru Agache, Marc Brooker, Andreea Florescu, Alexandra Iordache, Anthony Liguori, Rolf Neugebauer, Phil Piwonka, Diana-Maria Popa. (2020). Firecracker: Lightweight virtualization for serverless applications &#8617;                  Gerald J. Popek, Robert P. Goldberg. (1974). Formal requirements for virtualizable third generation architectures &#8617;                  How AWS’s Firecracker virtual machines work &#8617;                  AWS re:Invent 2019: Firecracker open-source innovation (OPN402) &#8617;                  Linux Capabilities and Seccomp &#8617;                  AWS re:Invent 2020: Deep dive into AWS Lambda security: Function isolation &#8617;                  Firecracker benchmarking code and data &#8617;           ","categories": [],
        "tags": ["amazon","aws","amazon web services","firecracker","virtualization","Lambda","severless","AWS Fargate"],
        "url": "https://easoncao.com/firecracker-paper-reading/",
        "teaser": "https://easoncao.com/assets/images/posts/2022/02/firecracker-paper-reading/cover.png"
      },{
        "title": "NEX WORK - 獲得國際大公司的內推機會、串連世界各地菁英：如果流浪是為了找回家的路，我們有責任把回家的路變得更美好",
        "excerpt":"我們知道獲得國際大公司的內推機會對於台灣人十分困難，為了串連海外台灣人才菁英並且開啟另類海外求職內推的機會，我將在這篇內容中與你分享你可能會感興趣的資源：NEX WORK — 一個非營利線上求職內推平台。                     (source)            NEX WORK 由一群 NEX Foundation (台灣未來基金會) 台灣熱血的工程師建置，目的在於打破對於海外求職的高門檻和增加被看見的機會，以串連在世界各地的海外菁英，建立永續的機制，並促進正向的人才循環。   NEX Foundation 台灣未來基金會是什麼？      NEX Foundation 台灣未來基金會成立於 2018 年，為美國聯邦政府核准的 501(c)(3) 非營利慈善新創機構。NEX 以美國西雅圖及台灣台北為據點，希望透過研發和經營線上的資源平台，協助海外人才在國際舞台上的職涯發展。並更進一步扮演橋樑的角色，連結活躍於世界各地的台灣人才，共同推動企業媒合、職涯諮詢、媒體實驗、社群聚會等計畫，期盼建立具有延續性的全球台灣人才互助圈。      NEX 的成立背景，來自團隊成員們的海外故事。一腳踏出熟悉的家鄉來到文化迥然的異地，學習在高度的競爭環境中生存，在面臨新的挑戰時保持堅強。然而，對於缺乏資源和當地人脈的海外遊子來說，眼前往往有許多的不容易和不安全感。    為此，我們希望透過 NEX 的運作，以互助的力量來提拔下一位追夢者，為需要幫助的人才們，創造更多的機會和協助更多夢想的實現。   基金會最初是由陳浩維 (HW. Chen) 和一群在美國工作的熱血朋友們，開始投入「NEX Foundation 台灣未來基金會」的籌備工作。(認識在世界各地的努力貢獻的團隊專家及志工)   並且，基金會於 2018 年 12 月獲得美國國稅局（IRS）批准，正式成為美國聯邦層級的非營利教育慈善機構。                     NEX Foundation - Why NEX (source)            NEX 的首要任務為建立一個信任平台來連結全球的台灣人才，系統性整合現有資源，推動相關協助計畫（如：公司內推整合、人才輔 導計畫、獎學金計畫等），期待去翻轉台灣「人才外移」的負面印象，並希望作為一個正向動力去團結大家的力量和資源，去幫助更多夢想和成就的實現。   目前 NEX Work 仍在持續投入許多非營利專案、包含定期舉辦社群活動和分享，為更多台灣人開啟海外求職的契機。你也可以關注在以下連結獲得更多資訊：      Website: https://nexf.org/   LinkedIn: https://www.linkedin.com/company/nexfoundation/   Facebook: https://www.facebook.com/NEXFoundation/   NEX Community: https://www.facebook.com/groups/nexfoundation            (Facebook 社團 - 不定期發布社群講座和活動資訊)           NEX Media Lab: https://media.nexf.org/   什麼是 NEX WORK？為什麼會有 NEX WORK？      NEX WORK 是一個非營利線上求職內推平台，目前仍在 Beta 階段，目的在於連結世界各地菁英，創造團結互助的力量。   尤其在日趨競爭的就業環境、對外國人不友善的簽證流程、其它族裔互助合作壯大自我（甚至遊走法律邊緣）等等現實情況下，我們認為幫助自己人為理所當然，且勢在必行。1   因此，作為一個推進的力量，支持和協助台灣人才的職涯發展，團隊成員在工作之餘努力的推動 NEX WORK 專案，且不斷的仍在持續收集用戶回饋和優化。   透過 NEX 設計的內推系統，讓台灣人陪著台灣人在國際職涯路上打開第一扇窗或衝刺最後一哩路。NEX WORK 快速整合求職供需鏈，讓你在同公司內找到那一把手，爭取時間就是爭取機會。   誰在使用 NEX WORK?   NEX WORK 作為初始試驗平台，目前已經累積許多在各個世界知名公司的台灣人自發性的在上面提供內推的管道 (包含我自己)。   目前平台上除了有知名的科技公司的台灣海外菁英自發性提供內推渠道 (例如：Facebook(Meta), Amazon, Apple, Google, Dropbox, Cisco)，也包含其他知名會計、加密貨幣交易所等。如果你有興趣提供相關的機會，也可以參考以下資訊透過註冊系統開啟這項渠道。   如何使用 NEX WORK   第一步可以透過以下連結訪問 NEX WORK 平台：      NEX WORK: https://work.nexf.org/   界面十分直覺 (如果覺得很難用請不吝透過右側的 Feedback 表單與我們分享使用者反饋)，下捲即可以看到目前有哪些公司，以及該公司存在的推薦人數。                     NEX WORK 的介面            為了快速幫助你了解平台的相關特性，以下分為兩種使用情境分別提供更多細節：   A. 若你要尋求內推機會   你可以透過右上角的註冊按鈕 (或是點擊這裡註冊) 填寫基本資料註冊帳戶並且完成信箱驗證。   完成註冊後，你可以選擇要尋求內推的公司，以下以 Amazon 為例：                     選擇尋求內推機會的公司            點擊後你可以查看有關提供內推渠道的推薦人以及查看更多資訊。   為了避免尋找不是活躍的推薦人讓推薦請求石沉大海，你也可以透過系統的幾項關鍵指標，例如：      推薦了幾名申請人   最近內推時間                     選擇內推的推薦人            點擊「幫我內推」即可以填寫必要基本資料及上傳履歷資訊：                     填寫必要基本資料和上傳履歷、職位細節            完成申請後，點擊 「檢視我的內推紀錄」即可查看你的內推資訊：                     檢視自己的內推紀錄            請注意：NEX WORK 並不保證推薦人一定會幫助你內推，內推的推薦人仍然會針對你的經歷及你提供的各種資料來決定是否內推，並非來者不拒的盲目內推。   給申請者的建議 - 履歷撰寫   請提供詳實的自我經驗總結介紹及必要資訊，幫忙的朋友看了你提供的資料後將會依情況決定是否要花時間內推。   若履歷上經驗不足、或是你沒有提供備註註明所需的資訊，為了維持內推的品質而被 HR 列為黑名單，仍然有機會拒絕你的請求。   若你對於履歷格式不確定如何開始，可以參考以下撰寫範例：      This Is What A GOOD Resume Should Look Like   請注意上述履歷通常比較適用美國企業 (例如：不需要特別放 profile photo、個人簡介)，不過可能會隨著國家有所區別，網路上有許多資源，請依照自行狀況斟酌。   給申請者的建議 - 內推就一定會有面試機會嗎？   通常內推是無法保證一定有職缺面試、錄取的機會 (我自己協助內推的經驗仍然是有被錄取的候選人寥寥無幾)。   但各公司的內推機制通常提供了比直接從網路上海投更容易被招聘團隊看見的機會，甚至可能縮短你在前期等待回應的時間。   內推通常為推薦人主動提供這樣的機會，並且很常會需要花費額外的時間。甚至必須要花費一陣努力 (私下了解你的背景、跟 HR 追問進度)。    在付出這麼多額外的時間後，仍在招聘公司許多考量下，沒有被錄取也十分常見，因此，請記得保持禮貌及感謝每一位幫助的海外台灣人。    B. 註冊成為推薦人 (我是某公司員工，我願意為串連海外工作機會盡一份心力)      你可以透過右上角的註冊按鈕，並且點擊「註冊成為推薦人」(或是點擊這裡註冊成為推薦人) 填寫基本資料註冊帳戶：                     註冊成為推薦人            並且可以於「公司名稱」一欄選擇或是新增你目前能夠協助推薦的公司完成註冊：                     選擇或是新增協助推薦的公司            你可以進一步編輯相關的個人資料以利尋求內推機會的人更加了解你。如此一來就完成必要資料的填寫，尋求推薦的候選人便可以到首頁檢視並且透過您所提供的管道提交必要材料。   一旦有新的推薦請求，你可以在「檢視內推申請」查看待處理的推薦請求：                     檢視待處理的內推申請            常見問題   註：若你是推薦人，目前 NEX WORK 工程團隊已經收到「內推紀錄」和「內推申請」的相關使用者反饋，一個是尋求內推機會的紀錄、一個是協助內推的紀錄，請記得不要搞混哦                     檢視內推紀錄            總結   希望這篇內容能夠對你有所幫助並且更加了解 NEX WORK 平台。若有任何關於 NEX WORK 的任何建議，也歡迎透過右側的 Feedback 表單或是以下聯繫方式，讓我們一起把 NEX WORK 變得更好：      Facebook 專頁私訊 - NEX Foundation 台灣未來基金會   Email: contact@nexf.org   此外，在 NEX Foundation 我們相信「今日的路人是明日的引路人」，延續 Give and Take 的精神，如果你願意一同攜手支持或是加入全球志工團隊的一份子讓我們啟動正向迴圈2，幫助更多台灣人走向世界，讓回家的路變得更好。你可以透過以下連結了解更多資訊：      NEX Foundation - Get involved   NEX Foundation - SUPPORT TO MAKE THE CHANGE   我同時也在 NEX Foundation 為串連台灣人才於國際舞台上的職涯發展貢獻己力，你可以透過 NEX WORK 附上 CV 提交內推申請 (需註冊登入) 以引薦更多像你這樣的優秀人才，或是透過我的 LinkedIn 與我聯繫。      NEX WORK：申請內推 (需登入)   如果你覺得這樣的內容有幫助，可以在底下按個 Like / 留言讓我知道。                  ptt, Amazon各職位內推 讓台灣人把亞麻填滿滿 &#8617;                  ptt, NEX Foundation台灣未來基金會號召全球熱血鄉民 &#8617;           ","categories": [],
        "tags": ["nex work","nex foundation","work","volunteer","taiwanzonian"],
        "url": "https://easoncao.com/nex-work/",
        "teaser": "https://easoncao.com/assets/images/posts/2022/03/nex-work/nex-work-logo.png"
      },{
        "title": "[AWS][EKS] Best practice for load balancing - 1. Let's start with an example from Kubernetes document",
        "excerpt":"This article is sharing the best practice for doing load balancing on Amazon EKS, learn what is advantage and disadvantage of using different controller. We will discuss more detail about what is the problem of using default Kubernetes service deployment as mentioned on official document.   Understand the default Kubernetes load balancing   An overview of externalTrafficPolicy   I have many occurrences to see Kubernetes administrators are not very familiar with the Kubernetes network flow, and feel struggling about that when they need to diagnose networking issue, especially for users using managed Kubernetes cluster service. But I think that’s normal to see this gap because it reflects Kubernetes is doing encapsulation perfectly, causes you are unable to easily troubleshoot any real-world failures unless you had deeply understand its design.   Before walking through the detail about the load balancing, it is required to understand the fundamental knowledge of Kubernetes load balancing and its effect when defining your YAML files.   In the Kubernetes, it provides External traffic policy, so you can set this field (spec.externalTrafficPolicy) in your Kubernetes service deployment to control the flow, and decide how to route the traffic from external. Kubernetes offers two options for this policy: Cluster and Local, let’s have a deep overview to see how it works:                     Figure 1: externalTrafficPolicy            By default, the kube-proxy is performing this layer of load balancing by using iptables. Based on the Pods you are running, it will create rules in  your iptables and uses random mode (--mode random) to perform the load balancing based on the probability. For example, if you have 3 Pods need to be distributed, kube-proxy will take the responsibility to add required iptables rules with defined probability, and try to balance the load:                     Figure 2: Kubernetes service overview (source)            I am not going to drill down into too much detail as it can increase the complexity of this article, however, if you are interested to learn how this translation happens, you can review the iptables rules on your host to see what’s going on.   # An example of iptables rules -A KUBE-SVC-XXXXX -m comment --comment \"default/app\" -m statistic --mode random --probability 0.20000000019 -j KUBE-SEP-AAAAAA -A KUBE-SVC-XXXXX -m comment --comment \"default/app\" -m statistic --mode random --probability 0.25000000000 -j KUBE-SEP-BBBBBB -A KUBE-SVC-XXXXX -m comment --comment \"default/app\" -m statistic --mode random --probability 0.33332999982 -j KUBE-SEP-CCCCCC -A KUBE-SVC-XXXXX -m comment --comment \"default/app\" -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-DDDDDD -A KUBE-SVC-XXXXX -m comment --comment \"default/app\" -j KUBE-SEP-EEEEEE   As mentioned in Figure 1, when externalTrafficPolicy=Cluster, it can have a scenario will route the traffic to other Nodes if you deploy Pod(s) on them. By relying on the iptables rules, this policy can accomplish the load balancing by redirecting them to other Nodes. In theory, this can bring the traffic jump out of the original Node.   When externalTrafficPolicy=Local, it limits the traffic only can be redirected on the same Node; however, the behavior of doing load balancing through the iptables still happens. If you have multiple Pods running on the single Node, the traffic can be routed to one of them.   Deep dive into the load balancing behavior - An example from K8s document   Let’s see an example mentioned at official Kubernetes document1:   apiVersion: v1 kind: Service metadata:   name: nginx-svc   labels:     app: nginx spec:   type: LoadBalancer   ports:   - port: 80     protocol: TCP   selector:     app: nginx   If you use AWS as cloud provider and deploy the service, it generally will create an Elastic Load Balancer (Classic Load Balancer) and provide the traffic load balancing. The Elastic Load Balancer will be managed by the in-tree load balancer controller2, which is implemented in Kubernetes source code; hence, you can simply provision the Elastic Load Balancer on AWS seamlessly.   Looks familiar, right? The example above is quite common if you find tutorial on somewhere. Maybe that is exactly same configuration running in your production environment.   But here is the problem: by default, Kubernetes implements another layer of load balancing, which is backed with kube-proxy. Let’s say if you have two worker nodes (Node-1 and Node-2), and each node have Pods running on it (Pod-1, Pod-2 on Node-1; Pod-3 on Node-2), using default option (externalTrafficPolicy=Cluster). On AWS, the traffic flow generally is representing as below:   Case 1   The default Kubernetes service will expose your application with a specific service port to provide external accessibility (NodePort), and establish relevant iptables rules to perform NAT traslation by replacing the IP address of the destination field.   With this design, this can be a happy case if kube-proxy doesn’t redirect the request to other host, which can be outlined as:   client -&gt; Load Balancer -&gt; Node-1 (NodePort) -&gt; iptables rules -&gt; Pod-1 on Node-1   Case 2   However, what if the iptables forward the traffic to other Nodes?   client -&gt; Load Balancer -&gt; Node-1 (NodePort) -&gt; iptables rules -&gt; Pod-3 on Node-2    On the other hand, if you deploy a Kubernetes service like this, the traffic flow can be routed as two particular phenomena:                     Figure 3: The traffic flow when working with externalTrafficPolicy            As you can see, no matter what it is, the behavior seems like doesn’t provide a better route because it definitely increases the number of hops for the traffic flow.   What about externalTrafficPolicy: Local? Does it work better?   Follow the example as mentioned in the previous paragraph, let’s say if you have two Pods (Pod-1 and Pod-2) running on the same Node (Node-1). The traffic flow of this policy generally can be breaking down as below:   client -&gt; Load Balancer -&gt; Node-1 (NodePort) -&gt; iptables rules -&gt; Node-1 (Target Pod-1) client -&gt; Load Balancer -&gt; Node-1 (NodePort) -&gt; iptables rules -&gt; Node-1 (Target Pod-2)   When load balancer move the request to the backend (Node-1), the probability to forward the request by iptables rules to the Pod-1 and Pod-2, is 50% chances.   On the other hand, the traffic firstly pass through the Elastic Load Balancer, and do the routing again in the system level (iptables), which means the architecture will perform the load balancing twice.   With no doubt, it did not offer the best path for the traffic routing.   The reason why you will see your targets are failing the health check even Pods are running   If externalTrafficPolicy=Local and you have multiple Nodes running behind your Elastic Load Balancer, you probably will see some Nodes will fail the health check, which can be expected.   That’s because if some Node doesn’t run the service’s backend Pods so it cannot pass the health check.                     Figure 4: Some Node doesn’t pass health check due to externalTrafficPolicy            In general, it doesn’t impact anything because the ELB will ensure only healthy targets can be routed; however, in this case, it doesn’t perfectly distribute the load with Elastic Load Balancer and offer high availabilty when we have multiple Pods. If the Node down, it can impact all Pods running on it.   What’s wrong with externalTrafficPolicy?      So, looks like using externalTrafficPolicy=Cluster is a good option?    Imagine you have a long running connection is jumping out of the first Node, unfortunately, the first Node is having issue such as hardware failure, intermittent connectivity problem … etc. In the end, it is going to be down. In this case, if any existing connections forwarded from other Nodes, the connections will be impacted and cannot response back to the origin correctly. In general, the Node down can cause the packet loss because the connection route is established in the middle:   (If you have established connection passed the Node, here is an example of the breaking route situation if the Node-1 in the middle is down.)     client -&gt; Load Balancer -&gt; Node-1 (NodePort) -&gt; iptables rules -&gt; Target Pod-2 on Node-2    If you reviewed the flow of Figure 3, connections can be routed to different paths and it can be hard to predict once you deployed many Pods. It also increase the complexity if you would like to trace the networking flow during the problem diagnostic.   When having a large scale scenario (e.g. deploy 100, 500 even 10,000 Pods), this also can potentially bring the system level issue, or, result in the packet loss, such as network latency increased due to kernel needs to compare several iptables rules when a new connection comes in; or, reach out to the kernel limits for the networking stack, because Linux kernel needs to track of them when working with iptables, and insert the rules on the system level. One common issue is to fill out the connection tracking table (conntrack) of the Linux kernel when the scale grows.   Summary   In this article, it explains the behavior of load balancing on Kubernetes. This article also brings you an overview and learn what issue can occur if you follow the default Kubernetes example to deploy your Elastic Load Balancer.   Now we have deep-level understanding of the Kubernetes load balancing, let’s start with more discussion regarding the load imbalancing problem with the current architecture on Amazon EKS in the next article.      Best practice for load balancing - 1. Let’s start with an example from Kubernetes document   Best practice for load balancing - 2. imbalanced problem   Best practice for load balancing - 3. what controller should I use   References                  Kubernetes service - Type LoadBalancer &#8617;                  Kubernetes source code - aws_loadbalancer.go &#8617;           ","categories": [],
        "tags": ["aws","amazon web services","EC2","Elastic Compute Cloud","amazon","ELB","ALB","Load Balancer","Elastic Load Balancer","ALB Ingress Controller","Kubernetes","k8s","EKS","Elastic Kubernetes Service","AWS Load Balancer Controller"],
        "url": "https://easoncao.com/eks-best-practice-load-balancing-1-en/",
        "teaser": "https://easoncao.com/assets/images/posts/2022/04/eks-best-practice-load-balancing/instance-target.png"
      },{
        "title": "[AWS][EKS] Best practice for load balancing - 2. imbalanced problem",
        "excerpt":"This article is sharing the best practice for doing load balancing on Amazon EKS, learn what is advantage and disadvantage of using different controller. We will discuss more detail about the imbalanced problem after applying controller to deploy the Elastic Load Balancer.   The load imbalanced problem   Follow the example as mentioned in the previous article, if you deployed a Kubernetes service and noticed the utilization on your backend application is not balanced; or, if you are using AWS Load Balancer controller, Traefik, nginx-ingress controller by finding the Elastic Load Balancer wasn’t correctly separate the loads (when using instance mode to register your Pods as targets), and you may find the imbalanced traffic, that’s the major topic in this article would like to talk about: discuss how to improve and optimize it.   Problem description   Let’s say if I am deploying 4 Pods in my Kubernetes cluster, which is using the default deployment as mentioned below to expose my Kubernetes service:   $ kubectl get pod -o wide NAME                                READY   STATUS    RESTARTS   AGE   IP nginx-deployment-594764c789-5s668   1/1     Running   0          30m   192.168.42.171 nginx-deployment-594764c789-9k949   1/1     Running   0          30m   192.168.39.194 nginx-deployment-594764c789-b292m   1/1     Running   0          33m   192.168.29.24  nginx-deployment-594764c789-s226c   1/1     Running   0          30m   192.168.15.158   The Kubernetes service:   apiVersion: v1 kind: Service metadata:   name: nginx-svc   labels:     app: nginx spec:   type: LoadBalancer   ports:   - port: 80     protocol: TCP   selector:     app: nginx   To better understand the problem I am describing in this post, the application I deployed will response Pod IP address to let us know which one received the request:                     Figure 1. Testing the service and see the response from the backend.            After running a loop and making at least 79 HTTP requests in my test, I get the following response to know how the load has been distributed:      192.168.42.171: 12 times   192.168.39.194: 33 times   192.168.29.24: 23 times   192.168.15.158: 10 times   According to the testing, we can see the load is not very evenly distributed.   Why this could happen?   As mentioned in the previous post, whether you are defining externalTrafficPolicy=Cluster or externalTrafficPolicy=Local, the routing behavior is relying on iptables(or ipvs) can be unpredictable. Because it is doing second layer of load balancing, which is totally unnecessary for increasing a hop in AWS VPC.   Elastic Load Balancer in AWS already provides a straightforward solution to balance your loads, and its algorithm will try to distribute the requests to all backend servers as even as possible. Doing load balancing in Kubernetes network generally is increasing the complexity of your architecture, and make traffic can be hard to trace; or, even worse, cause the imbalanced issue as you can observe.   This also makes the load balancing became unpredictable. Although the traffic send to the registered EC2 instance can be evenly distributed; however, it doesn’t mean the load can be separated to Pods as well. You will never know which Pods will be routed due to this load balancing layer implemented by Kubernetes networking.   No matter choose Traefik, nginx-ingress, if you are still following the default load balancing pattern offered by upstream Kubernetes code, then you can expect the traffic can come with load imbalanced.   How to optimize the load balancing?   The major problem is the default load balancing behavior can involve the Kubernetes load balancing and add a hop for the traffic. So you may start to wondering how to better resolve this problem; however, there is no specific feature can be adjusted on Kubernetes to remove the default load balancing, but it still could be possible to skip the Kubernetes load balancing and forward the traffic to Pods directly.   If you are running Pods on Amazon EKS and using default AWS VPC CNI Plugin1, you can expect your Pods should have dedicated secondary private IP address that can be communicated within your AWS VPC network; therefore, it also means that the IP address can be registered to your Elastic Load Balancer as backend target. The flow can be:   Client -&gt; NLB (forawrd request to IP target) -&gt; Pod IPs (Reach out to Pods directly)   For Application Load Balancer (ALB) and Network Load Balancer (NLB), both provide a feature that you can register backend targets with IP addresses (NLB, ALB. Note: Classic Load Balancer doesn’t offer this option). We can simply to associate these Pod IP addresses as backend targets instead of using instances. As long as the Pod IP addresses are reachable, it can move the request be forwarded to the backend Pods by skipping the Kubernetes load balancing behavior.   Using IP mode   So how to register Pod IP addresses in Elastic Load Balancer? A seamlessly way is to deploy your Kubernetes service and use AWS Load Balancer Controller2 to enable this feature. Instead of using the default Kubernetes controller to deploy your Elastic Load Balancer, using AWS Load Balancer Controller helps you manage load balancer resource including all functionality features and different type of load balancer such as NLB, ALB, both are can be supported by the controller. After installing the AWS Load Balancer on your EKS cluster, you can enable the IP registration type for your Pods by simply adding annotations to the deployment manifests.   Network Load Balancer (NLB)   Here is a deployment sample that use IP targets with pods deployed to Amazon EC2 nodes. Your Kubernetes service must be created as type LoadBalancer:   apiVersion: v1 kind: Service metadata:   name: my-service   annotations:     service.beta.kubernetes.io/aws-load-balancer-type: \"external\"     service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: \"ip\"   ... spec:   type: LoadBalancer   ...   Application Load Balancer (ALB)   To deploy application load balancer on Amazon EKS through the AWS Load Balancer Controller, you generally will create an Ingress object in your deployment. With the AWS Load Balancer Controller, it also provides supported annotation that can register pods as targets for the ALB. Traffic reaching the ALB is directly routed to pods for your service. Here is an example:   apiVersion: networking.k8s.io/v1 kind: Ingress metadata:   namespace: game-2048   name: ingress-2048   annotations:     alb.ingress.kubernetes.io/scheme: internet-facing     alb.ingress.kubernetes.io/target-type: ip     ...   In the AWS EKS documentation, it also mentioned detailed guide regarding how to deploy these two load balancers and share an example by using IP target to register your Pods. If you are interested to learn more, please check out to the following documents to get more detail:      Network load balancing on Amazon EKS   Application load balancing on Amazon EKS   By using IP mode, it totally removes the layer of load balancing manipulated by Kubernetes. This generally forward requests to the Pods without doing second forwarding:                     Figure 2. Register Pods with IP mode            Are you sure it is balanced? Let’s have a test!   This time I used the same testing strategy as mentioned in the first problem description section and ran four Pods associated with Network Load Balancer using IP mode, which is showing below:   $ kubectl get pods -o wide NAME                                READY   STATUS    RESTARTS   AGE     IP               NODE                                              NOMINATED NODE   READINESS GATES nginx-deployment-75d48f6698-b5fm7   1/1     Running   0          35m     192.168.17.15    ip-192-168-5-38.ap-northeast-1.compute.internal   &lt;none&gt;           &lt;none&gt; nginx-deployment-75d48f6698-l4gw5   1/1     Running   0          2m45s   192.168.27.143   ip-192-168-5-38.ap-northeast-1.compute.internal   &lt;none&gt;           &lt;none&gt; nginx-deployment-75d48f6698-q2q57   1/1     Running   0          41m     192.168.22.126   ip-192-168-5-38.ap-northeast-1.compute.internal   &lt;none&gt;           &lt;none&gt; nginx-deployment-75d48f6698-x5m25   1/1     Running   0          2m45s   192.168.14.48    ip-192-168-5-38.ap-northeast-1.compute.internal   &lt;none&gt;           &lt;none&gt;   After passing at least 50 requests, I can see the request distributions are showing below:      192.168.17.15: 10 times   192.168.27.143: 12 times   192.168.22.126: 14 times   192.168.14.48: 13 times   For each target, it nearly have ~25% chances will be routed evenly by the Network Load Balancer. Because it skip the load balancing layer of the Kubernetes, it will follow the routing algorithm3 and separate load evenly as we expected.   I tried to use IP mode but the traffic still get imbalanced   In my testing, I was running a couple of Pods with nginx image and provided simple web server in my backend. The scenario in this article mentioning generally is describing all targets were using stateless HTTP connections. However, in some cases, it could be possible ELB might unequally route traffic to your targets if:      Clients are routing requests to an incorrect IP address of a load balancer node with a DNS record that has an expired TTL.   Sticky sessions (session affinity) are enabled for the load balancer. Sticky sessions use cookies to help the client maintain a connection to the same instance over a cookie’s lifetime, which can cause imbalances over time.   Available healthy instances aren’t evenly distributed across Availability Zones.   Instances of a specific capacity type aren’t equally distributed across Availability Zones.   There are long-lived TCP connections between clients and instances.   The connection uses a WebSocket.   Generally speaking, if the client or any configuration can cause sticky session, it still have possibility can get the traffic imbalanced. The detail can refer to the following article on AWS knowledge center:      Why is Elastic Load Balancing unequally routing my load balancer traffic?   But overall, using the IP mode to register our Pods, literally can resolve the problem as we described due to the design of Kubernetes service networking.   A summary if you would like to optimize the traffic imbalanced when using AWS Load Balancer Controller   Using IP mode as register target to prevent Kubernetes additional hop   Although Elastic Load Balancer can offer an option to register your targets by instances, however, it generally would be suitable when you are running single service and expose it with a port on a dedicated EC2 instance. With Kubernetes service running on your EC2 instance but exposed as NodePort service, it can involve multiple Pods behind the service port offered on your instance due to the service load balancing. The packet can be replaced to other destination field of your Pod’s private IP address when the packet flood into the instance through Linux ipvs or iptables rules.   If the service work load is relying on Kubernetes deployment, it is recommended  such as service.beta.kubernetes.io/aws-load-balancer-nlb-target-type for NLB, alb.ingress.kubernetes.io/target-type for ALB.   Prevent to enable sticky session on ELB   It is also important to make sure the Elastic Load Balancer won’t stick your client session to specific target4 5. Although Elastic Load Balancer provides cookie-based stickiness session to bind a user’s session to a specific target, which can be achieved by configuring the load balancer attribute and also supported by AWS Load Balancer Controller as below, but to optimize the traffic imbalanced, it is recommended to avoid use the sticky session as it can potentially cause the phenomena.   # ALB alb.ingress.kubernetes.io/target-group-attributes: stickiness.enabled=true,stickiness.lb_cookie.duration_seconds=60  # NLB service.beta.kubernetes.io/aws-load-balancer-target-group-attributes: stickiness.enabled=true,stickiness.type=source_ip   Equally distribute Pods across Availability Zones   As ELB requires to strike the balance between your Availability Zones to ensure the service high availability. This helps your traffic can correctly be separated on all backend target.   Summary   In this article, it explains the practice of optimizing the load balancing and mitigate the imbalanced traffic problem when deploying service with Kubernetes. This article also brings you an overview and learn what other scenarios that you can potentially find out ELB might unequally route traffic to your backend targets.   In the next article we will review a couple of Kubernetes load balancer controllers that can be deployed on Amazon EKS and see what option can be the best practice for your environment.      Best practice for load balancing - 1. Let’s start with an example from Kubernetes document   Best practice for load balancing - 2. imbalanced problem   Best practice for load balancing - 3. what controller should I use   References                  AWS VPC CNI Plugin &#8617;                  AWS Load Balancer Controller &#8617;                  How Elastic Load Balancing works - Routing algorithm &#8617;                  Configure sticky sessions for your Classic Load Balancer &#8617;                  Sticky sessions for your Application Load Balancer &#8617;           ","categories": [],
        "tags": ["aws","amazon web services","EC2","Elastic Compute Cloud","amazon","ELB","ALB","Load Balancer","Elastic Load Balancer","ALB Ingress Controller","Kubernetes","k8s","EKS","Elastic Kubernetes Service","AWS Load Balancer Controller"],
        "url": "https://easoncao.com/eks-best-practice-load-balancing-2-en/",
        "teaser": "https://easoncao.com/assets/images/posts/2022/04/eks-best-practice-load-balancing/ip-target.png"
      },{
        "title": "[AWS][EKS] Best practice for load balancing - 3. what controller should I use",
        "excerpt":"This article is sharing the best practice for doing load balancing on Amazon EKS, learn what is advantage and disadvantage of using different controller. We will discuss what controller should you use.   Compare different controller options   Here are some common load balancing solutions that can be applied on Amazon EKS:   Kubernetes in-tree load balancer controller   This is the easiest way to provision your Elastic Load Balancer resource, which could be done by using default Kubernetes service deployment with type: LoadBalancer. In most case, the in-tree controller can quickly spin up the load balancer for experiment purpose; or, offers production workload.   However, you need to aware the problem as we mentioned in the previous posts 1 2 because it generally can add a hop for your load balancing behavior on AWS and also can increase the complexity for your traffic.   In addition, you need to aware this method only applies for creating Classic Load Balancer and Network Load Balancer (by using annotation 3).   nginx ingress controller   If you are using nginx Ingress controller in AWS, it will deploy Network load balancer (NLB) to expose the NGINX Ingress controller behind a Service of type=LoadBalancer. Here is an example for deploying Kubernetes service of nginx Ingress controller 1.1.3:   apiVersion: v1 kind: Service metadata:   annotations:     service.beta.kubernetes.io/aws-load-balancer-backend-protocol: tcp     service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: \"true\"     service.beta.kubernetes.io/aws-load-balancer-type: nlb   labels:     app.kubernetes.io/component: controller     app.kubernetes.io/instance: ingress-nginx     app.kubernetes.io/name: ingress-nginx     app.kubernetes.io/part-of: ingress-nginx     app.kubernetes.io/version: 1.1.3   name: ingress-nginx-controller   namespace: ingress-nginx spec:   externalTrafficPolicy: Local   ports:   - appProtocol: http     name: http     port: 80     protocol: TCP     targetPort: http   - appProtocol: https     name: https     port: 443     protocol: TCP     targetPort: https   selector:     app.kubernetes.io/component: controller     app.kubernetes.io/instance: ingress-nginx     app.kubernetes.io/name: ingress-nginx   type: LoadBalancer   Guess what, yes, it is still can rely on the in-tree controller. On the other hand, the problem we were mentioning can persist. It can be hard to expect which Pods will receive the traffic; however, the main issue is that an Ingress controller does not typically eliminate the need for an external load balancer, it simply adds an additional layer of routing and control behind the load balancer.                     Figure 1. An architecture overview of using nginx Ingress controller            So why to choose Nginx Ingress controller? It probably can be the reason why as mentioned in the post 4 as mentioned on the AWS Blog:      By default, the NGINX Ingress controller will listen to all the ingress events from all the namespaces and add corresponding directives and rules into the NGINX configuration file. This makes it possible to use a centralized routing file which includes all the ingress rules, hosts, and paths.   With the NGINX Ingress controller you can also have multiple ingress objects for multiple environments or namespaces with the same network load balancer.   AWS Load Balancer Controller   AWS Load Balancer Controller is similar to the in-tree Kubernetes controller and use native AWS APIs to provision and manage Elastic Load Balancers. The controller was an open-source project originally named ALB Ingress Controller because it was only provides capability to manage Application Load Balancer at the intial stage, lately, it officially renamed as AWS Load Balancer Controller 5, which is maintaining by AWS product team and open-source community.   Unlike in-tree Kubernetes controller needs to wait the upstream code to be updated, which requires you to upgrade Kubernetes control plane version if the controller has any bug or any new ELB features need to be supported. Using AWS Load Balancer Controller, it can gracefully be replaced because it will be running as Kubernetes deployment instead of relying on Kubernetes upstream source code integration.   The controller directly maintain your Elastic Load Balancer resources with up-to-date annotations. For nginx ingress controller, it can provision and add an extra load balancing layer with the Network Load Balancer, in this case, the traffic generally will pass through the controller itself (nginx-ingress); instead, for AWS Load Balancer Controller, it doesn’t play as a gateway. The AWS Load Balancer Controller will directly control the Elastic Load Balancer resource, which can register your Pod (by using IP mode) so the request can directly forward to your backend application.   The AWS Load Balancer Controller also starts to support TargetGroupBinding 6 and IngressGroup 7 feature since v2.2. It enables you can group multiple Ingress resources together, which allows multiple service deployments can share the same Elastic Load Balancer resource.   Conclusion: What controller should I use?   After comparing different load balancer controllers, generally speaking, using AWS Load Balancer basically can have better feature supports as well as adopt with the performance optimization by configuring AWS Load Balancer attributes correctly. It is essential to enable IP mode when applying the Kubernetes service deployment with AWS Load Balancer Controller to reduce unnecessary hop that can be caused by Kubernetes networking itself, which is generally not totally suitable for AWS networking and elastic load balancing feature.   However, the disadvantage of using AWS Load Balancer can be all features require to be supported by Elastic Load Balancer itself because the controller doesn’t involve additional functions to extend the traffic control. Using other controller still can have its benefit and provide different features that Elastic Load Balancer doesn’t have, such as using nginx Ingress controller you may be able to define forward service to external FastCGI targets, using Regular Expression to perform path matching … etc.   By the end of this article, I hope the comparison and information can better help you understand how to select load balancer controller that will be running in Amazon EKS, and choose the right option for your environment.   Thanks for reading! If you have any feedback or opinions, please feel free to leave the comment below.      Best practice for load balancing - 1. Let’s start with an example from Kubernetes document   Best practice for load balancing - 2. imbalanced problem   Best practice for load balancing - 3. what controller should I use   References                  [AWS][EKS] Best pratice load balancing - Let’s start with an example from Kubernetes document &#8617;                  [AWS][EKS] Best pratice load balancing - imbalanced problem &#8617;                  in-tree controller - Network Load Balancer support on AWS &#8617;                  Using a Network Load Balancer with the NGINX Ingress Controller on Amazon EKS &#8617;                  Introducing the AWS Load Balancer Controller &#8617;                  AWS Load Balancer controller v2.2 - TargetGroupBinding &#8617;                  AWS Load Balancer controller v2.2 - IngressGroup &#8617;           ","categories": [],
        "tags": ["aws","amazon web services","EC2","Elastic Compute Cloud","amazon","ELB","ALB","Load Balancer","Elastic Load Balancer","ALB Ingress Controller","Kubernetes","k8s","EKS","Elastic Kubernetes Service","AWS Load Balancer Controller"],
        "url": "https://easoncao.com/eks-best-practice-load-balancing-3-en/",
        "teaser": "https://easoncao.com/assets/images/posts/2022/04/eks-best-practice-load-balancing/nginx-ingress-architecture.png"
      },{
        "title": "在 AWS 上打造 Serverless (無伺服器) 雲端綠界支付金流 (ECPay)",
        "excerpt":"金流系統一直是許多線上服務、電商所必備的功能之一；常見的使用方式往往是透過第三方金流服務提供商對應的模組實現 (例如：OpenCart, WooCommerce)，以串接金流系統實現購物結帳的機制。   即使是設計自己的金流系統串接，想要將這些金流服務串接應用在雲端服務上，對於不熟悉使用雲端技術的用戶來說，仍然需要花一些時間摸索以達到這項目的。   為了實現在 AWS 上串接綠界金流 (ECPay) 提供信用卡付款機制，並且簡化管理和維護流程，以下內容以 Serverless 技術作為背景，簡介在 AWS 上實作的相關細節。   什麼是 Serverless？為什麼要用 Serverless 技術？   無伺服器運算 (Serverless) 概念提出了拋棄舊有傳統管理 Server ，在過去，你需要維護及管理運行你應用程式的基礎運算系統；Serverless 提出以平台即服務（PaaS）的運作模式，提供簡單且容易操作的微型的架構，使得你不需要部署、組態或管理伺服器，只需要運用 Serverless 相關的解決方案，將你的程式碼推送至相關平台，運行所需要的伺服器服務皆由雲端平台來提供。   自 2014 年 AWS 推出 Serverless 服務以來，已經儼然成為一項 IT 部署解決方案中熱門的運行架構；學會使用 Serverles，將幫助你更容易且快速地推行不同類型的應用，將你的想法付諸於實際實現。   在過去，如果要運作相關的金流服務，我可能會需要開啟一台虛擬機器 24 小時的提供商業邏輯的運作，並且，可能會因為一些非預期狀況而多許多而外的工作，例如：突然暴增的訂單請求、過高的使用負載等原因影響到業務。往往程式開發出來只是個起點，後面的系統維護工作才是更大的挑戰。   選擇使用 Serverless 架構設計的考量之一，便是考量部署、組態或管理伺服器的長遠維護性，尤其對於金流這種關鍵業務來說，更是至關重要。   怎麼在 AWS 上與綠界支付科技串接   一般來說，在 AWS 上要建立 Serverless 為基礎架構的應用程式，通常涉及幾種不同的關鍵服務；以這項支付金流系統為例，我採用了以下的 AWS 服務   AWS Lambda   是一種無伺服器的運算服務，可讓您執行程式但不必佈建或管理伺服器、建立工作負載感知叢集擴展邏輯、維護事件整合或管理執行階段。使用 Lambda，您可以透過虛擬方式執行任何類型的應用程式或後端服務，全部無需管理。在這篇內容中，我使用了 Lambda Function 以推送訊息至 Amazon SNS 以發佈檔案更新。 Amazon CloudWatch   API Gateway   為 AWS 提供的託管服務，可以讓開發人員輕鬆地建立、發佈、維護、監控和保護任何規模的 API。API 可作為應用程式的「前門」，以便從後端服務存取資料、商業邏輯或功能。使用 API Gateway 時，您可以建立 RESTful API 等應用程式。API Gateway 支援無伺服器工作負載和 Web 應用程式。API Gateway 可以用以負責處理有關接受和處理多達數十萬個並行 API 呼叫的所有工作，包括流量管理、CORS 支援、授權和存取控制。API Gateway 沒有最低費用或啟動成本。您要為收到的 API 呼叫和資料傳輸量支付費用。   Serverless Application Model (SAM)   為了更容易實現在 AWS 上運作串接綠界金流支付並且以 Serverless 架構運作的目標，我使用了 AWS Serverless Application Model (簡稱為 SAM) 為開發流程的重要工具，用以建置 Serverless 應用服務。   Serverless Application Model (SAM) 提供了一系列以簡易描述的方法，提供你用以更容易，在很多情況下，你可能無需非常熟悉不同 AWS 服務的設置，即可透過 SAM 建立無伺服器應用程式。   為了幫助你快速了解 Serverless Application Model (SAM) 的運作機制以及簡介，以下簡短 10 分鐘的影片分享了其運作流程的機制：               運作流程與架構概覽 (Architecture Overview)                     以綠界支付科技為基礎的 Serverless 雲端金流概覽 (建立訂單)            上述的使用者流程描述了用戶及各個彼此 AWS 服務之間的運作關係，以建立訂單為例，我們可以藉由綠界支付 (ECPay) 開放的對應 SDK 實際在 AWS 中設計屬於其結帳流程的相關操作，透過 API Gateway 建立一致的對外 API 接口，並且實作建立訂單訊息的 Python 應用程式，並且將其透過 Serverless Application Model 提供的 CLI 工具 (SAM CLI) 將應用部署至 AWS Lambda 上運作。   在這種運作架構下，我們只需要專注設計結帳流程和用戶流程的設計，其餘的服務運作機制，均可以交付由 AWS Serverless 相關的解決方案滿足業務實作需求。   如果你對於具體的實作內容有興趣，可以透過下列的連結獲取更多資訊：    學習在一天內於 AWS 雲端搭建 Serverless 架構的金流服務   從 Zero 到 Hero，學習 AWS 入門知識並深入了解、應用 Serverless 相關的服務及架構，同時學會在 AWS 上使用不同的解決方案實踐無伺服器技術 (Serverless)，運行屬於你的雲端金流系統   點擊獲取更多資訊 延伸學習    總結與延伸學習   本篇內容簡介了以 AWS Serverless 為基礎架構設計金流應用程式的實作流程，以及提及部分在 AWS 上實現串接綠界支付科技的對應機制，並且分享一項參考架構。如果你對於本篇具體的實作內容有興趣，可以利用以下連結獲取完整的內容：      打造 Serverless (無伺服器) 雲端金流   如果你覺得這樣的內容有幫助，可以在底下按個 Like / 留言讓我知道。  ","categories": [],
        "tags": ["aws","amazon web services","Lambda","Lambda Function","Serverless","Serverless Application Model","SAM"],
        "url": "https://easoncao.com/serverless-ecpay-aws/",
        "teaser": "https://easoncao.com/assets/images/posts/2022/05/serverless-ecpay-aws/create-payment-flow.png"
      },{
        "title": "[AWS][EKS] Zero downtime deployment(RollingUpdate) when using AWS Load Balancer Controller on Amazon EKS",
        "excerpt":"This article is describing the thing you need to aware when using ALB Ingress Controller (AWS Load Balancer Controller) to do deployment and prevent 502 errors.                     Overview            What’s AWS Load Balancer Controller (legacy ALB Ingress Controller)   Kubernetes doesn’t involve the Application Load Balancer (ALB) deployment in the native implementation for using Kubernetes service object with type=LoadBalancer. Therefore, if you would like to expose your container service with Application Load Balancer (ALB) on EKS, it is recommended to integrate with AWS Load Balancer Controller (In the past, it was ALB Ingress Controller when it firstly initiated by CoreOS and Ticketmaster). This controller make it possible to manage have load balancers with Kubernetes deployment.   Below is showing an overview diagram that describing the controller workflow:                     How AWS Load Balancer Controller works - source               (1) The controller watches for ingress events from the API server.   (2) An ALB (ELBv2) is created in AWS for the new ingress resource. This ALB can be internet-facing or internal.   (3) Target Groups are created in AWS for each unique Kubernetes service described in the ingress resource.   (4) Listeners are created for every port detailed in your ingress resource annotations.   (5) Rules(ELB Listener Rules) are created for each path specified in your ingress resource. This ensures traffic to a specific path is routed to the correct Kubernetes Service.      Note: AWS ALB Ingress Controller is replaced, while rename it to be “AWS Load Balancer Controller” with several new features coming out. For more detail, please refer the GitHub project - kubernetes-sigs/aws-alb-ingress-controller    How to deploy Kubernetes with AWS Load Balancer Controller?   Using Application Load Balancer as example, when running the controller, AWS Load Balancer Controller will be deployed as a Pod running on your worker node while continously monitor/watch your cluster state. Once there have any request for Ingress  object creation, AWS Load Balancer Controller will help you to manage and create Application Load Balancer resource. Here is a part of example for v1.1.8 deployment manifest:   apiVersion: apps/v1 kind: Deployment metadata:   labels:     app.kubernetes.io/name: alb-ingress-controller   name: alb-ingress-controller   namespace: kube-system spec:   selector:     matchLabels:       app.kubernetes.io/name: alb-ingress-controller   template:     metadata:       labels:         app.kubernetes.io/name: alb-ingress-controller     spec:       containers:         - name: alb-ingress-controller           args:             # Setting the ingress-class flag below ensures that only ingress resources with the             # annotation kubernetes.io/ingress.class: \"alb\" are respected by the controller. You may             # choose any class you'd like for this controller to respect.             - --ingress-class=alb              # REQUIRED             # Name of your cluster. Used when naming resources created             # by the ALB Ingress Controller, providing distinction between             # clusters.             # - --cluster-name=devCluster              # AWS VPC ID this ingress controller will use to create AWS resources.             # If unspecified, it will be discovered from ec2metadata.             # - --aws-vpc-id=vpc-xxxxxx              # AWS region this ingress controller will operate in.             # If unspecified, it will be discovered from ec2metadata.             # List of regions: http://docs.aws.amazon.com/general/latest/gr/rande.html#vpc_region             # - --aws-region=us-west-1            image: docker.io/amazon/aws-alb-ingress-controller:v1.1.8       serviceAccountName: alb-ingress-controller   The deployment basically will run a copy of ALB Ingress Controller (pod/alb-ingress-controller-xxxxxxxx-xxxxx) in kube-system:   NAMESPACE     NAME                                          READY   STATUS    RESTARTS   AGE kube-system   pod/alb-ingress-controller-5fd8d5d894-8kf7z   1/1     Running   0          28s  NAMESPACE     NAME                                     READY   UP-TO-DATE   AVAILABLE   AGE kube-system   deployment.apps/alb-ingress-controller   1/1     1            1           3m48s   Since v2, the controller added lots of different custom resources and enhancements. But the core deployment still preserve many thing that mentioned in this post. Depending on your environment, the default and suggested installation steps may also involve the configuration of IRSA (IAM Role for Service Account) to grant permission for the AWS Load Balancer Controller Pods in order to operate AWS resources (e.g. ELB), so it is recommended to take a look official documentation to help you quickly understand how to install the controller:      AWS Load Balancer Controller on Amazon EKS   In addition, the service can be deployed as Ingress Object. For example, if you tried to deploy the simple 2048 application:   $ kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/v1.1.8/docs/examples/2048/2048-namespace.yaml $ kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/v1.1.8/docs/examples/2048/2048-deployment.yaml $ kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/v1.1.8/docs/examples/2048/2048-service.yaml $ kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/v1.1.8/docs/examples/2048/2048-ingress.yaml   The file 2048-ingress.yaml is mentioning the annotations, spec in format that supported by ALB Ingress Controller can recognize (Before Kubernetes 1.18):   apiVersion: extensions/v1beta1 kind: Ingress metadata:   name: \"2048-ingress\"   namespace: \"2048-game\"   annotations:     kubernetes.io/ingress.class: alb     alb.ingress.kubernetes.io/scheme: internet-facing   labels:     app: 2048-ingress spec:   rules:     - http:         paths:           - path: /*             backend:               serviceName: \"service-2048\"               servicePort: 80   Before the IngressClass resource and ingressClassName field were added in Kubernetes 1.18, Ingress classes were specified with a kubernetes.io/ingress.class annotation on the Ingress. So right now, you should see the ingress specification will be defined as below if you are using controller version v2.x:   $ kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.4.1/docs/examples/2048/2048_full.yaml   apiVersion: networking.k8s.io/v1 kind: Ingress metadata:   namespace: game-2048   name: ingress-2048   annotations:     alb.ingress.kubernetes.io/scheme: internet-facing     alb.ingress.kubernetes.io/target-type: ip spec:   ingressClassName: alb   rules:     - http:         paths:         - path: /           pathType: Prefix           backend:             service:               name: service-2048               port:                 number: 80   The ingress object will construct ELB Listeners according rules and forward the connection to the corresponding backend(serviceName), which match the group of service service-2048, any traffic match the rule /* will be routed to the group of selected Pods. In this case, Pods are exposed on the worker node based on type=NodePort:   Here is the definition of this Kubernetes service:   apiVersion: v1 kind: Service metadata:   name: \"service-2048\"   namespace: \"2048-game\" spec:   ports:     - port: 80       targetPort: 80       protocol: TCP   type: NodePort   selector:     app: \"2048\"   So … what’s the problem?   Zero downtime deployment is always a big challenge for DevOps/Operation team when running any kind of business. When you try to apply the controller as a solution to expose your service, it has a couple of things need to take care due to the behavior of Kubernetes, ALB and AWS Load Balancer Controller. To achieve zero downtime, you need to consider many perspectives, some new challenges will also popup when you would like to roll out the new deployment for your Pods with AWS Load Balancer Controller.   Let’s use the 2048 game as example to describe the scenario when you are trying to roll out a new version of your container application. In my environment, I have:      A Kubernetes service service/service-2048 using NodePort to expose the service   The deployment also have 5 copy of Pods for 2048 game, which is my backend application waiting for connections forwarding by Application Load Balancer (ALB)   NAMESPACE     NAME                                          READY   STATUS    RESTARTS   AGE 2048-game     pod/2048-deployment-58fb66554b-2f748          1/1     Running   0          53s 2048-game     pod/2048-deployment-58fb66554b-4hz5q          1/1     Running   0          53s 2048-game     pod/2048-deployment-58fb66554b-jdfps          1/1     Running   0          53s 2048-game     pod/2048-deployment-58fb66554b-rlpqm          1/1     Running   0          53s 2048-game     pod/2048-deployment-58fb66554b-s492n          1/1     Running   0          53s  NAMESPACE     NAME                   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE 2048-game     service/service-2048   NodePort    10.100.53.119   &lt;none&gt;        80:30337/TCP    52s  NAMESPACE     NAME                                     READY   UP-TO-DATE   AVAILABLE   AGE 2048-game     deployment.apps/2048-deployment          5/5     5            5           53s   And for sure, once the controller correctly set up and provision the ELB resource, the full domain of ELB also will be recorded to the Ingress object:   $ kubectl get ingress -n 2048-game NAME           HOSTS   ADDRESS                                                                      PORTS   AGE 2048-ingress   *       xxxxxxxx-2048game-xxxxxxxx-xxxx-xxxxxxxxx.ap-northeast-1.elb.amazonaws.com   80      11m   I can use the DNS name as endpoint to visit my container service:   $ curl -s xxxxxxxx-2048game-xxxxxxxx-xxxx-xxxxxxxxx.ap-northeast-1.elb.amazonaws.com | head &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt;   &lt;meta charset=\"utf-8\"&gt;   &lt;title&gt;2048&lt;/title&gt;    &lt;link href=\"style/main.css\" rel=\"stylesheet\" type=\"text/css\"&gt;   &lt;link rel=\"shortcut icon\" href=\"favicon.ico\"&gt;   ...                     2048 Game deployed with controller            This application can be any kind of critical service you are running. As a administrator, SRE (Site Reliability Engineer), member of operation team or a DevOps engineer, the goal and your duty is: we always try to ensure the service can run properly without any issue and no interruption (Sometimes it means good sleep). That’s why people really gets hand dirty and maintain the regular operation usually don’t like to adopt service change, because it generally means unstable.   No matter you don’t want to change, with any new business requests, you still can face the challenges like: your developers are saying that “Oh! we need to upgrade the application”, “we are going to roll out a bug fix”, “the new feature is going to be online”, no one can one hundred percent guarantees the service can run properly if any changes applied, because system usually has its limitation and trade-off. Any service downtime can lead anyone of stakeholders(users, operation team or leadership) unhappy.   However, the question is that can we better to address these problem once we know the limitation and its behavior? Some people in Taiwan will also consider to put Kuai Kuai on the workstation because they believe it can make service happy, but I am not very obsessed with this method, so in the following section I will try to walk through more realistic logic and phenomena by using the 2048 game as my sample service.   I am going to use a simple loop trick to continously access my service via the endpoint xxxxxxxx-2048game-xxxxxxxx-xxxx-xxxxxxxxx.ap-northeast-1.elb.amazonaws.com to demonstrate a scenario: This is a popular web service and we always have customer need to access it. (e.g. social media platform, bitcoin trading platform or any else, we basically have zero tolerance for any service downtime as it can impact our revenue.), as below:   $ while true;do ./request-my-service.sh; sleep 0.1; done HTTPCode=200_TotalTime=0.010038 HTTPCode=200_TotalTime=0.012131 HTTPCode=200_TotalTime=0.005366 HTTPCode=200_TotalTime=0.010119 HTTPCode=200_TotalTime=0.012066 HTTPCode=200_TotalTime=0.005451 HTTPCode=200_TotalTime=0.010006 HTTPCode=200_TotalTime=0.012084 HTTPCode=200_TotalTime=0.005598 HTTPCode=200_TotalTime=0.010086 HTTPCode=200_TotalTime=0.012162 HTTPCode=200_TotalTime=0.005278 HTTPCode=200_TotalTime=0.010326 HTTPCode=200_TotalTime=0.012193 HTTPCode=200_TotalTime=0.005347 ...   Meanwhile, I am using RollingUpdate strategy in my Kubernetes deployment strategy with maxUnavailable=25%, which means, when Kubernetes need to update or patch(Like update the image or environment variables), the maximum number of unavailable Pods cannot exceed over 25% as well as it ensures that at least 75% of the desired number of Pods are up (only replace 1-2 Pods if I have 5 copies at the same time):   apiVersion: apps/v1 kind: Deployment metadata:   name: 2048-deployment   namespace: 2048-game spec:   ...   selector:     matchLabels:       app: \"2048\"   ...   strategy:     rollingUpdate:       maxSurge: 25%       maxUnavailable: 25%     type: RollingUpdate   Scenario: Rolling the new container image to existing container application with potential service downtime   When rolling the new version of my container application (for example, I update my deployment by replacing the container image with the new image nginx), it potentially can have a period of time that can return HTTP Status Code 502 error in my few hits:                     The HTTP 502 Error response from ELB during the rolling update deployment (instance mode)            If you are specifying the controller to use instance mode to register targets(Pods) to your ELB Target Group, it will use worker nodes’ instance ID and expose your service in that ELB target group with Kubernetes NodePort. In this case, the traffic will follow the Kubernetes networking design to do second tier of transmission according to externalTrafficPolicy defined in the Kubernetes Service object (No matter using externalTrafficPolicy=Cluster or externalTrafficPolicy=Local).   Due to the controller only care about to register Worker Node to the ELB target group, so if the scenario doesn’t involve the worker node replacement, the case basically have miniumun even no downtime(expect that it is rare to have downtime if the Kubernetes can perfectly handle the traffic forwarding); however, this is not how real world operate, few seconds downtime still can happen potentially due to the workflow below:   This is the general workflow when the client reach out to the service endpoint (ELB) and how was traffic goes   Client ----&gt; ELB ----&gt; Worker Node (iptables) / In this step it might be forwarded to other Worker Node ----&gt; Pod   So, in these cases, you can see the downtime:      (1) The client established the connection with ELB, ELB is trying to forward the request to the backend (the Worker Node), but the Worker Node is not ready to serve the Pod.   (2) Follow the iptables rules, the traffic be forwarded to the Pod just terminated due to RollingUpdate (Or the Pod just got the in-flight reqeust but immediately need to be terminated, the Pod flip to Terminating state. It haven’t response back yet, caused the ELB doesn’t get the response from Pod.)   (3) ELB established connection with the Worker Node-1, once the packet enter into the Worker Node-1, it follows the iptables then forward it to the Pod running on Worker Node-2 (jump out the current worker node), however, the Worker Node-2 just got terminated due to auto scaling strategy or any replacement due to upgrade, caused the connection lost.   Let’s say if you try to remove the encapsulation layer of the Kubernetes networking design and make thing more easier based on the AWS supported CNI Plugin (Only rely on the ELB to forward the traffic to the Pod directly by using IP mode with annotation setting alb.ingress.kubernetes.io/target-type: ip in my Ingress object), you can see the downtime more obvious when Pod doing RollingUpdate. That’s because not only the problem we mentioned the issues in case (1)/(2)/(3), but also there has different topic on the behavior of the controller need to be covered if the question comes to zero downtime deployment:   Here is an example by using IP mode (alb.ingress.kubernetes.io/target-type: ip) as resgistration type to route traffic directly to the Pod IP   apiVersion: networking.k8s.io/v1 kind: Ingress metadata:   namespace: game-2048   name: ingress-2048   annotations:     alb.ingress.kubernetes.io/scheme: internet-facing     alb.ingress.kubernetes.io/target-type: ip spec:   ingressClassName: alb   rules:     - http:         paths:         - path: /           pathType: Prefix           backend:             service:               name: service-2048               port:                 number: 80                     An example when using IP mode in AWS Load Balancer Controller - Can see my Pods all are registering with Pod owns IP address            Again follow the issue we mentioned (1) (2) (3), when doing the rolling update (I was replacing the image again in IP mode), similar problem can be observed. Potentially, you can have 10-15 seconds even longer downtime can be noticed if you are doing the same lab:                     The HTTP 502 Error response from ELB during the rolling update deployment (IP mode)            When Kubernetes is rolling the deployment, in the target group, you will see AWS Load Balancer Controller was issuing old targets draining process(Old Pods) in the meantime                     Old targets were going to be draining state in target group            However, you still can see HTTP 502/504 errors exceed 3-10 seconds for a single requset   HTTPCode=200_TotalTime=0.005413 2048 HTTPCode=200_TotalTime=0.009980 502 Bad Gateway HTTPCode=502_TotalTime=3.076954 2048 HTTPCode=200_TotalTime=0.005700 2048 HTTPCode=200_TotalTime=0.010019 502 Bad Gateway HTTPCode=502_TotalTime=3.081601 2048 HTTPCode=200_TotalTime=0.005527 502 Bad Gateway HTTPCode=502_TotalTime=3.070947 502 Bad Gateway HTTPCode=502_TotalTime=3.187812 504 Gateway Time-out HTTPCode=504_TotalTime=10.006324 Welcome to nginx! HTTPCode=200_TotalTime=0.011838 Welcome to nginx!   The issue and the workflow of the AWS Load Balancer Controller   Let’s use this scenario as it is a edge problem we need to consider for most use case. The issue generally is bringing out the core topic we want to address and giving a good entry point to dive deep into the workflow between the Kubernetes, AWS Load Balancer Controller and the ELB, which can lead HTTP status code 502/503(5xx) erros during deployment when having Pod termination.   Before diving into it, we need to know when a pod is being replaced, AWS Load Balancer Controller will register the new pod in the target group and removes the old Pods. However, at the same time:      For the the new Pods, the target is in initial state, until it pass the defined health check threshold (ALB health check)   For the old Pods is remaining as draining state, until it completes draining action for the in-flight connection, or reaching out the Deregistration delay defined in the target group.   Which result in the service to be unavailable and return HTTP 502.   To better understand that, I made the following diagrams. It might be helpful to you understanding the workflow:   1) In the diagram, I used the following IP addresses to remark and help you recognize new/old Pods. Here is the initial deployment.      Old Pods: Target-1(Private IP: 10.1.1.1), Target-2(Private IP: 10.2.2.2)   New Pods: Target-3(Private IP: 10.3.3.3), Target-4(Private IP: 10.4.4.4)                     Deployment workflow of AWS Load Balancer Controller - 1. the initial deployment            2) At this stage, I was doing container image update and start rolling out the new copies of Pods. In the meantime, the controller will make RegisterTarget API call to ELB on behalf of the Kubernetes.                     Deployment workflow of AWS Load Balancer Controller - 2. start rolling out the new copies of Pods and AWS Load Balancer Controller is going to issue RegisterTarget API call            3) Meanwhile, the DeregisterTarget API will be called by AWS Load Balancer Controller and new targets are in initial state.                     Deployment workflow of AWS Load Balancer Controller - 3. AWS Load Balancer Controller start to dereigster old targets on ELB Target Group            4) At this stage, anything could happen to cause service outage. Because the DeregisterTarget API call might take some time to process, but, Kubernetes doesn’t have any design to monitor the current state of the ELB Target Group, it only care about rolling the new version of Pods and terminate old one.   In this case, if the Pod got terminated by Kubernetes but Target-1 or Target-2 are still leaving in the ELB Target Group as Active/Healthy state (It need to wait few seconds to be Unhealthy once it reach out to the threshold of ELB HTTP health check), result in the ELB cannot forward the front-end request to the backend correctly.                     Deployment workflow of AWS Load Balancer Controller - 4. Note: issue cause by inconsistent state between Kubernetes and ELB            5) ELB received the DeregisterTarget request. So the ELB Target Group will start to perform connection draining(set old targets as draining), and mark the Target-1/Target-2 as draining state, any new connection won’t be routed to these old targets.                     Deployment workflow of AWS Load Balancer Controller - 5. ELB start to perform connection draining for old targets            6) However, here brings another issue: if the new targets (Target-3 and Target-4) are still working on passing the health check of ELB(Currently those are in Initial state), there has no backend can provide service at this moment, which can cause the ELB only can return HTTTP 5XX status code                     Deployment workflow - 6. ELB response HTTP 5XX error due to no healthy targets in can provide service            7) Until the new Pods is in Running state as well as can react the health check reqeust from ELB through HTTP/HTTPS protocol, the ELB end up mark the targets as Active/Healthy and the service become available                     Deployment workflow - 7. The service need to wait a period to recover until new targets passed the ELB health check            How to resolve the issue and meet zero-downtime?   Factor-1: Pod Readiness Gates   Since version v1.1.6, AWS Load Balancer Controller (ALB Ingress Controller) introduced Pod readiness gates. This feature can monitor the rolling deployment state and trigger the deployment pause due to any unexpected issue(such as: getting timeout error for AWS APIs), which guarantees you always have Pods in the Target Group even having issue on calling ELB APIs when doing rolling update.   ALB Ingress Controller 1.x (Legacy)   As mentioned in the previous workflow, obviously, if you would like to prevent the downtime, it is required to use several workarounds to ensure the Pod state consistency between ALB, ALB Ingress Controller and Kubernetes.   In the past, the readiness gate can be configured with legacy (version 1) by using the following pod spec. Here is an example to add a readiness gate with conditionType: target-health.alb.ingress.k8s.aws/&lt;ingress name&gt;_&lt;service name&gt;_&lt;service port&gt;   (As it might be changed afterward, for more detail, please refer to the documentation as mentioned in the AWS Load Balancer Controller project on GitHub):   apiVersion: v1 kind: Service metadata:   name: nginx-service spec:   clusterIP: None   ports:   - port: 80     protocol: TCP     targetPort: 80   selector:     app: nginx --- apiVersion: extensions/v1beta1 kind: Ingress metadata:   name: nginx-ingress   annotations:     kubernetes.io/ingress.class: alb     alb.ingress.kubernetes.io/target-type: ip     alb.ingress.kubernetes.io/scheme: internal spec:   rules:     - http:         paths:           - backend:               serviceName: nginx-service               servicePort: 80             path: /* --- apiVersion: apps/v1 kind: Deployment metadata:   name: nginx-deployment spec:   selector:     matchLabels:       app: nginx   replicas: 2   template:     metadata:       labels:         app: nginx     spec:       readinessGates:       - conditionType: target-health.alb.ingress.k8s.aws/nginx-ingress_nginx-service_80       containers:       - name: nginx         image: nginx         ports:         - containerPort: 80   AWS Load Balancer Controller (After v2.x)   For now, if you are using controller later than v2, the readiness gate configuration can be automatically injected to the pod spec by defining the label elbv2.k8s.aws/pod-readiness-gate-inject: enabled to your Kubernetes namespace.   $ kubectl create namespace readiness namespace/readiness created  $ kubectl label namespace readiness elbv2.k8s.aws/pod-readiness-gate-inject=enabled namespace/readiness labeled  $ kubectl describe namespace readiness Name:         readiness Labels:       elbv2.k8s.aws/pod-readiness-gate-inject=enabled Annotations:  &lt;none&gt; Status:       Active   So defining legacy fields readinessGates and conditionType are not required if you are using controller later than v2.0. If you have a pod spec with legacy readiness gate configuration, ensure you label the namespace and create the Service/Ingress objects before applying the pod/deployment manifest. The controller will remove all legacy readiness-gate configuration and add new ones during pod creation.   Factor-2: Graceful shutdown your applications   For existing connections(As mentioned in the workflow-4), the case is involving the gracefully shutdown/termination handling in Kubernetes. Therefore, it is requires to use the method provided by Kubernetes.   You can use Pod Lifecycle with preStop hook and make some pause(like using sleep command) for Pod termination. This trick ensures ALB can have some time to completely remove old targets on Target Group (It is recommended to adjust longer based on your Deregistration delay):       lifecycle:       preStop:         exec:           command: [\"/bin/sh\", \"-c\", \"sleep 40\"]   terminationGracePeriodSeconds: 70      Note: If a container has a preStop hook configured, that runs before the container enters the Terminated state. Also, if the preStop hook needs longer to complete than the default grace period allows, you must modify terminationGracePeriodSeconds to suit this.    An example to achieve zero downtime when doing rolling update after applying methods above   First apply the label to the namespace so the controller can automatically inject the readiness gate:   apiVersion: v1 kind: Namespace metadata:   name: 2048-game   labels:     elbv2.k8s.aws/pod-readiness-gate-inject: enabled   apiVersion: apps/v1 kind: Deployment metadata:   name: \"2048-deployment\"   namespace: \"2048-game\" spec:   selector:     matchLabels:       app: \"2048\"   replicas: 5   template:     metadata:       labels:         app: \"2048\"     spec:        # This would be optional if you are using controller after v2.x       readinessGates:       - conditionType: target-health.alb.ingress.k8s.aws/2048-ingress_service-2048_80        terminationGracePeriodSeconds: 70       containers:       - image: alexwhen/docker-2048         imagePullPolicy: Always         name: \"2048\"         ports:         - containerPort: 80         lifecycle:           preStop:             exec:               command: [\"/bin/sh\", \"-c\", \"sleep 40\"]   Here is an example after following the practice I was getting a try. The deployment will apply the feature and can see the status of the readiness gates:   $ kubectl get pods -n 2048-game -o wide NAME                              READY   STATUS    RESTARTS   AGE   IP               NODE                                              NOMINATED NODE   READINESS GATES 2048-deployment-99b6fb474-c97ht   1/1     Running   0          78s   192.168.14.209   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX.compute.internal   &lt;none&gt;           1/1 2048-deployment-99b6fb474-dcxfs   1/1     Running   0          78s   192.168.31.47    XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX.compute.internal   &lt;none&gt;           1/1 2048-deployment-99b6fb474-kvhhh   1/1     Running   0          54s   192.168.29.6     XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX.compute.internal   &lt;none&gt;           1/1 2048-deployment-99b6fb474-vhjbg   1/1     Running   0          54s   192.168.18.161   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX.compute.internal   &lt;none&gt;           1/1 2048-deployment-99b6fb474-xfd5q   1/1     Running   0          78s   192.168.16.183   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX.compute.internal   &lt;none&gt;           1/1   Once rolling the new version of the container image, the deployment goes smoothly and prevent the downtime issue as mentioned in previous paragraphs:                     Zero downtime with AWS Load Balancer Controller - Can see the targets are gracefully replaced when the Kubernetes is doing rolling update            In my scenario, the Kubernetes need to take at least 40 seconds termination period for single Pod, so the old targets are gradually moved out instead of remove all of them at once within few seconds, until entire target group only exists new targets.   Therefore, you probably also need to notice the Deregistration delay defined in your ELB Target Group, which can be updated through the annotation:   alb.ingress.kubernetes.io/target-group-attributes: deregistration_delay.timeout_seconds=30   In this case, it is recommended to be less than 40 seconds so ELB can drain your old targets before the Pod completely shutdown.   With the configuration, client can get normal responses from old Pods/existing connection during the deployment:   HTTPCode=200_TotalTime=0.012028 2048 HTTPCode=200_TotalTime=0.005383 2048 HTTPCode=200_TotalTime=0.010174 2048 HTTPCode=200_TotalTime=0.012233 Welcome to nginx! HTTPCode=200_TotalTime=0.007116 2048 HTTPCode=200_TotalTime=0.010090 2048 HTTPCode=200_TotalTime=0.012201 2048 HTTPCode=200_TotalTime=0.005532 2048 HTTPCode=200_TotalTime=0.010107 2048 HTTPCode=200_TotalTime=0.012163 Welcome to nginx! HTTPCode=200_TotalTime=0.005452 Welcome to nginx! HTTPCode=200_TotalTime=0.009950 2048 HTTPCode=200_TotalTime=0.012082 Welcome to nginx! HTTPCode=200_TotalTime=0.005349 2048 HTTPCode=200_TotalTime=0.010142 2048 HTTPCode=200_TotalTime=0.012143 2048 HTTPCode=200_TotalTime=0.005507  ... HTTPCode=200_TotalTime=0.012149 Welcome to nginx! HTTPCode=200_TotalTime=0.005364 Welcome to nginx! HTTPCode=200_TotalTime=0.010021 Welcome to nginx! HTTPCode=200_TotalTime=0.012092 Welcome to nginx! HTTPCode=200_TotalTime=0.005463 Welcome to nginx! HTTPCode=200_TotalTime=0.010136 Welcome to nginx!   This is the practice in case having AWS Load Balancer Controller for doing graceful deployment with RollingUpdate. However, it is another big topic need to be discussed regarding what type of the application when rolling the update. Because other type of applications need to establish long connection with the ELB or have requirement for considering persistence data need to be stored on the backend. All these things can bring out other issues we need to talk about.   But in summarize, with the deployment strategy above, it is also recommended to design the client/backend application as stateless, implement retry and fault-tolerance. These mothod usually help to reduce the customer complain and provide better user experience for most common use case.   Conclusion   Due to the current design of Kubernetes, it is involving the state inconsistent issue when you are exposing the service with Application Load Balancer. Therefore, in this article, I mentioned the potential issue when doing rolling update in the scenario having container service integrating with the AWS Load Balancer Controller (ALB Ingress Controller).   Even the technology is always in revolution, I am still willing to help people better handle the deployment strategy. I used a couple of hours to draft this content and tried to cover several major issues, metioned things you might need to aware, break down the entire workflow and shared few practical suggestions that can be achieved by using AWS Load Balancer Controller in order to meet the goal when doing zero downtime deployment.   The article was written based on my own experience (Of course many communications back and forth with different customers using AWS), it might not be perfect but I hope it is helpful to you. For sure, if you find any typo or have any suggestions, please feel free and leave comment below.   References      ALB Ingress Controller on Amazon EKS   Using pod conditions / pod readiness gates   Issue#1124   Issue#814   Issue#1064  ","categories": [],
        "tags": ["aws","amazon web services","EC2","Elastic Compute Cloud","amazon","ELB","ALB","Load Balancer","Elastic Load Balancer","ALB Ingress Controller","Kubernetes","k8s","EKS","Elastic Kubernetes Service","AWS Load Balancer Controller"],
        "url": "https://easoncao.com/zero-downtime-deployment-when-using-alb-ingress-controller-on-amazon-eks-and-prevent-502-error/",
        "teaser": "https://easoncao.com/assets/images/posts/2020/10/zero-downtime-deployment-when-using-alb-ingress-controller/deployment-workflow-alb-ingress-controller-4-side-note-of-deregister.png"
      },{
        "title": "[AWS] 那些沒寫在文件上的事 - AWS Load Balancer Controller v1 升級至 v2",
        "excerpt":"隨著 Amazon EKS 對於 Kubernetes 1.22 的推出，1.21 也預計於 February 15, 2023 在 Amazon EKS 終止支援 1，對於 AWS Load Balancer Controller 仍然使用舊版本的用戶來說，勢必面臨需要升級 AWS Load Balancer Controller 至 2.4.1 以上版本的需要。若在現有環境中仍持續運行 AWS Load Balancer Controller v1 (原 ALB Ingress Controller)，此時此刻將可能來到遷移業務需求的高峰。由於 AWS Load Balancer Controller v2 版本帶來了許多的改進，並且與 v1 版本有很大的差異，絕對不是套用一個 YAML 文件就能搞定的事情。   在 AWS Load Balancer Controller 文件中提及了具體的幾個注意事項2，然而，有些情境文件上不見得會全部捕捉 (或是不巧剛好被我遇到)，以下列舉在 AWS Load Balancer Controller 遷移到 v2 版本之前，我個人在協助用戶執行遷移關注到的幾個有趣的問題。   那些沒寫在文件上的事   ELB 資源命名規則改變帶來可能的停機行為   也許有的人發現 v1 版本的控制器升級到 v2 版本控制器的過程，會由 v2 控制器產生一個新的 ELB 資源，並且將相關資源部署到新產生的資源中完成遷移，舊有 v1 建立的 ELB 資源就不會繼續使用。使得完成遷移的過程如果有依賴舊有 ELB 資源的位置 (e.g. fe584233-echoserver-echose-XXXX-XXXXXXX.ap-northeast-1.elb.amazonaws.com) 或是有依賴服務關聯，就要記得去改對應的 DNS 紀錄。在文件上也確實具體提到了這項行為：      The AWS LoadBalancer resource created for your Ingress will be preserved. If migrating from&lt;v1.1.3, a new AWS LoadBalancer resource will be created and the old AWS LoadBalancer will remain in the account. However, the old AWS LoadBalancer will not be used for the ingress resource.    對於很多用戶來說，這可能不是什麼大問題；但對於已經有許多系統依賴單一 ELB 資源的用戶來說，前期規劃安裝也沒想太多就直接給他上了。導致這樣的升級過程對這部分用戶來說，就像跑了廁所蹲了馬桶，卻仍然還便秘一樣令人不愉快。   於是就有仍然在運行 v1.0.1 版本的客戶們很天才地提了我甚至都沒思考過的升級路徑：      既然文件上是說 &lt;v1.1.3，那是不是我先升級到大於這個版本之後 (例如：v1.1.9)，再升級到 v2 版本就可以保留原有的 ELB 資源了呢？     升級路徑為 v1.0.1 -&gt; v1.1.9 -&gt; v2    邏輯上好像沒有什麼謬誤，但在看過 AWS Load Balancer Controlelr 的原始代碼後，很遺憾，只能說這種想法真的是太美好了。   實際測試行為   根據 AWS Load Balancer Controller v2 版本對應產生的 ELB 資源名稱都存在 k8s 保留字串的不正確觀察，我大可以預料到只要是舊版本的 v1 控制器遷移很可能都無法複用舊有的 ELB 資源。   但針對上述的行為我們可以大膽假設，仍需要仔細驗證一下相關的行為。為求真相，實際在我的環境簡單複製測試後，直接地瓦解了上述的論證。   Step 1：部署 ALB Ingress Controller v1.0.1   首先，我在我的環境運行了 v1.0.1 的控制器，歷經一番考古和 kubectl convert 轉換 (舊有的 API 宣告)，將舊版 v1.0.1 控制器成功安裝到 Kubernetes 1.20 版本中運行，並且部署一個簡單的範例應用：   # Running controller v1.0.1 $ kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/v1.0.1/docs/examples/rbac-role.yaml $ wget https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/v1.0.1/docs/examples/alb-ingress-controller.yaml $ kubectl apply -f alb-ingress-controller.yaml $ kubectl logs -n kube-system $(kubectl get po -n kube-system | egrep -o alb-ingress[a-zA-Z0-9-]+)  W0130 12:45:29.518393       1 client_config.go:552] Neither --kubeconfig nor --master was specified.  Using the inClusterConfig.  This might not work. ------------------------------------------------------------------------------- AWS ALB Ingress controller   Release:    v1.0.1   Build:      git-ebac62dd   Repository: https://github.com/kubernetes-sigs/aws-alb-ingress-controller.git -------------------------------------------------------------------------------  # Running a sample application $ kubectl describe ing -n echoserver echoserver Address:          fe584233-echoserver-echose-XXXX-XXXXXXX.ap-northeast-1.elb.amazonaws.com ...   Step 2：升級至 ALB Ingress Controller v1.1.9   並且直接更新到 v1.1.9 版本，即使 ALB Ingress Controller 存在刷新操作，仍然針對原有的 Ingress 物件保留了原本的部署關聯 (fe584233-echoserver-echose-XXXX-XXXXXXX.ap-northeast-1.elb.amazonaws.com)：   # Upgrade and deploy to v1.1.9  $ kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/v1.1.9/docs/examples/rbac-role.yaml  # Use kubectl and update the image to \"docker.io/amazon/aws-alb-ingress-controller:v1.1.9\" $ kubectl logs -n kube-system $(kubectl get po -n kube-system | egrep -o \"alb-ingress[a-zA-Z0-9-]+\")  W0130 13:05:04.770613       1 client_config.go:549] Neither --kubeconfig nor --master was specified.  Using the inClusterConfig.  This might not work. ------------------------------------------------------------------------------- AWS ALB Ingress controller   Release:    v1.1.9   Build:      6c19d2fb   Repository: https://github.com/kubernetes-sigs/aws-alb-ingress-controller.git -------------------------------------------------------------------------------  # ELB name doesn't change $ kubectl describe ing -n echoserver echoserver Address:          fe584233-echoserver-echose-XXXX-XXXXXXX.ap-northeast-1.elb.amazonaws.com   Step 3：升級至 AWS Load Balancer Controller v2   在預備升級 v2 的過程 ELB 資源都持續存在，且 Ingress 也同樣關聯舊有的 ELB 資源；然而，一旦 v2 版本一部署下去，新的 ELB 資源立即被建立，並且使用不同的命名 (k8s-echoserv-echoserv-XXXXXXXX-XXXXXXX) 運作，並且關聯的 Ingress 和 Kubernetes Service 均遷移使用新的 ELB 資源：   # Update the controller to v2 # The old ALB Ingress controller has been uninstalled at this moment, and can see the ingress object is still preserved  $ kubectl describe ing -n echoserver echoserver Address:          fe584233-echoserver-echose-XXXX-XXXXXXX.ap-northeast-1.elb.amazonaws.com ....  $ helm install aws-load-balancer-controller eks/aws-load-balancer-controller \\   -n kube-system \\   --set clusterName=eks \\   --set serviceAccount.create=false \\   --set serviceAccount.name =aws-load-balancer-controller  # Once v2 controller has been installed, the controller will update the ELB name  $ kubectl describe ing -n echoserver echoserver Address:          k8s-echoserv-echoserv-XXXXXXXX-XXXXXXX.ap-northeast-1.elb.amazonaws.com ...  Events:   Type    Reason                  Age   From     Message   ----    ------                  ----  ----     -------   Normal  SuccessfullyReconciled  11s   ingress  Successfully reconciled   此時，舊有的 ELB 資源 (fe584233-echoserver-echose-XXXX-XXXXXXX.ap-northeast-1.elb.amazonaws.com ) 仍然存在，只是 AWS Load Balancer Controller 並未直接管理及操作該資源，並且不再執行註冊 Kubernetes Service 至相關 Target Group 資源。   行為分析   從上述部署來看，我們可以觀察到 v1 版本的控制器在古時候，使用 namespace + ingress 名稱的方式進行組合命名，這項行為也確實在 v1.0.1 如此呼叫 (Source: L299-L317)，在 v1.1.9 (Source: L285-L304) 亦同。一個 NameLB 短短幾行副程式道盡前人的字串處理之美 (Source: v1.0.1, v1.1.9)：   func (gen *NameGenerator) NameLB(namespace string, ingressName string) string {   hasher := md5.New()   _, _ = hasher.Write([]byte(namespace + ingressName))   hash := hex.EncodeToString(hasher.Sum(nil))[:4]    r, _ := regexp.Compile(\"[[:^alnum:]]\")   name := fmt.Sprintf(\"%s-%s-%s\",     r.ReplaceAllString(gen.ALBNamePrefix, \"-\"),     r.ReplaceAllString(namespace, \"\"),     r.ReplaceAllString(ingressName, \"\"),   )   if len(name) &gt; 26 {     name = name[:26]   }   name = name + \"-\" + hash   return name }   然而，在 v2 版本除了功能性的改進，針對 ALB Ingress Controller 也確實做了多項程式上的重構。最顯著的就是上述命名的變更，在 v2 版本的命名中存在了更多元的規範 (Source: v2.4.4, L90-L124)：   func (t *defaultModelBuildTask) buildLoadBalancerName(_ context.Context, scheme elbv2model.LoadBalancerScheme) (string, error) {   ...   if len(explicitNames) == 1 {     name, _ := explicitNames.PopAny()     // The name of the loadbalancer can only have up to 32 characters     if len(name) &gt; 32 {       return \"\", errors.New(\"load balancer name cannot be longer than 32 characters\")     }     return name, nil   }   if len(explicitNames) &gt; 1 {     return \"\", errors.Errorf(\"conflicting load balancer name: %v\", explicitNames)   }   uuidHash := sha256.New()   _, _ = uuidHash.Write([]byte(t.clusterName))   _, _ = uuidHash.Write([]byte(t.ingGroup.ID.String()))   _, _ = uuidHash.Write([]byte(scheme))   uuid := hex.EncodeToString(uuidHash.Sum(nil))    if t.ingGroup.ID.IsExplicit() {     payload := invalidLoadBalancerNamePattern.ReplaceAllString(t.ingGroup.ID.Name, \"\")     return fmt.Sprintf(\"k8s-%.17s-%.10s\", payload, uuid), nil   }    sanitizedNamespace := invalidLoadBalancerNamePattern.ReplaceAllString(t.ingGroup.ID.Namespace, \"\")   sanitizedName := invalidLoadBalancerNamePattern.ReplaceAllString(t.ingGroup.ID.Name, \"\")   return fmt.Sprintf(\"k8s-%.8s-%.8s-%.10s\", sanitizedNamespace, sanitizedName, uuid), nil }   除了對於 ELB 命名的檢查更為嚴謹了，也多了以 Cluster 名稱、Ingress Group 和多個關聯的識別資料進行雜湊產生 UUID，最終透過 k8s- 前綴組織成了人見 - 人們不見得愛的正則化命名。   總結   本章用了數百字的篇幅傳遞 v2 版本真的改很多東西，作為總結：   若從 v1 版本遷移至 v2 控制器涉及你目前所遭遇或未來將面臨的情境，則生成新的 ELB 資源都是很有可能且可以預期的行為。   在規劃遷移的同時，若尚未對 ELB 資源存取設計另一層存取介面的情境，考慮透過 DNS 紀錄 (CNAME) 方法管理應對 ELB 資源更新變更的存取位置是一種常見的做法，以降低用戶端因上述升級行為所產生的改動；也建議透過規劃相應的停機時間和更新 DNS 對應紀錄的變更紀錄納入考量。   畢竟，有很多事情只是人生暫時過不去的坎，在這樣的機制下，沒有什麼事情是清一下 DNS 快取以及「請稍候重試」提示訊息不能解決的。   Related Posts      Best practice for load balancing - 1. Let’s start with an example from Kubernetes document   Best practice for load balancing - 2. imbalanced problem   Best practice for load balancing - 3. what controller should I use   References                  Amazon EKS Kubernetes versions - Amazon EKS Kubernetes release calendar &#8617;                  AWS Load Balancer Controller - Migrate from v1 to v2 &#8617;           ","categories": [],
        "tags": ["aws","amazon web services","amazon","ELB","ALB","Load Balancer","Elastic Load Balancer","ALB Ingress Controller","Kubernetes","k8s","EKS","Elastic Kubernetes Service","AWS Load Balancer Controller"],
        "url": "https://easoncao.com/eks-aws-load-balancer-controller-v1-to-v2-migration-behavior/",
        "teaser": null
      },{
        "title": "在 AWS Cloud Support Engineer 面試中脫穎而出：必備的技術能力和重要特質",
        "excerpt":"如果你正準備面試 AWS Cloud Support Engineer 的職位，在這篇文章中，我將與你分享我對於 AWS Cloud Support Engineer 所需的必備技能和特質，幫助你更好地了解這份職位且思考自己目前所具備的能力是與該團隊所交集，讓你在面試中脫穎而出。                     在 AWS Cloud Support Engineer 面試中脫穎而出：必備的技術能力和重要特質 (source: Unsplash)            詳細內容可以參考以下我的團隊針對 AWS Cloud Support Engineer (雲端工程師) 職涯分享會中所提到的具體細節，裡面也包含了部分面試流程和一些小秘訣幫助你可以更好地掌握我們團隊所看重的能力：               請注意本篇內容純屬個人觀點，會分享這些內容的目的是希望有興趣投遞 AWS Cloud Support Engineer 能夠了解具體應該提升哪些必備技能，也同時分享一些日常為客戶解決技術問題時非常重要的能力。寫這篇內容的目的不是要幫助大家 Crash 考題，也不代表任何官方的參考指南。   即使你面試時展現把考題背熟的能力，進來團隊終究會在實際面對客戶問題時怕得要死，因為客戶問題往往都是沒有被定義清楚但又希望你能給予解答。如果只會背誦這些內容，仍然無法實際為客戶解決任何問題。   另外團隊召聘所看重的核心技能也可能隨時間變化，面試也不是一般考試，重要的是了解你能為團隊貢獻什麼樣的技能，看的是不同維度的全面評估。因此以下內容屬於我個人在團隊的經驗和處理客戶案例認為非常重要的必備技能，僅供參考。   如果你還不是很清楚 AWS Cloud Support Engineer 在做什麼，我十分推薦你可以參考我在 AWS 職涯系列的相關文章，以幫助你逐步建立對於這個職位的認識：      我在 Amazon 學到的 10 件事   我是如何在還沒畢業就錄取並進入到 Amazon 工作   我是如何在一年內通過 AWS 五大核心認證   Amazon Cloud Support Engineer 到底是在做什麼 (Amazon Web Services / AWS)   關於 Cloud Support Engineer 職位的常見問題 (Amazon Web Services / AWS) - AWS Cloud Support Engineer FAQs   在 AWS Cloud Support Engineer 面試中脫穎而出：必備的技術能力和重要特質   身處 Amazon 工作 5 年學到的事：在 AWS 擔任 Cloud Support Engineer 是什麼樣的體驗   基本技術能力 (Fundamental Technical Skill)   很多應徵者把這份工作當成一般設定環境的 IT Helpdesk 或是只是單純的客戶服務職位，以為遵循 Runbook 就能解決大部分工作上的問題。但實際 AWS Support 做的工作與一般公司的 IT Support 會與想像中有蠻大的差異，即使工作上以 Ticket 形式與客戶互動，但角色仍偏向顧問服務性質，直接被拉進客戶會議直接一個人打十個討論問題更是你都可能會遇到的情境，我會建議在應徵這份工作前可以有個心理準備。   我常觀察到很多候選人即使在 IT 界從業多年，對於很多基本的知識都有很大的落差 (例如：我聽過有人說用 ping 可以測網站的 Port 80 看網站是不是掛了)。這種現象在只專注做開發相關工作的工程師身上尤為明顯 (嚴格上來說很多軟體工程師職位都是在「實作」，面對的很多產品規格都已經在現有的封裝函式庫或是公開解決方案的 API 上定義能夠直接套用，所以可能也沒太多機會思考這種這麼核心底層的問題)。   不論是開發人員或是系統維運人員，可能在高階應用和實作上能夠滿足「使用者」身份角度的需求，所以也不需要對於基礎知識有太深入的了解，使得當東西壞掉或問題情境複雜時便束手無策 (也是感謝這些人才讓我有飯吃)。   但 AWS Cloud Support Engineer 就像是醫生這項職業，醫生必須根據病人描述的徵狀跟現有資訊提出正確的診斷步驟，用正確的診斷工具 (例如：聽診器、X 光)，最後開出正確的藥來緩解病人的症狀；工程師在協助 Troubleshooting 問題時也需要依照自己對於客戶提出問題的背景，知道要收集什麼資訊進行分析、用什麼樣正確的工具。   甚至有時候客戶給的資訊還是錯的，這就十分仰賴對於基礎知識至上層的全面了解，提供正確的排查方向，否則就只是在亂查一通。   網路概論 (Networking)   網路概論基本包含：      基本的 TCP/IP 協議運作   OSI 網路七層的基本架構 (由於 AWS Cloud Support Engineer 主要負責的產品就是 “Web Services”，所以 L4-L7 的討論不少，延伸知識例如常見的 Route、SSL、HTTP 等基本認識)   IPv4 的組成 (學習 AWS VPC 時對於 Subnet 的基本認識尤為重要)   DNS 的運作及除錯   HTTP/SSL/TLS   VPN (如果招聘團隊不著重處理網路相關的產品，則不會是討論的重心)   熟悉不同協議中對應的網路除錯工具和實際排查案例   DNS 算是基本中再基本到不行的必備知識，我自己個人倒是遇過很多連基本 DNS 協議都不太熟的候選人 (當然也有些從事 IT 工作的客戶也不是那麼熟)，最常見的問題就是 DNS 查詢的具體流程、DNS 協議的組成和問題除錯。   遇到問題除錯的場景或是系統故障就將矛頭直接指向應用程式或是服務端，壓根沒有想到實際造成問題的其實是 DNS 不正確設定或是一些非預期行為導致。   關於網路概論，有太多的免費資源可以參考，甚至有一些很不錯的參考資源可以具體幫助你了解。可能光以下的連結要全盤了解就讀不完了，我這裡就不一一列舉：      What is DNS? - Introduction to Domain Name System   High network performance   請注意問題的深度仍取決招聘團隊所看重的技術能力，如果是專注網路相關 AWS 服務的團隊，則可能在網路的部分就會更加深入；但對於其他專業團隊來說，由於更多的重心在於協助特定領域的 AWS 產品，則具備基本網路問題排查能力即可滿足協助客戶的情境。   作業系統 (Operating System)   由於我個人不太熟 Windows，為避免誤人子弟，這邊就僅列舉我認為非常實用的 Linux 資源，以及基礎到不能再基礎的檔案系統章節 (其實把鳥哥所有章節認真讀完並且實作，可能就足以面對 60-80% 有關 Linux 維運的情境)：   Linux (file system/operation/administration knowledges)     Linux 的檔案權限與目錄配置   Linux 檔案與目錄管理   Linux 磁碟與檔案系統管理   如果你完全並未具備這方面的經驗，搭建一個 Web Service (HTTP) 涵蓋網路概論至作業系統基本維運操作過程中所必備的知識都是必須的。   重要特質   以下列舉幾個我認為應徵 AWS Cloud Support Engineer 所需具備的幾項重要特質：   客戶服務技能和溝通能力   AWS Cloud Support Engineer 的主要工作是為客戶提供協助，並且常常會需要將複雜的技術問題拆解成能理解的步驟。讓客戶甚至是其他團隊 (例如開發團隊) 能夠清楚地知道如何排查問題、修正哪些錯誤。需要能夠清晰、明確地傳達信息，解釋問題和解決方案。   與一般軟體開發工作不同的是，AWS Cloud Support Engineer 由於需要經手系統故障排查的情境，不免會接受客戶環境上的壓力，例如有時候客戶在系統故障影響到營收的同時，充滿緊張和壓力的情境下只希望能盡快把問題解決 (急急急)，原本這些專業的 IT 人員也會瞬間變得很不理智。   試想下你剛進問題現場才短短的 5 分鐘，進行 Live troubleshooting 的同時試著釐清問題檢查每一個項目，並且引導客戶執行正確的步驟確認 (因為有時候客戶給的資訊是錯的)。但有時候客戶就是會覺得你在浪費他的時間，具備保持冷靜和耐心特質的重要性在這種情境下就特別顯著。我個人自己聽過的就有：     你到底會不會   這沒必要看，我現在只想要他恢復   你看這沒用啊，你行不行啊，我檢查過了這沒有問題   跟你溝通沒有意義，請找 ECS 專家來跟我溝通   客戶有情緒但你不能帶著情緒協助，因為這樣就是大家都一起 Panic (大家一起急急急)。我在這份工作確實也學習到很多溝通軟技巧，如果再拉一堆不相干的人進來，我的經驗是這通常只會把問題攪得更亂，對問題調查沒有太大的幫助。   你可以想想自己過去是否有類似的經驗，談論如何與其他人有效地溝通，如何解決複雜的技術問題以及如何處理緊急情況。   解決問題的能力   AWS Cloud Support Engineer 需要有效、精確地識別和解決問題。基本的邏輯和良好的分析能力是必須的，並能夠迅速掌握問題的本質。同時，你需要能夠綜合多個方面的信息，從而定位出問題的癥結點。   簡單來說就是排查問題的過程邏輯要對、能夠正確分析問題、使用正確的方法和工具，知道當問題發生時要如何排查、為什麼用這些工具、為何查 A 不是查 B。比如網站連不上為什麼是用 ping 而不是其他工具、用 ping 返回的結果代表什麼、正確獲取結果後調查的方向是什麼？。   而不是收集到一堆無用的資訊胡亂瞎猜，將問題弄得更發散 (反面案例即是前面提到使用 ping 檢查 Port 80 能不能正常連通)。   主動學習、問題研究能力和自我提升   AWS 產品不斷推陳出新，基本上已經學不完，這項工作不得不跟隨客戶的快速腳步不斷地持續的學習和自我提升。   由於這份工作的角色也從原本用戶端 (使用者) 變成解決問題的角色，在你的專業領域中也必須擁有深入研究問題的能力，當客戶拋出未知且未定義清楚的問題，你通常才能具體的給予明確的排查方向。   專業技術能力 (Professional Technical Competency)   由於各個專業領域都有各自側重的項目，例如，專注 Database 專業的工程師跟專注 Linux 領域專業的工程師對於 Linux 知識的要求定義可能有所不同。可能 Database 專業的工程師具體了解 Linux 的基本原理、知道一些基本的指令和明白檔案系統、檔案權限管理、基本問題排查即可；但 Linux 專業的工程師可能就要非常了解 Linux process 運作、知道如何使用 Linux 的工具更加了解系統效能、知道 kernel dump 怎麼解讀、troubleshooting 等等知識。1   每個專業領域會有基礎需要知道的基本知識，但團隊的技能樹也都是隨著客戶需求在變化，解決的問題也是日益更新。以下分享一些我認為可能對於所有專業團隊來說都十分有幫助的學習資源：   AWS 相關的知識   AWS Cloud Support Engineer 的工作是支援 AWS 的客戶，你需要熟悉 AWS 的服務和產品，並能夠協助客戶解決他們遇到的問題。同時，你需要知道如何設定和管理 AWS 環境，以及如何進行故障排除。因此如果你對 AWS 技術有著深刻的了解，這會對於你在入職之後非常有幫助。      AWS Training: 包含了各式免費 AWS 訓練的資源   AWS Educate: AWS Educate 是給予大專院校學生或是任何有意展開雲端旅程的任何人，免費學習和進行 AWS 服務使用試驗的計畫，裡面有一些 Training 通常也直接包含了 Cloud Support Associate 角色的相關訓練材料，能幫助你更加了解這份職位的工作內容和必備技能   其他專業技術領域則參考招聘簡介中所提到的對應專業技能，不同技術團隊所重視的技能樹基於專注的產品多少都有些不同，可以透過產品頁面大致了解相關的細節：      [All AWS Products]https://aws.amazon.com/products/   Container / DevOps / Deployment 領域   對於整個 AWS Support，我可能還稱不上非常了解，但如果是 DevOps 和容器技術相關領域的團隊，個人對於該領域小有心得還能分享點東西。   我所在的團隊大部分涵蓋 AWS 服務包含以下：      Elastic Container Service (ECS)   Elastic Kubernetes Service (EKS)   AWS Fargate   Amazon Elastic Container Registry (ECR)   CloudFormation   AWS Batch   AWS AppMesh   AppRunner   CodeCommit   CodeBuild   CodePipeline   CodeDeploy   CodeStar   Cloud Map   CodeArtifact   Cloud Development Kit (CDK)   Amazon Managed Service for Prometheus (AMP)   Elastic Beanstalk   AWS OpsWorks   Artifact   X Ray   DevOps Guru   CodeGuru   目前我的團隊一個人可能可以支持到快 40 個不同的 AWS Service，上述服務基本上都是客戶如果拋出問題來我都會有機會協助。   有鑒於我們團隊也在積極尋求合適的人才，以下是我們團隊十分看重的技術經驗和能力，部分附上一些你可以參考的學習資源：   Linux     Container and Virtualization features   Container Networking   Performance analysis (I/O, process state, CPU, memory)   Kubernetes / Docker     CERTIFIED KUBERNETES ADMINISTRATOR (CKA)   Kubernetes The Hard Way   learnk8s   Docker official document   Kubernetes official document   CI/CD     部署策略   基本的版本控制方法   Infrastructure as Code (IaC)   總結   在這篇內容中，簡述了有關 AWS Cloud Support Engineer 必備的技術能力、特質和相關可以參考的學習材料。如果你是正在考慮加入 AWS Cloud Support Engineer 團隊，希望這些內容能夠更加幫助你建立更多認識。   這篇內容也更像是我自己對於 AWS Cloud Support Engineer 技術職位所具備的長遠學習路徑有個基本的指南，並且幫助你思考如何在你的問題中使用具體的案例正確的展現這些能力。   看更多系列文章      我在 Amazon 學到的 10 件事   我是如何在還沒畢業就錄取並進入到 Amazon 工作   我是如何在一年內通過 AWS 五大核心認證   Amazon Cloud Support Engineer 到底是在做什麼 (Amazon Web Services / AWS)   關於 Cloud Support Engineer 職位的常見問題 (Amazon Web Services / AWS) - AWS Cloud Support Engineer FAQs   在 AWS Cloud Support Engineer 面試中脫穎而出：必備的技術能力和重要特質   身處 Amazon 工作 5 年學到的事：在 AWS 擔任 Cloud Support Engineer 是什麼樣的體驗   References                  關於 Cloud Support Engineer 職位的常見問題 - 請問面試過程中會問到多深入呢？ &#8617;           ","categories": [],
        "tags": ["amazon","aws","amazon web services","work","Cloud Support","Cloud Support Engineer"],
        "url": "https://easoncao.com/aws-cloud-support-engineer-interview-tips-and-required-skills/",
        "teaser": "https://easoncao.com/assets/images/posts/2023/03/aws-cloud-support-engineer-interview-tips-and-required-skills/cover.jpg"
      },{
        "title": "身處 Amazon 工作 5 年學到的事：在 AWS 擔任 Cloud Support Engineer 是什麼樣的體驗",
        "excerpt":"2023 是我在 AWS 擔任 Cloud Support Engineer 的第六年，這份工作對我來說某種程度上是又愛又恨。作為見證 AWS 中文技術支援團隊的一員，五年時間說長不長，說短也不短，卻有非常多學習和體悟。                     身處 Amazon 工作 5 年學到的事：在 AWS 擔任 Cloud Support Engineer 是什麼樣的體驗 (source: Unsplash)            一轉眼五年過去，除了見證團隊的成長，也看過各種人來來去去。在 Amazon 待超過五年的員工不正確估算在全球大概佔 PR 90，在同一個團隊待超過五年的人更是稀缺。一滿五年，你就能夠晉身橘色識別證的一員1。作為團隊少數幾個拿橘牌的員工，不免有一些勵志或是辛苦的工作歷程可以分享，可惜忙碌跟快速的工作步調讓很多想法稍縱即逝。尤其是回顧自己過去寫下的內容 (我在 Amazon 學到的 10 件事)，驚覺這些改變其實無時無刻都在發生，我確實明白自己有些模樣在這五年前已經有所改變，慶幸的是我沒有因為環境而變得事故。   我想或多或少是因為能夠透過回顧這些內容，甚至是因為協助面試的緣故，很多來面試的候選人甚至主動提及曾經讀過我的內容並且因此受到一些啟發 (不論是否最終有進入我們團隊工作)。這些文字跟反饋都讓我時刻刻提醒自己要永保初心，也要求自己用更成熟的方法處理事情。有些文章甚至獲得很多各方高手的迴響，但一直遲遲沒有安排時間再繼續寫更多。因此寫下這篇內容，也算是我個人對自己在用五年後的視角，來總結我對這個團隊喜歡和認為有待加強的地方。   在這裡先提個免責申明，AWS 雖然作為 Amazon 整個集團重要的一個業務，但有許多管理的方式可能也因不同組織和角色而有所差異。畢竟 Amazon 在全球有數十萬名員工分佈在世界各地，工作時遇到一堆奇奇怪怪的部門早已屢見不鮮，用 AWS Support 不能以偏概全所有團隊的樣貌。   此外，這篇內容僅為個人的觀察，不代表任何官方立場，本篇內容更不期待帶有任何批判色彩。在團隊裡身為一個獨立貢獻者 (Individual Contributor)，大部分時間我也是站在第一線解決各式各樣的工程問題，而非討論管理維運議題。因為不是站在管理層的角度用宏觀的面向關注團隊維運，工程師關注的議題跟管理者的議題多少都有些不同，我僅分享我對於身為工程師及親身經歷的相關感受，不意味著任何一方不好。   畢竟我的角度為「工程師」而非「管理者」，因此可能部分觀察的角度也會有所侷限，但會盡可能用客觀的角度寫下我個人的觀察，還請閱讀者自行評判。   認識不同年齡層工作者的機會間接拓展更廣的人際網路   我在中文技術團隊觀察一直沒變的事情是，團隊中充滿了各式各樣優秀的同事，許多不乏都是在業界工作數年的工程師並且擁有豐富的經歷。有趣的是，時下的招聘政策也鼓勵許多剛畢業的學生加入 AWS Support 技術團隊，不時為團隊注入心血，使得整個團隊的組成十分多元。常常也有許多不同的新進同事從其他公司帶來不一樣的經驗和想法，甚至從原本使用 AWS 產品的客戶端變成解決問題的角色，都促使團隊中因為不同背景的工作者加入彼此交流而建立強大的人脈網路。   與全世界交流   Cloud Support Engineer 是一個全球化的團隊，工程師遍佈世界各地。當你身肩的責任和任務越多，自然越有更多機會與全世界的同事交流和執行專案。我個人曾經主持過跨三個時區的技術講座和訓練，不僅讓我實際應用專案管理的思維、訓練教學技能，更讓我進一步增加自己的能見度，並且實質提升團隊的技術職能，為團隊作出貢獻。   能進一步打開自己的視野並與全世界交流，是我個人最喜歡的部分。尤其身處 Dublin，多得是不同語言和背景的工程師，充滿了不同國家、語言、背景交流的機會，除了專注在技術上的交流，工作之餘也可以聊聊不同背景之間的特色和學習彼此的文化。   但如果人為在台灣的技術團隊，實際上可能因為時區的緣故，部分交流多少會有一些受限。但與世界各地的同事交流仍只是使用通訊軟體這種觸手可及的事情，壞處就是你可能要額外安排其他時間 (比如你必須要早起、晚上回訊息或參加會議)。   增強抗壓能力   我認為這份工作與一般軟體開發最大不同的是，由於面對的是客戶的生產環境，Cloud Support Engineer 不時會有面對高壓的情境，例如功能故障、應用程式不工作的事件、系統崩潰等等。有時候客戶甚至會不斷的催促你盡快給予資訊，在這種情況下，你需要學會保持冷靜和集中注意力，同時，不能因客戶的情緒引領你往不正確的調查方向。   我還記得第一次面對客戶環境故障時，我還得請求資深工程師一同指導解決客戶所遭遇的技術問題。但在從中觀摩學習後，並且檢討學習排查問題的方法不斷練習，慢慢將這種壓力視為對客戶的理解，學會用冷靜的態度處理棘手的狀況，正確的釐清和排除。可能有些人認為是缺點 (例如：客戶很難搞)，但實際在走過一遭後，一旦你跨過那個不舒服的過程，將成為無懈可擊且帶得走的軟實力，就看你是否願意視這些挑戰為成長的機會。   這樣的經驗和訓練不自覺在生活中產生一些幫助，尤其是面對系統故障或是一些非預期的狀況發生時，第一直覺反應是釐清問題並且如何找出解決問題的方式，而不是受情緒或環境影響不斷焦慮。   磨練跨團隊的溝通技巧   Cloud Support Engineer 與軟體開發不同的是，這是一個大量需要溝通的工作角色，並且將技術問題用淺顯易懂的方式與客戶分享相關的調查結果、提及可執行且理解的步驟供客戶採納 (不論是書信、Chat 或是電話形式)。由於面向的客戶端存在各式各樣的角色，你除了要學會用開發者能理解的方式解釋問題和解決方案，不免遇到客戶端主管級別的角色想釐清問題的相應狀況；同時，AWS 也會有不同面向的客戶端角色一同協助客戶的問題，身為技術工程師也讓我多了很多必須要學會與這些不同角色溝通的技能。   某種程度上學會站在他人角度、同理他人。在產品開發團隊前面，我會需要了解客戶遭遇的問題是什麼、如何複製、點出產品當前的問題、建議如何修正。除了要讓產品團隊理解當前問題要排查的方向，更需要對產品整體的核心運作有一定的認識，才能使用開發團隊所能理解的語言有效的將問題修正；在客戶前面，我需要了解客戶所遭遇的問題、客戶的痛點，並且提出可參考的實務建議，以幫助他們在業務上透過產品的功能和方法，滿足他們業務上所期待的目標，甚至有時候需要引導客戶改正問題以爲他們帶來長遠的效益 (因為有時候客戶有自己的想法並且多急於解決當下的短期問題)。   提升書信寫作能力   除了 Amazon 組織文化本身就具備寫文件的精神外，技術支持工程師會有大量的時間會投入在將複雜的問題調查報告轉譯成客戶或是產品團隊能理解的語言，並且寫出能夠讓客戶理解的書信內容。                     一個 AWS Support Center 的通訊範例 (非技術相關)            各種曝光和成長的機會   AWS Support 除了是一個跨國組成的團隊外，AWS 本身就提供了一個能夠讓你成長和曝光的平台。   身處中文 DevOps/Container 領域的技術團隊，我特別喜歡的一點是週遭的同事都非常支持且互相幫忙，並且在自己的職涯規劃上都很積極，不會只侷限在日常協助客戶解決單一 Support Case 的問題上。   即使每天日常解決多少個 Support Case (Ticket) 很重要，但更多得是其他面向的工作幫助你成長不同面向的技能。由於 AWS Support 密切的與不同產業的客戶合作，一個顯著的例子是透過客戶端面向的教育訓練機會幫助你成長，為不同規模的企業客戶分享有關 AWS 產品的使用建議和最佳實踐。   此外，為了協助更多客戶解決技術問題，內部不時充斥各種專案和計畫。不論是藉由影片、技術文章或是教育訓練，團隊成員們都會透過不同的方式提升自己的技能。除了使中文的客戶受益，更多時候貢獻己力讓全球的客戶受益，並且在全球打開能見度。例如，以下都是我或是同事們貢獻的各種內容：   AWS Knowledge Center     How do I troubleshoot the error “ECS was unable to assume the role” when running the Amazon ECS tasks? - Joyce Kuo   How do I troubleshoot the container health check failures for Amazon ECS tasks? - Shih-ting Yuan                                                   更甚者，我厲害的同事們多是路見不平拿 Pull Request 來填，甚至會提交對應的修補程式，或開發對應的工具讓更多客戶從中受益，例如：      (aws-cdk) fix(eks): cannot disable cluster logging once it has been enabled #21185 - Kuo-Le Mei   AWS::RDS::DBInstance replacement update notice #1225 - Yu-Chi Chen   cloudtrail-cli - Kuo-Le Mei   彈性的職涯規劃路徑   作為開啟 AWS 職涯的敲門磚，Cloud Support Engineer 著實是一個充滿學習廣度機會的工作，這也是我個人覺得這份工作十分有趣的地方，例如：      處理客戶案例所累積對於 AWS 服務的技術知識和高可用架構設計思維、在客戶端大量的提供教育訓練或最佳實踐建議，轉職成為解決方案架構師 (Solution Architect)   針對特定客戶所遭遇的問題提供協助而逐步轉職成為技術經理 (Technical Account Manager)   協助客戶執行教育訓練或是訓練內部工程師，培養成為講者的能力 (Trainer)   設計內部工具和相關專案計畫累積系統設計相關的開發技能 (Software Development Engineer)   大量的書信寫作訓練和開源文件貢獻機會，轉職成為技術寫手 (Technical Writer)   整合內部資源執行跨區域或是全球的計畫，逐步成為主管 (Operation Manager) 或是資深工程師   還算可接受的 Work-life balance   雖然每個人對於 Work-life balance 的定義不同 (就我的觀點，這是一種相對感受)，但比起很多公司的 IT Support 或是工程師職位，「相對來說」，AWS Cloud Support Engineer 可能不會是一個非常輕鬆的工作。   以目前團隊的工作型態，為了提供客戶 24 x 7 x 365 天不間斷的支持，除了意味著國定假日或是週末會是你的工作時間外，團隊成員彼此之間通常工作時間會有部分不重疊的輪班制度。   但之所以我認為這還算可接受，主要有以下幾點觀察：           (1) 在過去，在台灣的中文團隊值班時間需覆蓋整整 16 小時，直到晚上 11 點左右才轉移至北美時區 (這意味著當時有部分同事需要工作到晚上 11 點)。由於值晚班這件事情對很多人來說並不是一個很健康的工作型態，管理層也在台灣團隊成立不久後，不斷地尋求可能的解決方案。隨著歐洲團隊的建立，這樣的現象也趨於改善，使得台灣能從值晚班的噩夢中解放，將工作時間往前推移 (能下班的時間越來越早)。            (2) 即使 Cloud Support Engineer 同樣會有 Oncall 的機制，團隊的 Oncall 會以工作時間為主。由於是全球化的團隊，工作時間結束後的 Oncall 班次將會由其他時區輪值。       大部分情況下，新進人員在 Work-life balance 這件事情上面通常能有很好的控制。但隨著想做的事情越多，可能在你身上肩負的責任也越多，使得工作與生活上不見得能夠充分平衡。例如：我觀察到資深的工程師，有時候也得必須配合美洲時區在晚上時間 (21:00) 之後開會。但「相對來說」，比起傳聞有些 Amazon 的開發團隊需要半夜 Oncall 起床處理問題，確實種程度上是還可接受的 Work-life balance。   雖然難以置信，但在提供客戶 24 小時不間斷服務的背後，仍有 AWS 開發團隊需要負擔全天候的 Oncall 工作，不得不得在半夜時間起床。尤其你身為 AWS 技術支持工程師並具備一定資歷後，多少會接觸到客戶生產環境故障的問題，多的是把北美時區的開發者叫起床的機會。   作為曾經在半夜被叫醒的工作者，我個人十分認同半夜起床值 Oncall 是一個很不健康的工作型態。雖然團隊對於工作型態的設計不是我很喜歡的一點，但在方面團隊整體確實有在以緩慢的節奏進步。隨著加入的人才越多，整個團隊的工作安排會趨於理想值。   客戶無法區分清楚真正的問題緊急程度：客戶預期和實際環境的衝突導致工作時間碎片化   日常工作時間的碎片化是我個人很不喜歡的一點。要討論這點之前，需要先理解整體環境的影響佔這個問題的關鍵性因素。取決於市場型態不同，客戶的行為也會有所不同；對於中文的客戶，由於客戶習慣即時通訊方法和立刻響應速度，這往往造就了客戶使用技術支持服務時，產生很多非預期的行為。   即使在文件和產品頁面中明確定義了嚴重性的不同 2 3，客戶習慣仍傾向選擇最少的時間來開啟案例 (能選多短就選多短)，而非真正的問題嚴重性影響 (例如：客戶有一個專案趕著下週上線所以選擇最短的響應時間 15 分鐘，而非系統正在當機)：                     在產品頁面明確定義的案例嚴重性                              在文件頁面明確定義的案例嚴重性            即使明白客戶常常不正確的選擇案例嚴重性，AWS Support 仍提供客戶最大的決定權。然而，這樣的現象某種程度上確實也導致工程資源被濫用。這就好比家喻戶曉的伊索寓言「狼來了」中描述的故事，當假警報一多，除了使得團隊無法正確區分真正受到生產環境影響的故障，更嚴重的是由於工程師都被一堆非故障影響的問題佔用，使得團隊工程師無法很好平衡不同問題之間的嚴重性，即時協助真正有環境受損影響的故障。   這個現象所帶來的影響更使得中文技術團隊必須大量的應付客戶這種短而快的回覆，而往往喪失能夠專注在技術問題上的時間。我看過許多新進人員因此無所適從，迫使被拉去處理大量需要短時間回應的案例，而無法真正的在單一案例中投入太多充分的時間進行調查：一下忙 A 案例，一下被抽去做 B 案例，或是手邊正在忙碌的事情、正在開的會不得不中斷去協助客戶，導致工作時間的碎片化。如果間接犧牲的是客戶長遠的服務品質，我相信整個市場型態有很多有待改進的空間。   相對來說，日文客戶就慣用「一般指導」、「系統效能不佳/系統受損」等這類真正反應其事實狀況的案例嚴重性，進行問題指導和事件後的相關問題調查。這樣的市場型態讓我從日文團隊同事中間接受益，從他們每個人身上提供給客戶的回覆我學習到非常多。我常常可以觀察到他們提供給客戶的訊息都十分詳細且完整，在回覆前不僅做了非常多詳細的測試，更提出各種可參考的方案或是 PoC，甚至在內部已經討論過一圈 (但缺點是客戶需要有足夠的耐心)。   當然這並不是要比較哪種客戶比較好，畢竟，從親身體驗過印度客戶的型態，也覺得支持上充滿挑戰，就明白這並不是單一語系客戶的問題，每種客戶都有各自的特性。而是從實際經驗中，讓我對文化和市場差異有更深的體悟。   同時，團隊也在針對這項問題做了很多不同面向的嘗試，以試圖優化工程師在工作上的痛點，讓客戶學習如何更好且正確的使用 AWS 技術資源，以幫助他們解決真正重要的問題。   快速迭代的流程有時讓人無所適從   由於團隊快速成長且存在多時區的問題，為了適應不同問題的情境，流程的修訂和快速迭代有時往往讓人跟不上。例如：有時候今天建議的工作流程 A，可能明天會變成 A-1 版本，再過幾週可能變成 A-10。由於流程常因客戶需求和問題不斷迭代，有時候不見得能夠即時的在各區域中套用，或是特定區域根本是獨立的系統，有自己的一套系統運作。   除了「朝令夕改」大概是最適合用來形容團隊一些流程上的現況，很多時候團隊會不斷嘗試導入一些新的方法或是流程。我自己有時候都會覺得無所適從。必須要不時回去翻翻內部的文件，或是回到一些原則性的討論，以了解是否有任何理解錯誤。   雖然有時候感到混亂，但這種迭代的過程在團隊中會一直不斷的進行，你得學會適應快節奏和不斷變化的文化。   學會如何成為一名更好的客戶   最後，「學會如何成為一名更好的客戶」絕對是我任職客戶面向技術支持工程師角色這幾年收穫最大的體悟，絕對可以列為最重要的一點。由於日常工作中實際就是在做類似客戶服務性質的工作，工作中不免看盡客戶百態，了解不同客戶的型態，並且了解到什麼是好的、什麼是不好的。   身為一名技術支持工程師，隨著協助客戶經驗的累積，漸漸地學會如何站在客戶服務人員的角度思考，並且同理身為客戶服務角色的辛苦。   當你了解到客戶並未尊重專業時，那份挫折感絕對是深深擊潰你對於技術的自信。甚至很多時候即使你的建議正確，並且成功解決客戶問題後，客戶可能就只把你當做一名 AWS 的後台人員，也不見得會獲得客戶的肯定。   在開始工作的頭幾年我很不能理解，往往覺得在工作上付出了努力但仍得不到任何客戶的反饋；但轉頭一看，其實還是有非常多的客戶展現充分的專業並且在工作上有很好的合作體驗，更加學會心平氣和的理解不同性質的客戶。也因此學習到如何成為一名「好客戶」，更懂得如何在日常的生活中，向不同產業、工作的客戶服務人員展示尊重，可以是餐廳服務生、是銀行電話客戶服務人員，或是任何一種客戶面向的工作者。在我所處的團隊中，團隊成員也都不吝分享自己的經驗，並且分享如何針對不同客戶提供適當的處理方式，藉由這些經驗成長。   自從成為客戶服務角色後，能更同理不同行業類別的客服工作，更加重視第一線的服務人員背後所付出的辛勞。並且在未獲得預期的服務水平時，能提出實質的建議、想法而不是純抱怨。有趣的是，這樣做往往讓我獲得更為滿意的結果 (不是更快的退費效率或是獲得更多的補償)，一同促使產品和服務進步。   總結   在這篇內容中，深入探討了在 Amazon Web Services (AWS) 擔任 Cloud Support Engineer 的工作體驗，並分享了個人在過去五年中學到的寶貴技能和體驗。以上幾點完全屬於個人的觀察，不代表任何官方立場。   如果你正對 AWS Cloud Support Engineer 職位感興趣，希望以上的內容對您有所幫助，也可以透過參考其他系列文章以幫助你了解更多資訊。   看更多系列文章      我在 Amazon 學到的 10 件事   我是如何在還沒畢業就錄取並進入到 Amazon 工作   我是如何在一年內通過 AWS 五大核心認證   Amazon Cloud Support Engineer 到底是在做什麼 (Amazon Web Services / AWS)   關於 Cloud Support Engineer 職位的常見問題 (Amazon Web Services / AWS) - AWS Cloud Support Engineer FAQs   在 AWS Cloud Support Engineer 面試中脫穎而出：必備的技術能力和重要特質   身處 Amazon 工作 5 年學到的事：在 AWS 擔任 Cloud Support Engineer 是什麼樣的體驗   References                  Discover what’s behind the Amazon ID badges &#8617;                  比較 AWS Support 計畫 &#8617;                  建立支援案例和案例管理 - 選擇嚴重性 &#8617;           ","categories": [],
        "tags": ["amazon","aws","amazon web services","work","Cloud Support","Cloud Support Engineer"],
        "url": "https://easoncao.com/five-years-at-amazon-as-cloud-support-engineer-in-aws/",
        "teaser": "https://easoncao.com/assets/images/posts/2023/04/five-years-at-amazon-as-cloud-support-engineer-in-aws/cover.jpg"
      }]
